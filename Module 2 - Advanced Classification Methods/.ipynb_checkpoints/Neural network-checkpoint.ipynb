{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2070b1b-dca7-4885-b10e-83027255adf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:219: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score \n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.manifold import Isomap\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn import random_projection\n",
    "from sklearn.manifold import MDS\n",
    "from sklearn.manifold import Isomap\n",
    "\n",
    "# Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# Optional: KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from collections import defaultdict\n",
    "\n",
    "from scikitplot.metrics import plot_roc\n",
    "from scikitplot.metrics import plot_precision_recall\n",
    "from scikitplot.metrics import plot_cumulative_gain\n",
    "from scikitplot.metrics import plot_lift_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9723d75-3278-4d3f-8423-bc870746b335",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce62abb2-809f-489f-8884-9850ed6d4e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of Features: 561\n"
     ]
    }
   ],
   "source": [
    "features = list()\n",
    "with open('../features.txt') as f:\n",
    "    features = [line.split()[1] for line in f.readlines()]\n",
    "print('No of Features: {}'.format(len(features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bae65eb1-4079-41c0-b990-7d646de856f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('X_train.txt', delim_whitespace=True, header=None, encoding='latin-1')\n",
    "X_train.columns = features\n",
    "\n",
    "# add subject column to the dataframe\n",
    "#X_train['subject'] = pd.read_csv('subject_train.txt', header=None, squeeze=True)\n",
    "\n",
    "y_train = pd.read_csv('y_train.txt', names=['Activity'], squeeze=True)\n",
    "#y_train_labels = y_train.map({1: 'WALKING', 2:'WALKING_UPSTAIRS',3:'WALKING_DOWNSTAIRS',\\\n",
    "#                       4:'SITTING', 5:'STANDING',6:'LAYING'})\n",
    "\n",
    "# put all columns in a single dataframe\n",
    "#train = X_train\n",
    "#train['Activity'] = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8cfd472f-1c53-4a5c-8e1f-6ea333b19d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.read_csv('../test/X_test.txt', delim_whitespace=True, header=None, encoding='latin-1')\n",
    "X_test.columns = features\n",
    "\n",
    "# add subject column to the dataframe\n",
    "#X_test['subject'] = pd.read_csv('subject_train.txt', header=None, squeeze=True)\n",
    "\n",
    "y_test = pd.read_csv('../test/y_test.txt', names=['Activity'], squeeze=True)\n",
    "#y_test_labels = y_train.map({1: 'WALKING', 2:'WALKING_UPSTAIRS',3:'WALKING_DOWNSTAIRS',\\\n",
    "#                       4:'SITTING', 5:'STANDING',6:'LAYING'})\n",
    "\n",
    "# put all columns in a single dataframe\n",
    "#train01 = X_test\n",
    "#train01['Activity'] = y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a50043-3621-4f18-a0a3-dc7623a8938e",
   "metadata": {
    "id": "9__Vi3KWxa6q",
    "tags": []
   },
   "source": [
    "## Hyper-Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ed88598-dbc1-4ca6-8c00-13e083b9daa0",
   "metadata": {
    "id": "qi07ibIXxa6r"
   },
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "raw",
   "id": "65de6df1-b2be-4ce1-ac95-a4bbec9347ec",
   "metadata": {
    "id": "-YGpEgGnxa6r"
   },
   "source": [
    "def build_model(n_layers=2, h_dim=64, activation='relu', optimizer='adam'):\n",
    "    # define the model\n",
    "    model = Sequential()\n",
    "\n",
    "    n_feature = X_train.shape[1]\n",
    "    \n",
    "    model.add(Dense(h_dim, activation=activation, input_shape=(n_feature,)))\n",
    "    for i in range(n_layers-1):\n",
    "        model.add(Dense(h_dim, activation=activation))\n",
    "    #linear activation\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    #compile the model\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2c6fa244-ab74-4b89-9ff2-0484ce50d30d",
   "metadata": {
    "id": "7X5a5Rhdxa6r"
   },
   "source": [
    "n_layers = [1, 2, 3]\n",
    "h_dim = [32, 64, 128]\n",
    "activation = ['relu', 'tanh']\n",
    "optimizer = ['adagrad', 'adam']\n",
    "params = dict(optimizer=optimizer, n_layers=n_layers, h_dim=h_dim, activation=activation)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0017e990-5745-465b-bf75-c740c4d6d599",
   "metadata": {
    "id": "s0hrtheUxa6r",
    "outputId": "6d9f45b9-6b70-44e6-8b85-1248392caec0"
   },
   "source": [
    "model = KerasClassifier(build_fn=build_model)\n",
    "\n",
    "rnd = RandomizedSearchCV(estimator=model, param_distributions=params, n_iter=5, cv=3)\n",
    "rnd_result = rnd.fit(X_train, y_train, epochs=100, batch_size=10, verbose=0)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5eda1e5d-f8c4-43fe-bfa1-79077cbf8565",
   "metadata": {
    "id": "JnUQjKzixa6s",
    "outputId": "43c851ff-4e2e-4a61-e013-90079d4a9a99"
   },
   "source": [
    "print(\"Best: %f using %s\" % (-rnd_result.best_score_, rnd_result.best_params_))\n",
    "means = rnd_result.cv_results_['mean_test_score']\n",
    "stds = rnd_result.cv_results_['std_test_score']\n",
    "params = rnd_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (-mean, stdev, param))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "845a67fc-5be0-44c8-b535-bc1be3a9ae52",
   "metadata": {
    "id": "ndbhP-8Yxa6s",
    "outputId": "0a0c826a-8420-48e8-89a4-5b7fdc737942"
   },
   "source": [
    "clf = rnd_result.best_estimator_.model\n",
    "\n",
    "loss, acc = clf.evaluate(X_test, y_test)\n",
    "print('Loss %f, Accuracy %f' % (loss, acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9cf68f-da23-48c1-81b3-351df4cc4828",
   "metadata": {
    "id": "reItPoV-xa6c"
   },
   "source": [
    "# Sklearn Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ccc1ebd8-d2c4-4e1e-82ea-49ae7c92e276",
   "metadata": {
    "id": "M6-3eV8kxa6c"
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e31edd09-a1c6-4943-8979-7dfd1ae7eb59",
   "metadata": {},
   "source": [
    "param = {\n",
    "    #'hidden_layer_sizes': [1, 2, 3, 4, 5, 6],\n",
    "    'activation': ['tanh', 'relu', 'logistic'],\n",
    "    'solver': ['sgd', 'adam', 'lbfgs'],\n",
    "    #'batch_size': [6, 12, 24, 32, 64, 128],\n",
    "    'learning_rate': ['constant','adaptive'],\n",
    "}\n",
    "\n",
    "clf = GridSearchCV(MLPClassifier(), param, n_jobs=-1, cv=5)\n",
    "grid_search = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8170210c-89a5-4757-a5c0-1a7912bfae96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'tanh', 'learning_rate': 'adaptive', 'solver': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "188a1740-980a-470c-8d76-44bcb80eeda0",
   "metadata": {
    "id": "BunblYs6xa6c"
   },
   "outputs": [],
   "source": [
    "hidden_layer_sizes = (100, 200,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2b282c-5198-41ed-aecb-8f235d92bdce",
   "metadata": {
    "id": "oTueGBTUxa6c",
    "tags": []
   },
   "source": [
    "### Parameters\n",
    "\n",
    "hidden_layer_sizes tuple, length = n_layers - 2, default=(100,)\n",
    "The ith element represents the number of neurons in the ith hidden layer.\n",
    "\n",
    "activation {'identity', 'logistic', 'tanh', 'relu'}, default='relu'\n",
    "Activation function for the hidden layer.\n",
    "* 'identity', no-op activation, useful to implement linear bottleneck, returns f(x) = x\n",
    "* 'logistic', the logistic sigmoid function, returns f(x) = 1 / (1 + exp(-x)).\n",
    "* 'tanh', the hyperbolic tan function, returns f(x) = tanh(x).\n",
    "* 'relu', the rectified linear unit function, returns f(x) = max(0, x)\n",
    "\n",
    "solver {'lbfgs', 'sgd', 'adam'}, default='adam'\n",
    "The solver for weight optimization.\n",
    "* 'lbfgs' is an optimizer in the family of quasi-Newton methods.\n",
    "* 'sgd' refers to stochastic gradient descent.\n",
    "* 'adam' refers to a stochastic gradient-based optimizer proposed by Kingma, Diederik, and Jimmy Ba\n",
    "The default solver 'adam' works pretty well on relatively large datasets (>= 1000 training samples) in terms of both training time and validation score. For small datasets, 'lbfgs' can converge faster and perform better.\n",
    "\n",
    "alpha float, default=0.0001\n",
    "L2 penalty (regularization term) parameter.\n",
    "\n",
    "batch_size int, default='auto'\n",
    "Size of minibatches for stochastic optimizers. If the solver is 'lbfgs', the classifier will not use minibatch. When set to “auto”, batch_size=min(200, n_samples)\n",
    "\n",
    "learning_rate {'constant', 'invscaling', 'adaptive'}, default='constant'\n",
    "Learning rate schedule for weight updates.\n",
    "*'constant' is a constant learning rate given by 'learning_rate_init'.\n",
    "*'invscaling' gradually decreases the learning rate at each time step 't' using an inverse scaling exponent of *'power_t'. effective_learning_rate = learning_rate_init / pow(t, power_t)\n",
    "*'adaptive' keeps the learning rate constant to 'learning_rate_init' as long as training loss keeps decreasing. Each time two consecutive epochs fail to decrease training loss by at least tol, or fail to increase validation score by at least tol if 'early_stopping' is on, the current learning rate is divided by 5.\n",
    "Only used when solver='sgd'.\n",
    "\n",
    "learning_rate_init double, default=0.001\n",
    "The initial learning rate used. It controls the step-size in updating the weights. Only used when solver='sgd' or 'adam'.\n",
    "\n",
    "power_t double, default=0.5\n",
    "The exponent for inverse scaling learning rate. It is used in updating effective learning rate when the learning_rate is set to 'invscaling'. Only used when solver='sgd'.\n",
    "\n",
    "max_iter int, default=200\n",
    "Maximum number of iterations. The solver iterates until convergence (determined by 'tol') or this number of iterations. For stochastic solvers ('sgd', 'adam'), note that this determines the number of epochs (how many times each data point will be used), not the number of gradient steps.\n",
    "\n",
    "shuffle bool, default=True\n",
    "Whether to shuffle samples in each iteration. Only used when solver='sgd' or 'adam'.\n",
    "\n",
    "random_state int, RandomState instance or None, default=None\n",
    "If int, random_state is the seed used by the random number generator; If RandomState instance, random_state is the random number generator; If None, the random number generator is the RandomState instance used by np.random.\n",
    "\n",
    "tol float, default=1e-4\n",
    "Tolerance for the optimization. When the loss or score is not improving by at least tol for n_iter_no_change consecutive iterations, unless learning_rate is set to 'adaptive', convergence is considered to be reached and training stops.\n",
    "\n",
    "verbose bool, default=False\n",
    "Whether to print progress messages to stdout.\n",
    "\n",
    "warm_start bool, default=False\n",
    "When set to True, reuse the solution of the previous call to fit as initialization, otherwise, just erase the previous solution. See the Glossary.\n",
    "\n",
    "momentum float, default=0.9\n",
    "Momentum for gradient descent update. Should be between 0 and 1. Only used when solver='sgd'.\n",
    "\n",
    "early_stopping bool, default=False\n",
    "Whether to use early stopping to terminate training when validation score is not improving. If set to true, it will automatically set aside 10% of training data as validation and terminate training when validation score is not improving by at least tol for n_iter_no_change consecutive epochs. The split is stratified, except in a multilabel setting. Only effective when solver='sgd' or 'adam'\n",
    "\n",
    "validation_fraction float, default=0.1\n",
    "The proportion of training data to set aside as validation set for early stopping. Must be between 0 and 1. Only used if early_stopping is True\n",
    "\n",
    "beta_1 float, default=0.9\n",
    "Exponential decay rate for estimates of first moment vector in adam, should be in [0, 1). Only used when solver='adam'\n",
    "\n",
    "beta_2 float, default=0.999\n",
    "Exponential decay rate for estimates of second moment vector in adam, should be in [0, 1). Only used when solver='adam'\n",
    "\n",
    "epsilon float, default=1e-8\n",
    "Value for numerical stability in adam. Only used when solver='adam'\n",
    "\n",
    "n_iter_no_change int, default=10\n",
    "Maximum number of epochs to not meet tol improvement. Only effective when solver='sgd' or 'adam'\n",
    "\n",
    "\n",
    "### Attributes\n",
    "loss_ float\n",
    "The current loss computed with the loss function.\n",
    "\n",
    "coefs_ list, length n_layers - 1\n",
    "The ith element in the list represents the weight matrix corresponding to layer i.\n",
    "\n",
    "intercepts_ list, length n_layers - 1\n",
    "The ith element in the list represents the bias vector corresponding to layer i + 1.\n",
    "\n",
    "n_iter_ int,\n",
    "The number of iterations the solver has ran.\n",
    "\n",
    "n_layers_ int\n",
    "Number of layers.\n",
    "\n",
    "n_outputs_ int\n",
    "Number of outputs.\n",
    "\n",
    "out_activation_ string\n",
    "Name of the output activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "855fb7ad-f391-44f1-8b1b-fc088803fae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.92      0.97      0.94       496\n",
      "           2       0.94      0.97      0.96       471\n",
      "           3       0.98      0.95      0.96       420\n",
      "           4       0.94      0.92      0.93       491\n",
      "           5       0.92      0.94      0.93       532\n",
      "           6       1.00      0.95      0.98       537\n",
      "\n",
      "    accuracy                           0.95      2947\n",
      "   macro avg       0.95      0.95      0.95      2947\n",
      "weighted avg       0.95      0.95      0.95      2947\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf4 = MLPClassifier(hidden_layer_sizes=(4), learning_rate='adaptive', \n",
    "                    activation='tanh', early_stopping=False, solver='adam', batch_size=(12), random_state=0)\n",
    "\n",
    "clf4.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf4.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "693d4896-e894-4985-8931-084a6f2bb2c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.96      0.99      0.98       496\n",
      "           2       0.98      0.95      0.97       471\n",
      "           3       0.99      0.98      0.98       420\n",
      "           4       0.96      0.87      0.91       491\n",
      "           5       0.90      0.96      0.93       532\n",
      "           6       0.99      1.00      1.00       537\n",
      "\n",
      "    accuracy                           0.96      2947\n",
      "   macro avg       0.96      0.96      0.96      2947\n",
      "weighted avg       0.96      0.96      0.96      2947\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf5 = MLPClassifier(hidden_layer_sizes=(5), learning_rate='adaptive',\n",
    "                    activation='tanh', early_stopping=False, solver='adam', batch_size=(32), random_state=0)\n",
    "\n",
    "clf5.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf5.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ca750ba-c423-4bec-b9da-a71e061d9a9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))\n",
    "fig.suptitle('Loss curves', fontweight='bold', fontsize=20)\n",
    "\n",
    "ax1.title.set_text('4 hidden layer (batch 12)')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_xlabel('Epochs')\n",
    "ax1.plot(clf4.loss_curve_)\n",
    "\n",
    "ax2.title.set_text('5 hidden layer (batch 32)')\n",
    "ax2.set_ylabel('Loss')\n",
    "ax2.set_xlabel('Epochs')\n",
    "ax2.plot(clf5.loss_curve_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4b6172c-8ac3-4f99-8b48-d5c93b2de31b",
   "metadata": {
    "id": "_9UuoSC6xa6e",
    "outputId": "f639b73b-4820-40e1-e1cf-698bd8b2ab42"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(clf.loss_curve_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56220164-297c-4f2b-a14c-8321d3dada8f",
   "metadata": {
    "id": "kcfc8kg4xa6i"
   },
   "source": [
    "# Keras Deep Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "345f4c29-f094-41d9-937f-420b2c6b0ac6",
   "metadata": {
    "id": "d-P_FuIAxa6i"
   },
   "outputs": [],
   "source": [
    "# use old pc or fix\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "93396694-41bf-4bb7-8ccd-9c8bc44e1121",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_train)\n",
    "encoded_Y = encoder.transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "23474cef-4de8-40be-8e8f-441cd1e48700",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_test)\n",
    "encoded_test = encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fd80e784-f464-43d7-812d-09fd45ca453b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_y = np_utils.to_categorical(encoded_Y)\n",
    "test_y = np_utils.to_categorical(encoded_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7fa5c8f-03ea-4021-a283-6324a68e31a1",
   "metadata": {
    "id": "c9elqE0pxa6i"
   },
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    \n",
    "    n_feature = X_train.shape[1] #561\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, input_dim=561, activation='relu'))\n",
    "    #model.add(Dropout(0.5))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    #model.add(Dropout(0.5))\n",
    "    model.add(Dense(6, activation='softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6519b0f0-fe9f-4bcf-a8e2-bda29e2b326c",
   "metadata": {
    "collapsed": true,
    "id": "JG0wI3uLxa6i",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "a8df190c-7104-4fef-9e97-bf912ad7b770",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "736/736 [==============================] - 5s 6ms/step - loss: 0.3094 - accuracy: 0.8758\n",
      "Epoch 2/50\n",
      "736/736 [==============================] - 4s 6ms/step - loss: 0.1395 - accuracy: 0.9418\n",
      "Epoch 3/50\n",
      "736/736 [==============================] - 4s 6ms/step - loss: 0.0974 - accuracy: 0.9597\n",
      "Epoch 4/50\n",
      "736/736 [==============================] - 4s 5ms/step - loss: 0.0933 - accuracy: 0.9615\n",
      "Epoch 5/50\n",
      "736/736 [==============================] - 4s 6ms/step - loss: 0.0874 - accuracy: 0.9659\n",
      "Epoch 6/50\n",
      "736/736 [==============================] - 5s 6ms/step - loss: 0.0744 - accuracy: 0.9693\n",
      "Epoch 7/50\n",
      "736/736 [==============================] - 5s 7ms/step - loss: 0.0822 - accuracy: 0.9697\n",
      "Epoch 8/50\n",
      "736/736 [==============================] - 5s 7ms/step - loss: 0.0742 - accuracy: 0.9716\n",
      "Epoch 9/50\n",
      "736/736 [==============================] - 7s 9ms/step - loss: 0.0657 - accuracy: 0.9737\n",
      "Epoch 10/50\n",
      "736/736 [==============================] - 4s 6ms/step - loss: 0.0621 - accuracy: 0.9748\n",
      "Epoch 11/50\n",
      "736/736 [==============================] - 4s 5ms/step - loss: 0.0588 - accuracy: 0.9780\n",
      "Epoch 12/50\n",
      "736/736 [==============================] - 4s 6ms/step - loss: 0.0668 - accuracy: 0.9755\n",
      "Epoch 13/50\n",
      "736/736 [==============================] - 4s 6ms/step - loss: 0.0631 - accuracy: 0.9766\n",
      "Epoch 14/50\n",
      "736/736 [==============================] - 5s 6ms/step - loss: 0.0493 - accuracy: 0.9808\n",
      "Epoch 15/50\n",
      "736/736 [==============================] - 4s 6ms/step - loss: 0.0612 - accuracy: 0.9771\n",
      "Epoch 16/50\n",
      "736/736 [==============================] - 4s 6ms/step - loss: 0.0557 - accuracy: 0.9797\n",
      "Epoch 17/50\n",
      "736/736 [==============================] - 4s 5ms/step - loss: 0.0504 - accuracy: 0.9786\n",
      "Epoch 18/50\n",
      "736/736 [==============================] - 4s 5ms/step - loss: 0.0514 - accuracy: 0.9808\n",
      "Epoch 19/50\n",
      "736/736 [==============================] - 5s 6ms/step - loss: 0.0500 - accuracy: 0.9819\n",
      "Epoch 20/50\n",
      "736/736 [==============================] - 4s 6ms/step - loss: 0.0479 - accuracy: 0.9818\n",
      "Epoch 21/50\n",
      "736/736 [==============================] - 4s 6ms/step - loss: 0.0453 - accuracy: 0.9822\n",
      "Epoch 22/50\n",
      "736/736 [==============================] - 5s 6ms/step - loss: 0.0448 - accuracy: 0.9823\n",
      "Epoch 23/50\n",
      "736/736 [==============================] - 5s 6ms/step - loss: 0.0612 - accuracy: 0.9773\n",
      "Epoch 24/50\n",
      "736/736 [==============================] - 5s 6ms/step - loss: 0.0441 - accuracy: 0.9822\n",
      "Epoch 25/50\n",
      "736/736 [==============================] - 4s 6ms/step - loss: 0.0461 - accuracy: 0.9833\n",
      "Epoch 26/50\n",
      "736/736 [==============================] - 4s 5ms/step - loss: 0.0422 - accuracy: 0.9834\n",
      "Epoch 27/50\n",
      "736/736 [==============================] - 5s 6ms/step - loss: 0.0544 - accuracy: 0.9820\n",
      "Epoch 28/50\n",
      "736/736 [==============================] - 4s 6ms/step - loss: 0.0461 - accuracy: 0.9818\n",
      "Epoch 29/50\n",
      "736/736 [==============================] - 4s 6ms/step - loss: 0.0395 - accuracy: 0.9841\n",
      "Epoch 30/50\n",
      "736/736 [==============================] - 5s 7ms/step - loss: 0.0424 - accuracy: 0.9844\n",
      "Epoch 31/50\n",
      "736/736 [==============================] - 4s 6ms/step - loss: 0.0439 - accuracy: 0.9841\n",
      "Epoch 32/50\n",
      "736/736 [==============================] - 4s 6ms/step - loss: 0.0421 - accuracy: 0.9823\n",
      "Epoch 33/50\n",
      "736/736 [==============================] - 4s 6ms/step - loss: 0.0362 - accuracy: 0.9853\n",
      "Epoch 34/50\n",
      "736/736 [==============================] - 4s 6ms/step - loss: 0.0466 - accuracy: 0.9826\n",
      "Epoch 35/50\n",
      "736/736 [==============================] - 4s 6ms/step - loss: 0.0438 - accuracy: 0.9850\n",
      "Epoch 36/50\n",
      "736/736 [==============================] - 4s 6ms/step - loss: 0.0421 - accuracy: 0.9833\n",
      "Epoch 37/50\n",
      "736/736 [==============================] - 4s 6ms/step - loss: 0.0351 - accuracy: 0.9868\n",
      "Epoch 38/50\n",
      "736/736 [==============================] - 5s 6ms/step - loss: 0.0475 - accuracy: 0.9816\n",
      "Epoch 39/50\n",
      "736/736 [==============================] - 4s 6ms/step - loss: 0.0314 - accuracy: 0.9878\n",
      "Epoch 40/50\n",
      "736/736 [==============================] - 4s 6ms/step - loss: 0.0346 - accuracy: 0.9886\n",
      "Epoch 41/50\n",
      "736/736 [==============================] - 4s 6ms/step - loss: 0.0542 - accuracy: 0.9812\n",
      "Epoch 42/50\n",
      "736/736 [==============================] - 4s 6ms/step - loss: 0.0417 - accuracy: 0.9857\n",
      "Epoch 43/50\n",
      "736/736 [==============================] - 4s 6ms/step - loss: 0.0460 - accuracy: 0.9831\n",
      "Epoch 44/50\n",
      "736/736 [==============================] - 4s 6ms/step - loss: 0.0430 - accuracy: 0.9823\n",
      "Epoch 45/50\n",
      "736/736 [==============================] - 4s 5ms/step - loss: 0.0356 - accuracy: 0.9869\n",
      "Epoch 46/50\n",
      "736/736 [==============================] - 4s 6ms/step - loss: 0.0356 - accuracy: 0.9856\n",
      "Epoch 47/50\n",
      "736/736 [==============================] - 4s 6ms/step - loss: 0.0398 - accuracy: 0.9864\n",
      "Epoch 48/50\n",
      "736/736 [==============================] - 4s 5ms/step - loss: 0.0321 - accuracy: 0.9882\n",
      "Epoch 49/50\n",
      "736/736 [==============================] - 5s 6ms/step - loss: 0.0341 - accuracy: 0.9875\n",
      "Epoch 50/50\n",
      "736/736 [==============================] - 5s 7ms/step - loss: 0.0294 - accuracy: 0.9887\n"
     ]
    }
   ],
   "source": [
    "model1 = build_model()\n",
    "\n",
    "history1 = model1.fit(X_train, dummy_y, epochs=50, batch_size=10).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c14f2863-79ce-4d43-b41d-bdbf3bc31b67",
   "metadata": {
    "collapsed": true,
    "id": "fwEqiel9xa6j",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "5a081bae-7960-45bb-d0e1-3aace3c46a11",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "148/148 [==============================] - 2s 8ms/step - loss: 0.4528 - accuracy: 0.8315\n",
      "Epoch 2/50\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.1659 - accuracy: 0.9377\n",
      "Epoch 3/50\n",
      "148/148 [==============================] - 1s 8ms/step - loss: 0.1074 - accuracy: 0.9614\n",
      "Epoch 4/50\n",
      "148/148 [==============================] - 1s 8ms/step - loss: 0.0865 - accuracy: 0.9684\n",
      "Epoch 5/50\n",
      "148/148 [==============================] - 1s 8ms/step - loss: 0.0788 - accuracy: 0.9697\n",
      "Epoch 6/50\n",
      "148/148 [==============================] - 1s 9ms/step - loss: 0.0855 - accuracy: 0.9660\n",
      "Epoch 7/50\n",
      "148/148 [==============================] - 1s 7ms/step - loss: 0.0659 - accuracy: 0.9744\n",
      "Epoch 8/50\n",
      "148/148 [==============================] - 1s 9ms/step - loss: 0.0676 - accuracy: 0.9758\n",
      "Epoch 9/50\n",
      "148/148 [==============================] - 2s 11ms/step - loss: 0.0658 - accuracy: 0.9728\n",
      "Epoch 10/50\n",
      "148/148 [==============================] - 1s 9ms/step - loss: 0.0591 - accuracy: 0.9776\n",
      "Epoch 11/50\n",
      "148/148 [==============================] - 1s 8ms/step - loss: 0.0513 - accuracy: 0.9805\n",
      "Epoch 12/50\n",
      "148/148 [==============================] - 1s 10ms/step - loss: 0.0459 - accuracy: 0.9811\n",
      "Epoch 13/50\n",
      "148/148 [==============================] - 1s 9ms/step - loss: 0.0461 - accuracy: 0.9819\n",
      "Epoch 14/50\n",
      "148/148 [==============================] - 1s 9ms/step - loss: 0.0489 - accuracy: 0.9822\n",
      "Epoch 15/50\n",
      "148/148 [==============================] - 1s 7ms/step - loss: 0.0494 - accuracy: 0.9803\n",
      "Epoch 16/50\n",
      "148/148 [==============================] - 1s 8ms/step - loss: 0.0479 - accuracy: 0.9811\n",
      "Epoch 17/50\n",
      "148/148 [==============================] - 1s 8ms/step - loss: 0.0848 - accuracy: 0.9694\n",
      "Epoch 18/50\n",
      "148/148 [==============================] - 1s 9ms/step - loss: 0.0472 - accuracy: 0.9804\n",
      "Epoch 19/50\n",
      "148/148 [==============================] - 1s 8ms/step - loss: 0.0421 - accuracy: 0.9846\n",
      "Epoch 20/50\n",
      "148/148 [==============================] - 1s 8ms/step - loss: 0.0386 - accuracy: 0.9859\n",
      "Epoch 21/50\n",
      "148/148 [==============================] - 1s 8ms/step - loss: 0.0470 - accuracy: 0.9820\n",
      "Epoch 22/50\n",
      "148/148 [==============================] - 1s 8ms/step - loss: 0.0430 - accuracy: 0.9816\n",
      "Epoch 23/50\n",
      "148/148 [==============================] - 1s 9ms/step - loss: 0.0805 - accuracy: 0.9737\n",
      "Epoch 24/50\n",
      "148/148 [==============================] - 1s 8ms/step - loss: 0.0426 - accuracy: 0.9830\n",
      "Epoch 25/50\n",
      "148/148 [==============================] - 2s 11ms/step - loss: 0.0392 - accuracy: 0.9849\n",
      "Epoch 26/50\n",
      "148/148 [==============================] - 1s 7ms/step - loss: 0.0411 - accuracy: 0.9842\n",
      "Epoch 27/50\n",
      "148/148 [==============================] - 1s 8ms/step - loss: 0.0387 - accuracy: 0.9849\n",
      "Epoch 28/50\n",
      "148/148 [==============================] - 1s 8ms/step - loss: 0.0334 - accuracy: 0.9880\n",
      "Epoch 29/50\n",
      "148/148 [==============================] - 1s 8ms/step - loss: 0.0400 - accuracy: 0.9849\n",
      "Epoch 30/50\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.0472 - accuracy: 0.9815\n",
      "Epoch 31/50\n",
      "148/148 [==============================] - 1s 9ms/step - loss: 0.0292 - accuracy: 0.9886\n",
      "Epoch 32/50\n",
      "148/148 [==============================] - 1s 9ms/step - loss: 0.0310 - accuracy: 0.9871\n",
      "Epoch 33/50\n",
      "148/148 [==============================] - 1s 10ms/step - loss: 0.0264 - accuracy: 0.9898\n",
      "Epoch 34/50\n",
      "148/148 [==============================] - 1s 9ms/step - loss: 0.0281 - accuracy: 0.9884\n",
      "Epoch 35/50\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.0293 - accuracy: 0.9895\n",
      "Epoch 36/50\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.0264 - accuracy: 0.9906\n",
      "Epoch 37/50\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.0763 - accuracy: 0.9709\n",
      "Epoch 38/50\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.0336 - accuracy: 0.9875\n",
      "Epoch 39/50\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.0348 - accuracy: 0.9856\n",
      "Epoch 40/50\n",
      "148/148 [==============================] - 1s 9ms/step - loss: 0.0238 - accuracy: 0.9903\n",
      "Epoch 41/50\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.0210 - accuracy: 0.9932\n",
      "Epoch 42/50\n",
      "148/148 [==============================] - 1s 8ms/step - loss: 0.0296 - accuracy: 0.9888\n",
      "Epoch 43/50\n",
      "148/148 [==============================] - 1s 8ms/step - loss: 0.0232 - accuracy: 0.9908\n",
      "Epoch 44/50\n",
      "148/148 [==============================] - 1s 9ms/step - loss: 0.0275 - accuracy: 0.9894\n",
      "Epoch 45/50\n",
      "148/148 [==============================] - 1s 8ms/step - loss: 0.0216 - accuracy: 0.9894\n",
      "Epoch 46/50\n",
      "148/148 [==============================] - 1s 9ms/step - loss: 0.0166 - accuracy: 0.9931\n",
      "Epoch 47/50\n",
      "148/148 [==============================] - 1s 8ms/step - loss: 0.0180 - accuracy: 0.9917\n",
      "Epoch 48/50\n",
      "148/148 [==============================] - 1s 8ms/step - loss: 0.0213 - accuracy: 0.9924\n",
      "Epoch 49/50\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.0173 - accuracy: 0.9933\n",
      "Epoch 50/50\n",
      "148/148 [==============================] - 1s 7ms/step - loss: 0.0282 - accuracy: 0.9891\n"
     ]
    }
   ],
   "source": [
    "model2 = build_model()\n",
    "\n",
    "history2 = model2.fit(X_train, dummy_y, epochs=50, batch_size=50).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "dcac9380-3204-4a60-8d80-31079c8f13c3",
   "metadata": {
    "id": "b-cGwHs2xa6j",
    "outputId": "ef8c48cd-334c-4315-b1cb-ca40f00eaa6f"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAA2C0lEQVR4nO3dd3yV5dnA8d+VcbIhgySMAGHvKaCCAoogOECcKK6KFa1WrdVq+9a+amtfbau1WrRuqRYQrQvECaiAgoQte0MgZJBBBtn3+8d9AoeQkAPk5JA81/fz4XPyPGddD4RznXtdtxhjUEop5VwB/g5AKaWUf2kiUEoph9NEoJRSDqeJQCmlHE4TgVJKOVyQvwM4WS1atDDJycn+DkMppRqVFStWZBlj4mu6r9ElguTkZFJSUvwdhlJKNSoisru2+7RrSCmlHE4TgVJKOZwmAqWUcrhGN0aglHKusrIyUlNTKS4u9ncoZ6zQ0FCSkpIIDg72+jmaCJRSjUZqaipRUVEkJycjIv4O54xjjOHgwYOkpqbSoUMHr5+nXUNKqUajuLiYuLg4TQK1EBHi4uJOusWkiUAp1ahoEjixU/n7cU4i2P0DzH8CKiv8HYlSSp1RnJMI9qXAomegtNDfkSilGrHIyEifv8dtt91GQkICvXv3PuZ8dnY2o0ePpkuXLowePZqcnJx6eT/nJAJXhL0tLfBvHEopVYdbb72Vzz///LjzTz31FKNGjWLr1q2MGjWKp556ql7ez0GJIMreaotAKVXPVq9ezTnnnEPfvn2ZOHHikW/qzz//PD179qRv375MmjQJgG+//Zb+/fvTv39/BgwYQH5+/nGvN3z4cGJjY487//HHH3PLLbcAcMstt/DRRx/VS/zOmT6qLQKlmpTH56xnw/5D9fqaPVs3438v73XSz7v55pt54YUXGDFiBH/4wx94/PHHee6553jqqafYuXMnISEh5ObmAvC3v/2NadOmMWzYMAoKCggNDfX6fdLT02nVqhUALVu2JD09/aRjrYmDWgRViUBbBEqp+pOXl0dubi4jRowA7Df17777DoC+ffsyefJk3nnnHYKC7PfuYcOG8cADD/D888+Tm5t75PzJEpF6m0HloBaBe4CnRFsESjUFp/LNvaF9+umnfPfdd8yZM4cnn3ySdevW8cgjj3DppZcyb948hg0bxhdffEH37t29er3ExETS0tJo1aoVaWlpJCQk1EuczmkRhLgTgXYNKaXqUfPmzYmJiWHRokUAvP3224wYMYLKykr27t3LBRdcwNNPP01eXh4FBQVs376dPn368PDDDzN48GA2bdrk9XuNHz+e6dOnAzB9+nQmTJhQL9fgoBaBdg0ppU5fUVERSUlJR44feOABpk+fzp133klRUREdO3bkzTffpKKightvvJG8vDyMMdx7771ER0fz6KOPsnDhQgICAujVqxfjxo077j2uv/56vvnmG7KyskhKSuLxxx9nypQpPPLII1x77bW8/vrrtG/fntmzZ9fLNWkiUEqpk1BZWVnj+aVLlx53bvHixcede+GFF+p8j5kzZ9Z4Pi4ujvnz59f5/JPlnK6hqjECTQRKKXUM5ySCwGAIDIHS4+fsKqWUkzknEYDtHtIWgVJKHcNhiSBSE4FSSlXjsEQQodNHlVKqGuclAl1QppRSx3BWIgjRriGl1OlpiDLUycnJ9OnTh/79+zNo0KAj57UMdX3QMQKlVCOxcOFCVq9eTUpKypFzWoa6PugYgVLKB+q7DHVttAx1fdDpo0o1HZ89AgfW1e9rtuwD407+W3Z9l6EWEcaMGYOIMHXqVO644w5Ay1DXD1ektgiUUvXKF2WoFy9ezMqVK/nss8+YNm3akdfzpGWoT5UrEsqLoaIcAp116Uo1Oafwzb2hnWoZ6jZt2gCQkJDAxIkT+fHHHxk+fHjjLEMtImNFZLOIbBORR07wuKtExIjIoNoeUy+qCs+VafeQUqp+1HcZ6sLCwiPjBoWFhXz55ZdHNrFvdGWoRSQQmAaMBlKB5SLyiTFmQ7XHRQH3Act8FcsRnhVIQ5v7/O2UUk2Pr8tQp6enM3HiRADKy8u54YYbGDt2LECjLEM9BNhmjNkBICKzgAnAhmqP+yPwNPCQD2OxQtwb2OuiMqXUKfJ1GeqOHTuyZs2aGu9rjGWo2wB7PY5T3eeOEJGBQFtjzKcneiERuUNEUkQkJTMz89Qj0g3slVLqOH6bNSQiAcCzwK/reqwx5hVjzCBjzKD4+PhTf1PdnEYppY7jy0SwD2jrcZzkPlclCugNfCMiu4BzgE98OmCsiUCpRs8Y4+8Qzmin8vfjy0SwHOgiIh1ExAVMAj6putMYk2eMaWGMSTbGJANLgfHGmJSaX64euHQDe6Uas9DQUA4ePKjJoBbGGA4ePFjjIrUT8dlgsTGmXETuAb4AAoE3jDHrReQJIMUY88mJX8EHNBEo1aglJSWRmprKaY0VNnGhoaHHzGryhk9XVRlj5gHzqp37Qy2PHenLWADtGlKqkQsODqZDhw7+DqPJcViJCU0ESilVnbMSwZEN7LVrSCmlqjgrEYDdnEYXlCml1BHOSwRailoppY7hwESgpaiVUsqTAxOBtgiUUsqTAxOBtgiUUsqTAxOBtgiUUsqTAxOBtgiUUsqTAxOBtgiUUsqTMxOBriNQSqkjnJcIQqKgogQqyvwdiVJKnRGclwi03pBSSh1DE4FSSjmcAxNB1Z4EmgiUUgocnQjy/RuHUkqdIRyYCLRrSCmlPGkiUEoph3NgItAxAqWU8uS8RBDiTgQlOkaglFLgxESgXUNKKXUM5yWCYE0ESinlyXmJIDAIgkK1AqlSSrk5LxGAViBVSikPDk0EuieBUkpVcXAi0BaBUkqBYxNBhLYIlFLKzcGJQFsESikFTk0EIZG6S5lSSrk5MxHoGIFSSh3h0ESgYwRKKVXFwYlAWwRKKQWOTQS6gb1SSlVxaCKoqjek3UNKKeWYRPD99iwen7OeykqjFUiVUsqDYxLBhv2HeHPJLg4Vl2kiUEopDz5NBCIyVkQ2i8g2EXmkhvvvFJF1IrJaRBaLSE9fxRIX6QIgu7DUY5cy7RpSSimvEoGIBJ7sC7ufMw0YB/QErq/hg36GMaaPMaY/8Bfg2ZN9H2/FRoQA7kRwZJcyTQRKKeVti2CriPz1JL+xDwG2GWN2GGNKgVnABM8HGGMOeRxGAOYkXv+kxIbbFsHBwlLtGlJKKQ/eJoJ+wBbgNRFZKiJ3iEizOp7TBtjrcZzqPncMEblbRLZjWwT31vRC7vdLEZGUzMxML0M+Vqy7ayjnmK4hTQRKKeVVIjDG5BtjXjXGDAUeBv4XSBOR6SLS+XQCMMZMM8Z0cr/u72t5zCvGmEHGmEHx8fGn9D41twi0a0gppbweIxCR8SLyIfAc8AzQEZgDzKvlafuAth7HSe5ztZkFXOFNPKcizBVIWHBgtRaBJgKllAry8nFbgYXAX40x33ucf19EhtfynOVAFxHpgE0Ak4AbPB8gIl2MMVvdh5e638dnYiNc7llDOkaglFJVvE0EfY0xNX59NsbU2K9vjCkXkXuAL4BA4A1jzHoReQJIMcZ8AtwjIhcBZUAOcMtJX8FJiIt02a6hgEAICtMWgVJK4X0iSBCRmcC5QCXwA/ArY8yOEz3JGDOPal1Hxpg/ePx838mFe3piwl3kFJXaAy08p5RSgPezhmYAs4GWQGvgPWCmr4LylbgIFwcLPBKBriNQSimvE0G4MeZtY0y5+887QKgvA/OFI2MEACFR2iJQSim87xr6zF0iYhZ20dd1wDwRiQUwxmT7KL56FRPh4nBZBYdLKwjTzWmUUgrwPhFc676dWu38JGxi6FhvEflQXIS73lBRKW1cEVB8qI5nKKVU0+dVIjDGdPB1IA0htioRFLgTwaE0P0eklFL+51UiEJFg4C6gas3AN8DLxphGtcVXrEeLAFeUdg0ppRTedw29BAQDL7qPb3Kfu90XQfnKkURQWKIb2CullJu3iWCwMaafx/ECEVnji4B8Kc5divpgQamuI1BKKTdvp49WiEinqgMR6QhU+CYk34kKDSIwQOyiMlckVJRCeam/w1JKKb/ytkXwILBQRHYAArQHfuazqHwkIECICXevJWjuUXguKNa/gSmllB/VmQjcO431A7oA3dynNxtjSnwZmK/ERgQf7RoC2z0UrolAKeVcdXYNGWMqgOuNMSXGmLXuP40yCYAdMLZdQ1qBVCmlwPuuoSUi8k/gXeDIJ6cxZqVPovKhuIgQNh44pLuUKaWUm7eJoL/79gmPcwa4sF6jaQAxEcHV9iTQKaRKKWfzNhFMqV5y2j1zqNGJjQgh73AZ5UER9uI1ESilHM7b6aPv13DuvfoMpKHERbgwBg5V2jUF2jWklHK6E7YIRKQ70AtoLiJXetzVjEZYhhpsBVKA3PJgYkFbBEopx6ura6gbcBkQDVzucT4f+LmPYvKpqgqkB0uDbclUbREopRzuhInAGPMx8LGInGuM+aGBYvKpqnpDmaXuS9ddypRSDuftYPE2EfkdkOz5HGPMbb4IypeOViCtgOBw7RpSSjmet4ngY2AR8DWNsMaQp5jwqgqkWnhOKaXA+0QQbox52KeRNBBXUABRoUGaCJRSys3b6aNzReQSn0bSgI5sYq+b0yillNeJ4D5sMjgsIodEJF9EGu2Gv0cTgW5Oo5RS3u5ZHOXrQBpSXISLfbnFEBsBxbn+DkcppfzqhC0CEbnR4+dh1e67x1dB+VpMuIscHSNQSimg7q6hBzx+fqHafY1u6miV2EjbNWQ0ESilVJ2JQGr5uabjRiMuwkVpRSVlgRFQku/vcJRSyq/qSgSmlp9rOm40qtYSHJZQbREopRyvrsHi7iKyFvvtv5P7Z9zHjbIMNUBcpE0EhSaU5pVldgP7IJefo1JKKf+oKxH0aJAoGlhVi6DAVJWi1g3slVLOVVfRud3Vz4nIZcaYub4LyffiImwCyKvwSAS6gb1SyqG8XVDm6Ym6H3Jmi3V3DeVWuLuDdJxAKeVgp5IIGu1soSoRrkBcgQHklGkiUEqpU0kEU+s9igYmIsRGuMiq2pNAy0wopRzMq0QgIteISFWZiYtF5AMRGejDuHwuNsJFZkmwPdDNaZRSDuZti+BRY0y+iJwHXAi8Drzku7B8LzbCRXpJVYtAu4aUUs7lbSKo2ozmUuBVY8ynQJ0T70VkrIhsFpFtIvJIDfc/ICIbRGStiMwXkfbeh356YiNcpB0OtAfaNaSUcjBvE8E+EXkZuA6YJyIhdT1XRAKBacA4oCdwvYj0rPawVcAgY0xf4H3gLycT/OmIjXCxv6gqEWiLQCnlXN4mgmuBL4CLjTG5QCzwUB3PGQJsM8bsMMaUArOACZ4PMMYsNMYUuQ+XAkneBn66YiNcZJRoIlBKKW8TQSvgU2PMVhEZCVwD/FjHc9oAez2OU93najMF+KymO0TkDhFJEZGUzMxML0M+sdgIF4YAKnUDe6WUw3mbCP4LVIhIZ+AVoC0wo76CcO97MAj4a033G2NeMcYMMsYMio+Pr5f3jIuwQxyVQbpLmVLK2bxNBJXGmHLgSuAFY8xD2FbCiezDJowqSe5zxxCRi4D/AcYbY0q8jOe0xbgTQVlgmHYNKaUczdtEUCYi1wM3A1V1hoLreM5yoIuIdBARFzAJ+MTzASIyAHgZmwQyvA/79FW1CEoDwzURKKUczdtE8DPgXOBJY8xOEekAvH2iJ7hbEPdgB5k3ArONMetF5AkRGe9+2F+BSOA9EVktIp/U8nL1LtadCIolTDenUUo5mreb128QkQeBriLSG9hsjHnai+fNA+ZVO/cHj58vOsl46010uAsRKEI3p1FKOZtXicA9U2g6sAtbdK6tiNxijPnOZ5H5WGCAEB0WTKEJgdJsf4ejlFJ+41UiAJ4BxhhjNgOISFdgJnCWrwJrCLERLvIrQ7RFoJRyNG/HCIKrkgCAMWYLdQ8Wn/FiI1zkVoZAqY4RKKWcy9sWwQoReQ14x308GUjxTUgNJzbCRW6OC8oKwRiQRr/VglJKnTRvE8GdwN3Ave7jRcCLPomoAcVGhJBdFgyV5VBRCkEh/g5JKaUaXJ2JwF08bo0xpjvwrO9DajixEcEcLHXZv4XSQk0ESilHqnOMwBhTAWwWkXYNEE+Dio0IId94bGCvlFIO5G3XUAywXkR+BI5MsTHGjK/9KWe+2IhgCk2oPdBdypRSDnXCROAuMpcIPFrtrvOBNF8F1VBiI0LsgjLQKaRKKceqq2voOeCQMeZbzz/Ax8AVvg7O1+IiXGSa5vYgb++JH6yUUk1UXYkg0RizrvpJ97lkn0TUgGIiXGw2bSkPDIO9y/wdjlJK+UVdiSD6BPeF1WMcfhEX4aKcIA5E9YY9P/g7HKWU8ou6EkGKiPy8+kkRuR1Y4ZuQGk5ocCDhrkB2hPWBA+u0CqlSypHqmjV0P/ChiEzm6Af/IMAFTPRhXA0mJtzFhqCeDDeVkLocOl3o75CUUqpBnTARGGPSgaEicgHQ2336U2PMAp9H1kDiIl2sMl1AAmDPUk0ESinH8XY/goXAQh/H4hexES72FwCJOk6glHImb6uPNlmx4S6yC0uh3bmQmgIVZf4OSSmlGpQmgoiqRHAOlBXBgbX+DkkppRqUJoJIF4fLKjjcarA9sWepfwNSSqkGpokg3G5inx3YAqLb6ziBUspxNBFEuBNBgXucYM9Su0mNUko5hOMTQbu4cAA2pOXZcYLCTMje4eeolFKq4Tg+EXRLjCIpJozPfjpgWwSg3UNKKUdxfCIQEcb1bsmSbVnkRXaA0GgdMFZKOYrjEwHAuD6tKKswLNicabuHNBEopRxEEwHQPymals1CmbfugE0EB7dCYZa/w1JKqQahiQAICBDG9m7Jd1syOdxqiD2prQKllENoInAb17slJeWVLDzUBgJDdMBYKeUYmgjcBiXH0iLSxacbs6HNQG0RKKUcQxOBW2CAMKZXSxZuyqA86WxIWw2lRf4OSymlfE4TgYdLereiqLSCNQE9oLIc9jX6TdiUUqpOmgg8nN0xlujwYP6b0cae0O4hpZQDaCLwEBwYwOgeiczZXERlfHcdMFZKOYImgmou6dOK/JJy0pr1h70/QmWFv0NSSimf0kRQzdDOcUSFBPFdSWcozYf09f4OSSmlfEoTQTUhQYGM6pHA2/ta2RNbv/RvQEop5WM+TQQiMlZENovINhF5pIb7h4vIShEpF5GrfRnLyRjXpxUbDseQ3XokLHoGsnf6OySllPIZnyUCEQkEpgHjgJ7A9SLSs9rD9gC3AjN8FcepGNE1nnBXIK81/yVIIHzyS92sRinVZPmyRTAE2GaM2WGMKQVmARM8H2CM2WWMWQtU+jCOkxYaHMgF3RKYvdVQOfqPsGsRrHjL32EppZRP+DIRtAH2ehynus+dNBG5Q0RSRCQlMzOzXoKry7g+LckqKOWjgIuo7DACvnwUcvfW/USllGpkGsVgsTHmFWPMIGPMoPj4+AZ5zwu6JZDYLIQH3lvLZTuvoaSsjPSZd5FXVNog76+UUg3Fl4lgH9DW4zjJfa5RiAgJ4usHRvDi5IH06NmX57iBxPRF/OnPj3L9K0v5z7LdFJWW+ztMpZQ6bWJ8NAgqIkHAFmAUNgEsB24wxhw3MV9E3gLmGmPer+t1Bw0aZFJSUuo52rpVVFRQ9MoYgrM2c0vYCyzLctEsNIhJQ9px0zntaRsb3uAxKaWUt0RkhTFmUE33+axFYIwpB+4BvgA2ArONMetF5AkRGe8ObLCIpALXAC+LyBm7eiswMJCoa14mVMqY1WY27089h/O7xvP64p2M+OtC7vh3Ct9vz8JXiVUppXzFZy0CX/FXi+CIJc/DV4/Cpc/AoCmkHSrmnaW7mbFsDzlFZZzVPoZXbx5EbITr2OdVVkBAoH9iVko5nl9aBE3WuXdD+/Pg01/DW5fRqnAzD13cnR9+O4onJ/bmp315XPfyD2QcKrZrD3YugumXw9PJkLHR39GfGSrKYM59cGCdvyNRSqGJ4OQFBMLNH9sWQeZGeGUkfHgXoYfTmXx2e9782WD25Rbx9LQXKXl1DEy/DDI3Q0AQfPBzKD866yj9UDFvLtnJrqxC/12PP2z90q7LWPx3f0eilEK7hk5PcZ4tQbH0JbsCedi90KofhV8/TUTWGtKJI/D8X9Fi+O2wfSHMuh6G3U/xyD/w6nc7eOnb7RSVVuAKDOC28zpwz4WdiQwJ8vdV+d6sybBpLgSFwoNbIbSZvyOyvnkawmNhyM/9HYlS9e5EXUOaCOpDzi74+nFY/4E9jm7H/j53ceWSZMoDXLxz+xC6t2yG+fiXsOpt7nb9kXmHOnJxr0TuGN6JGcv28N+VqcRHhfDw2O5cOaANAQHi10vymaJs+FtXSBpk93uYMA0G3OjvqKDwIDzTFUKawa83Q5Cr7uco1YhoImgoqSvg0D7oNg4Cg9mWUcDk15ZSXFbJo5f15IMfNvHnjF8QFmTYfc1XDOmRfOSpq/bk8NicDazZm0u/ttE8dnlPBrSL8d+1+MqyV+Czh2DqInjvVmjWGm6d6++ojsYFMGkmdL/Ev/E0NfN+A3Gd4Oyp/o7EsXSwuKEknQU9x0NgMACdEyJ5b+pQmoUF8eB7a9iaB9vPe4YEk8WQTU8f89QB7WL48K6hPHNNP/bnHmbii9/z0HtryC5sYiuZ18yAxD7Qqi/0vc7WcToTSnesmQkJvSC8Bax919/RNC2Hc2H5a7D4Oag8o8qKKTdNBD7WLi6c/945lCcn9mbhgyMZNeZy5PwH7Qfiho+PeWxAgHDVWUksfHAkU0d05MNV+xj1zDfMTtnbNNYnZGyC/aug//X2uO+19nbdbP/FBJC5BfavhP43QO+rYPNn9sNL1Y9di8BUQP5++++vzjiaCBpAQrNQJp/d/uhA8IjfQOsBdgrlobTjHh8ZEsRvx/Vg7r3n0Sk+kt+8v5brXlnK1vT8Bo68nq2ZYQfV+1xjj2M7QLtzYc27/i3zvXYWSICNq+91UFECGz/xXzxNzbb5EBxhZ85t/Ljux6sG54ApKmegwGC48lX41/nw0V1w9p2Quwdyd9uB59w9kLeX7q4o3otpz84u8cxLdTHthRac1W8AV48bQ1jk6c20Scs7zMxle0iKCef8ri1o1Tysfq6tNpUVsHY2dBkNkQlHz/e9DubeD2mrbXJsaJWVNq5OF0JUoo0trrNNTgNvbvh4mhpjYPt86DgCyktg4xy46HGQJjoZopHSROAvLbrAmD/CvAdhx0J7LigMottBTHs7q6akAMnZRcecxdxjMuy/1nrI/SmSedFXk9/vNoZ070D3llFezzIqLqvgtUU7mLZwO4fLKo6c75IQyfld4hnetQVnd4gjzFXPq6B3LIT8NBj71LHne10Bnz0Ma2b5JxHsXgJ5e+Gix+yxiE1OC5+0YxfRbU/4dFWH7B32i83Qe22LYO79kLEBEnv5OzLlQROBPw2+3X77dEXaBBCZUPs3pdJCyN3Dto1rKF/xb67Ke4u8b2fz5oKx3OUaT5/O7RnaqQVDOsTQKT4SqfY6xhi+3JDOnz7dwN7sw1zcK5H/uaQnRWXlfLclk0Vbs3hn2W7eWLITV2AAd47sxK8u6nLc69SmvKKSoMAT9DSungmh0XZGlaewGOg2Fta9D2P+dGSgvcGsmQWuKOh2CcYYe719r7WJYN1sOP/XDRtPU7N9gb3tdCGERMHcX9lWgSaCM4omAn8SgU4XePdYVwQk9KBzQg8YMQn2ryZk/lPcv/0DpvIFM7aN4y9rR5NLFLERLga1j2FIh1gGJ8cSEhzAk59uZNHWLLomRvKf289mWOcWR166e8tm3DG8E8VlFfy4M5t3U/by/PytlFdU8tDF3U6YDErKK3j4/bV8vv4A4/u15oaz29MvqfmxzynOswvI+k+GoJDjX6TvJDtwvn0BdL3Y27+901daZN+35wSKcHHLyz/QIjKEf94wkMCqsYvzHtBujNOxfQFEt4fYjvbvsf1QmwhGHreFufIjTQSNVev+hN40Cw6sI+y7vzJlw/vc2uwLfup4O//hUpbuyefLDelHHt4sNIjHLu/Jjee0r/Wbe2hwIMO7xnNe5xY0Cw3mxW+2IwIPjqk5GeQWlXLH2yv4cWc2F3ZPYO7aNGanpNKrdTMmn92eCf1bExESBOs/gvJiOyunJp0vgrBY++28IRPB5nlQmk9l3+t44N01LN+VA8DfvtzMw32vtd9e09ZA6/4NF1NTUl4KO7+zLayq358el8Pnj8DB7XZdgTojaCJo7Fr2gWv/DekbCPz6Mfpt+jv9oj+AS58gPelilu/OYX/uYa4amERcZA3fxmsQECA8eUVvwDBt4XYE4ddjuh6TDPYcLOLWt34kNfsw/5jUnwn925BfXMZHq/fzn6W7+d2H6/jzvI1M6N+a3x14m/C4Lkibs2p+wyAX9LkaVky3rYfQ5vXwF+OFNbOgeVv+trkFn6/fye8v7cH2zEJe+mY7/a8+l4sDXXZNgSaCU5O6HEoLbLdQle6X2USwcQ6cd7/fQlPH0umjTUViT5g8G2760I45vHcLif+dyGVxB7hjeCevk0AVmwz6MGlwW/65cBvPfrXlyFqG1XtzufKlJRwsKOXtKUOY0N9uRR0VGsxN57Tns/vO54NfDOXiXi1ZtiKFiPTlvFV4Lm99v4vc2rb67DvJTtvc0EDTC/PTYft8NsWP48Vvd3L9kLZMOa8Dj4/vxVntY7j/490canuhHbuoqJ+d6LZnFnDx37/j7v+sZH/u4Xp5zTPa9gV2unCH4UfPRbe1kwI2zqnXtyosKefmN37ktUU7msaamwamLYKmptOFcOciWPlvO+D56gXQ51o49xcnPSsnIED488Q+ALywYBsC9G7TnHtnrSI+KoRZtw6hc0Lkcc8TEQa2i2FguxiKoz/BfC98E3oh387ZwJ8/28TFvVpy9VlJRIcFk1NUSm5RGbmFMYwPbcehBW8w88BgEpqFkhAVQmKzUBKbhZAQFVq/M5nWvQemkvs2dmVopziemNAbEcEVJLx040Auf2ExT+3vx59LP4cd30CXi07r7VbuyWHKW8sxwK6DhSzcnMG9o7pw27AOuIKa6Pex7fMhafDxLbwel8P8JyBvHzRvUy9v9ce5G/huSybfbcnkQF4xv7ukR9Ot1+UDmgiaooBAGPQzu0p28bOw9F92BkzLvnDWLXbhlJfdLwEBwp+v6EVc8R52fTOdUjnIY80DGN8zmvDl86DsMJQV2Qc3a+3xpw1EtSJ0w2zoOJLpN09k/f48Zi/fy0er9zNnzf7j3isr8GweDH6PL5YsZ1dF3HH3x4QH0zE+kk7xEXSMj6RjC3vbPi6c4BPNWKpB6cqZbKEzpTFdeHHywGOenxAVyss3DWLyv4r4nSuS8DWzCDiNRPDVhnR+OXMlic1C+fdtQwgQ4fE5G3jqs028vyKVJyb0YminFnW/UGNSeBD2r4aRvz3+vh7jbSLY9Cmcfcdpv9VXG9KZtXwvU0d0pKSsktcW7+RgYSl/ubrvSf9eOJUWnXOCw7n2G/DK6XYzmKAw6DXRVv1s1souqjIVdtGXqYTKcji4zZYD2L/aDpiWVlvVHBQGwWEQHA7BofZ5h9KgvIYujytfPVpOAruWYcm2LIyB6PBgosNdxIQH07wkjaAX+mF6XUn+ub8hLSiJ9EPFZOSXkH6omNScIrZnFrIjs5CsgpIjrxccKHRJiKJn62b0bNWMnq2b0cuVTtSGGZDQEzqPhsj4I48v2LOGyDeG8xS3ce3df6Rj/PGtGoDZKXsp++g+rnEtwfXwdgg5+jhjDJkFJRw6XEbHFpG1fvucsWwPv/9oHb3bNOeNWwfTwqOLbv7GdB6bs5692YcZ3681v7ukBy2bh57gH/LIm8PWr2DrF3Dh7+0UXB/IOFTM0p3ZdE2MpHN85ImnB1e37n347xS4fb5dE1PdtHMw4XE80/pZ9uYU8der+51Syygjv5ixzy2iVfNQPvzFMIIDhWkLt/G3L7cwsls8L04eSLir5u+7JeUV5BeXH/Nv0pRp9VFlGWM/3FdOt/9RSwtO/PjAEDsY3bq/7VZqPQBiOtgEUNOUSmOgOBcO7Xf/2WdbDINv9359wLzfwPJXbWJJGgz9JkGvK+0+AR7yDpexI7OAHZmFbMnIZ2NaPhv255FfUMDdQR8xNXAuIWL79isRdgR3ZW342WyKGkq3zC8YX/wJq675gSG9u50wnNdnzGTKljuZ1/kxNiVcwo6sQnYdLGRnZiGFpXZBXotIF8O7xnNBtwSGd4mneXgwxhj+/vVWnp+/lZHd4pl2w0A7g6qa4rIKXvpmOy99ux2A6we3ZeqITrSOrmWl9+7v7bfpPT/Y426XwKQZIIIxhuzCUrIKSomNcNEi0uX1OpDqvtuSyf3vrj5S9DAsOJBerZvRNymavknN6d2mOW1jwwgJqqW77qO7YdMc+M3OGrdorfj6T8jiZxhU/CLZNOOas5L4y9V9TypeYwy3vbWc77cfZO4vz6NLYtSR+2b+uIf/+XAd/dpG8+atg4kOt2XF84rKWLg5g682pPPN5gwKSytoEx3GgHbRDGgXw8B20fRq3bxJdtdpIlDHKymAbV/bD2oJsP9Zj9wG2gVuCT0afoEX2JbFuvdsRdCMDRDostNKe10JHUZAxPHdRgBs/YqKub8mMG83mxMvYUbU7QQfTqdHwVL6FC2jc9lmArC/72mJI2l1V90D02XlFWT/X0+yykL4R8VV7Gs+kBYtEunQIoIOLSIIcwWyZFsW327JJLeojACBge1iiA4P5uuNGVxzVhJ/vrJPnV0Uew4WMW3hNv67MhURuPqsJO4a0Zl2ceH2AWlrbALY9jXl4Yms6zyVrOwcRqe+wL8jp/BKxWVkHCqhtOJodc+w4ECSYsJoFxtO29hwkmLCOK9LC7q3rL08SUWl4bmvt/DPhdvomhDFY+N7kX6omDWpuaxLzeOn/XkUl9n3EIGEqBCSYuxrt4kOo21sOKO6x5Pw6kBoO9jOaKumsKSc/3tzNn86cBcLuz3KqrjLeX7BNh4e2527Rno/pfSdpbv5/Uc/8b+X9+Rnwzocd//nPx3g3lmraBcbzg1D2rFgUwZLdxykvNIQHxXC6J6JJMeFsyY1j1W7c9ifVwyAKyiAAW2j+cUFnRnepcUpJ9MzjSYC1TgZAwfW2mme696Dwkx7PrG3nYmSfL5doFRa6J6S+Am06Gq3EfWcqVKlINMOYO5aBIOmQJuBXoVRufId+PTXBFQUAwIte9v3Tj7PxpKfRuXBHRzYvZG81C1I7i6al2VQ2SyJ1l3PQhJ62lldCT2Pa9lUty/3MP/6ZjvvLt9LhTFM7VHGzSUzaJn6OQUBUbxqJvDy4VEUE0JosPCvkH9yfvkPTGv3dwpbnU3LZqHERYaQXVDC3pzD7MkuYq/7T1UL5pyOsdw6tAMX9Ug4prsn41Ax985axdId2Vw7KInHx/c+boC+vKKSbZkFrN93iL05RezLOUxqzmFSc4tIyy2mvNLQO3gfcwMfomDMs0QOnXLM87MLS/nZW8tZl5rD2ujfEJnUC3PDbO6dtZo5a/bzrxsHMrZ3qzr/TXZkFnDp84sZlBzD9J8NqbVrbumOg/x8egr5JeV0io9gTK+WjOmZSL+k6OOecyCvmJV7cli1J4fPfjpAas5hhnaK4+Gx3enXNrrOmKqrqDSsTc0lMiTomNaKv2giUI1fRbktFb3zW9i5CPYus4vUJAACgu3X0+EP2Zo2vthdrLwE9q2AXYttItn7o33/Ywg0bwuxyVRGtSIgLxXS19vusiqRLaHzKBhwE7Q7p9ZVywe3LCVz3p/pnvsthSaE1ysuYWHsdXRt14YB7aLp3y6aLglRBJbm232zSwvtbDHPgn4ejDFk5pfwwap9vP3DbvblHqZNdBg3ndueSYPbsn7/Ie6btZqCkjL+dEUfrj4r6eT/iioq2Z5ZyMYP/o8rMqYxqnIaY4cN4ufndyQ63EVqThE3v/Ej+3IO888bBjJ67/Pw4yvw0DaKAyO5/tWlbEw7xOyp59I3KbrW9ymrqOTql75n18Eivrh/eJ3jKlkFJeQXl9OhRYTX11JaXsmMZbt5fsE2sgtLubRPKx68uFudr1FUWs6irVnM35jOgk0ZZBWUIgJXDkjioYu7eTcG5COaCFTTU1YM+1LsytXCLLtfdExyA7//CsjaDM2SbEnt6HbHl9AwBvIPQMZ6yNhou3g2f2bHZ+I62wH7ftdDVEv72N1L7D7Y2xdAaHOK+k9hU/vJdOnQnqjQWrrpDvwEr42CtkPgpo9q7JP3VF5RydcbM3jr+50s3ZFNSFAApRWVdIqP5MXJA+l6ut9e37mK0qxdPJDwKp+uSyPCFcTkc9rx8ar9FJaW8/otgxnSIdYm09dHw5WvQd9ryMwvYeKLSygpr+TjX5xL62auGrsmn/1qC8/P38q0GwZyad+6Ww+nI7+4jFcX7eS1RTsoKa/k2kFJdHJPLjAGDAZjoLzSsGJ3Dou3ZVFaXklUaBAXdEtgVI8ENqbl88binQQEwNThnZg6omOtA9i+pIlAqTNJSYFdOLfqbTvoK4HQZQwczoG9SyEiHs6923ZfhXpZbnzVO/Dx3TD8N3Dh/3gdyqYDh3hn6W5CgwJ5YEzX0/+AKiuGp5PtNOVxT7PpwCH+8fVWPvvpAAlRIfx7ypCjYxSVlfBsDzvrKbEXFGZSkpdO/sE0YiSfAFc4Mv4FsjtcRsqubFJ257B8Vzar9+YysX8bnr2u/+nFehIy80t4YcFWZizbQ3llzZ+ZbWPDuKhHIqN7JDK4Q+wx40J7s4t46vNNfLo2jYSoEB66uBtXDUzicFkFO90TEHZlFbIzq4icolKGdW7BJX1a1mt5eE0ESp2psrbaD/E1M+2g+NB7YeBNdmbWyfroblj9Dkz+77EL4EryIWe3Lbcd3d5OAvDVAOj2hfD2FXDD7GPqRm3LKKB5WDDxUdVaTN88DT/8E8LjbAKMiGd/eSQfbilhpGszvSo28q/yy/lL+XUEBQbRN6k553SM486RnY5u9NSAissqKCmvRAQEu3jS3trB+boGllfszuaJuRtZszeXqJAg8kuOXbXeslko4SGB7MgsBGBwcgyX9W3NuD4tSYg6vW4lTQRKnemMOf0P59IieO0iu+9DpwvsJkc5u6Do4LGPa9EVel5h15KcKClUTQcuyITCDChw/ynMsK2ahO7QZpAdBA90fyh/+SgsfQke2W0r5p6imT/u4fkv1/Nk2H+4MH8Oea3PI+S6twhtHl/3kz2V5MOSf9g1MkPusOtm/Kyy0jBn7X6W7jhIUkw4HVpEkBwXQXKL8CMtsh2ZBXy6No25a9PYnJ6PCExMKuTK0SM5r2vN40B10USglFNkbYOZk+yiwJhku8lRTLJtCTRvCwfW2Gqwu5fYtRpVSSG+m20x5O513+6xP5cVHv8eEmhbLFXrUILC7FqTNmfZ1cLNk+DWufV3TSv/DZ/+GqJawaT/2LUt3tg4F+Y9ZBOjiN0Yp+91MOw+uzFUdZWVdtxn0xzI3GwTZa8rfTP54CRsTc9n51cvM3Lb/7Gj30N0n3hqJbw1ESiljlWQYafbeiYFsP31zdvage/odrZUSGSiXZkdkWBnJYXF2g/WnF32gzM1xQ7cp621hQPHPAlD76nfeFNXwLs32nGU8S/YarW1tWTyUu3CxM2f2um9lz0HES1sF9Sqd+wMsB6XwXm/smVXdi2ySWPzPJs0AoLsNR/aZ28HTYFBtx2zOr3BlJfCF7+F5a9hOozAXPUmAZG1rKOpgyYCpVTtCjLtGo3otnYXsVNVXgrZ2+1sKF8sRCzIgNm3wJ7vbTKqWu3eZqC9jUy001EX/Ml2BV3wWzjnF8fGUpAJy/5lV68X50FwhG31BIfbab3dL4euYyCkOexYYOt0bfvKjt/0vhrOuRNa9av/a6v1em+2EwqG/hJGPXa0C+4UaCJQSjUNFWV2gWHqj7BvlV15btx7b1d9qHceDZf+7cTTiYsP2VIrB7dDl9HQ8QJwhdf82KytsOxlWD3Dvn6rfrZseu+rICrR+9gLs2zra9cSe1uYad+321hbNdizEGRqCrx7k20BTfinbQGdJk0ESqmmqbQI0n+CfSvtWo1OF9oxD1/Mijqca5PQmpmQttouZux4ga2H1f1SOzheUW4/4AsO2D0vCg7YQo+7lkDmRvs6weF2zUd4nF0vcjjHdke1Hwpdx9qfv/y9XVsyaYb3YyJ10ESglFL1KXOz3b1u7XuQt8d+uLsi7Ld+qn2muiKh7dmQPMyWJmnV/+gAdEW53clty+ew5YujyaLjSLj6zTpLkpwMTQRKKeULlZV2EeBPH9iB8siWtrsosqX9Rh+ZaGc7edu3n7PLloDvMPK0xgNqcqJEoBvTKKXUqQoIsF067YfWz+vFJDdsqRS3pld0Wyml1EnRRKCUUg7n00QgImNFZLOIbBOR45bDiUiIiLzrvn+ZiCT7Mh6llFLH81kiEJFAYBowDugJXC8iPas9bAqQY4zpDPwdeNpX8SillKqZL1sEQ4BtxpgdxphSYBYwodpjJgDT3T+/D4ySprIvnFJKNRK+TARtgL0ex6nuczU+xhhTDuQBxxXSEJE7RCRFRFIyMzN9FK5SSjlToxgsNsa8YowZZIwZFB/vh8JPSinVhPkyEewD2nocJ7nP1fgYEQkCmgPViqcrpZTyJV8uKFsOdBGRDtgP/EnADdUe8wlwC/ADcDWwwNSx1HnFihVZIrL7FGNqAWSd4nMbM6deNzj32vW6ncWb625f2x0+SwTGmHIRuQf4AggE3jDGrBeRJ4AUY8wnwOvA2yKyDcjGJou6XveU+4ZEJKW2JdZNmVOvG5x77XrdznK61+3TEhPGmHnAvGrn/uDxczFwjS9jUEopdWKNYrBYKaWU7zgtEbzi7wD8xKnXDc69dr1uZzmt6250ZaiVUkrVL6e1CJRSSlWjiUAppRzOMYmgrkqoTYWIvCEiGSLyk8e5WBH5SkS2um9j/BmjL4hIWxFZKCIbRGS9iNznPt+kr11EQkXkRxFZ477ux93nO7gr+m5zV/h1+TtWXxCRQBFZJSJz3cdN/rpFZJeIrBOR1SKS4j53Wr/njkgEXlZCbSreAsZWO/cIMN8Y0wWY7z5uasqBXxtjegLnAHe7/42b+rWXABcaY/oB/YGxInIOtpLv392VfXOwlX6bovuAjR7HTrnuC4wx/T3WDpzW77kjEgHeVUJtEowx32EX53nyrPI6HbiiIWNqCMaYNGPMSvfP+dgPhzY08Ws3VoH7MNj9xwAXYiv6QhO8bgARSQIuBV5zHwsOuO5anNbvuVMSgTeVUJuyRGNMmvvnA0CiP4PxNfcGRwOAZTjg2t3dI6uBDOArYDuQ667oC0339/054DdApfs4DmdctwG+FJEVInKH+9xp/Z7r5vUOY4wxItJk5wyLSCTwX+B+Y8whz+0tmuq1G2MqgP4iEg18CHT3b0S+JyKXARnGmBUiMtLP4TS084wx+0QkAfhKRDZ53nkqv+dOaRF4Uwm1KUsXkVYA7tsMP8fjEyISjE0C/zHGfOA+7YhrBzDG5AILgXOBaHdFX2iav+/DgPEisgvb1Xsh8A+a/nVjjNnnvs3AJv4hnObvuVMSwZFKqO5ZBJOwlU+doqrKK+7bj/0Yi0+4+4dfBzYaY571uKtJX7uIxLtbAohIGDAaOz6yEFvRF5rgdRtjfmuMSTLGJGP/Py8wxkymiV+3iESISFTVz8AY4CdO8/fcMSuLReQSbJ9iVSXUJ/0bkW+IyExgJLYsbTrwv8BHwGygHbAbuNYYU31AuVETkfOARcA6jvYZ/w47TtBkr11E+mIHBwOxX+xmG2OeEJGO2G/KscAq4EZjTIn/IvUdd9fQg8aYy5r6dbuv70P3YRAwwxjzpIjEcRq/545JBEoppWrmlK4hpZRStdBEoJRSDqeJQCmlHE4TgVJKOZwmAqWUcjhNBEq5iUiFu6Jj1Z96K1AnIsmeFWGVOpNoiQmljjpsjOnv7yCUamjaIlCqDu76739x14D/UUQ6u88ni8gCEVkrIvNFpJ37fKKIfOjeI2CNiAx1v1SgiLzq3jfgS/dKYETkXvc+CmtFZJafLlM5mCYCpY4Kq9Y1dJ3HfXnGmD7AP7Er1AFeAKYbY/oC/wGed59/HvjWvUfAQGC9+3wXYJoxpheQC1zlPv8IMMD9Onf65tKUqp2uLFbKTUQKjDGRNZzfhd38ZYe7sN0BY0yciGQBrYwxZe7zacaYFiKSCSR5ljZwl8b+yr1xCCLyMBBsjPmTiHwOFGBLgXzksb+AUg1CWwRKecfU8vPJ8Kx5U8HRMbpLsTvoDQSWe1TPVKpBaCJQyjvXedz+4P75e2zlS4DJ2KJ3YLcKvAuObBrTvLYXFZEAoK0xZiHwMNAcOK5VopQv6TcPpY4Kc+/0VeVzY0zVFNIYEVmL/VZ/vfvcL4E3ReQhIBP4mfv8fcArIjIF+83/LiCNmgUC77iThQDPu/cVUKrB6BiBUnVwjxEMMsZk+TsWpXxBu4aUUsrhtEWglFIOpy0CpZRyOE0ESinlcJoIlFLK4TQRKKWUw2kiUEoph/t/9ADrRLde84oAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history1['loss'], label='Loss 10')\n",
    "plt.plot(history2['loss'], label='Loss 50')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Cross-Entropy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b0149e13-cd23-4ec4-8445-0916ead996b5",
   "metadata": {
    "id": "hz8bsLgmxa6j",
    "outputId": "01313d91-25f5-4143-f675-cd97e9c57c3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 1s 5ms/step - loss: 0.2013 - accuracy: 0.9522\n",
      "93/93 [==============================] - 1s 4ms/step - loss: 0.2472 - accuracy: 0.9471\n",
      "Loss 0.201301, Accuracy 0.952155\n",
      "Loss 0.247177, Accuracy 0.947065\n"
     ]
    }
   ],
   "source": [
    "test_loss_1, test_acc_1 = model1.evaluate(X_test, test_y)\n",
    "test_loss_2, test_acc_2 = model2.evaluate(X_test, test_y)\n",
    "\n",
    "print('Loss %f, Accuracy %f' % (test_loss_1, test_acc_1))\n",
    "print('Loss %f, Accuracy %f' % (test_loss_2, test_acc_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c4bdaabf-b8cf-4275-a80a-e55343e9b2ff",
   "metadata": {
    "id": "iODngAmtxa6k",
    "outputId": "b1fbfb3a-c599-4101-e0e2-939e40878638"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.41940956905327453\n",
      "F1-score [0.80769231 0.25878004 0.8185654  0.09320388 0.00375235 0.97811608]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.68      0.81       496\n",
      "           1       1.00      0.15      0.26       471\n",
      "           2       1.00      0.69      0.82       420\n",
      "           3       1.00      0.05      0.09       491\n",
      "           4       1.00      0.00      0.00       532\n",
      "           5       1.00      0.96      0.98       537\n",
      "\n",
      "   micro avg       1.00      0.42      0.59      2947\n",
      "   macro avg       1.00      0.42      0.49      2947\n",
      "weighted avg       1.00      0.42      0.49      2947\n",
      " samples avg       0.42      0.42      0.42      2947\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model1.predict(X_test).astype(int)\n",
    "\n",
    "print('Accuracy %s' % accuracy_score(test_y, y_pred))\n",
    "print('F1-score %s' % f1_score(test_y, y_pred, average=None))\n",
    "print(classification_report(test_y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "19aaf7a5-2287-420e-a1e9-0aca8f90148e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.2860536138445877\n",
      "F1-score [0.68085106 0.11576846 0.66666667 0.01214575 0.         0.78231293]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.52      0.68       496\n",
      "           1       0.97      0.06      0.12       471\n",
      "           2       1.00      0.50      0.67       420\n",
      "           3       1.00      0.01      0.01       491\n",
      "           4       0.00      0.00      0.00       532\n",
      "           5       1.00      0.64      0.78       537\n",
      "\n",
      "   micro avg       1.00      0.29      0.44      2947\n",
      "   macro avg       0.83      0.29      0.38      2947\n",
      "weighted avg       0.81      0.29      0.37      2947\n",
      " samples avg       0.29      0.29      0.29      2947\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model2.predict(X_test).astype(int)\n",
    "\n",
    "print('Accuracy %s' % accuracy_score(test_y, y_pred))\n",
    "print('F1-score %s' % f1_score(test_y, y_pred, average=None))\n",
    "print(classification_report(test_y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "41f79277-d6bf-4f09-9a5a-2924588565f9",
   "metadata": {
    "collapsed": true,
    "id": "9DbIyp0-xa6k",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "5ee386cf-e8d3-4ca2-878e-8170b7c45c45",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/700\n",
      "736/736 [==============================] - 7s 9ms/step - loss: 0.3486 - accuracy: 0.8560 - val_loss: 0.1794 - val_accuracy: 0.9325\n",
      "Epoch 2/700\n",
      "736/736 [==============================] - 6s 8ms/step - loss: 0.1304 - accuracy: 0.9497 - val_loss: 0.3065 - val_accuracy: 0.8914\n",
      "Epoch 3/700\n",
      "736/736 [==============================] - 3s 5ms/step - loss: 0.1291 - accuracy: 0.9465 - val_loss: 0.2218 - val_accuracy: 0.9332\n",
      "Epoch 4/700\n",
      "736/736 [==============================] - 5s 7ms/step - loss: 0.0960 - accuracy: 0.9608 - val_loss: 0.1846 - val_accuracy: 0.9260\n",
      "Epoch 5/700\n",
      "736/736 [==============================] - 7s 10ms/step - loss: 0.0826 - accuracy: 0.9680 - val_loss: 0.2632 - val_accuracy: 0.9152\n",
      "Epoch 6/700\n",
      "736/736 [==============================] - 8s 11ms/step - loss: 0.0732 - accuracy: 0.9710 - val_loss: 0.2050 - val_accuracy: 0.9359\n",
      "Epoch 7/700\n",
      "736/736 [==============================] - 8s 11ms/step - loss: 0.0702 - accuracy: 0.9723 - val_loss: 0.1759 - val_accuracy: 0.9427\n",
      "Epoch 8/700\n",
      "736/736 [==============================] - 10s 14ms/step - loss: 0.0694 - accuracy: 0.9724 - val_loss: 0.1566 - val_accuracy: 0.9437\n",
      "Epoch 9/700\n",
      "736/736 [==============================] - 7s 9ms/step - loss: 0.0594 - accuracy: 0.9765 - val_loss: 0.2452 - val_accuracy: 0.9325\n",
      "Epoch 10/700\n",
      "736/736 [==============================] - 7s 9ms/step - loss: 0.0694 - accuracy: 0.9713 - val_loss: 0.1604 - val_accuracy: 0.9515\n",
      "Epoch 11/700\n",
      "736/736 [==============================] - 7s 10ms/step - loss: 0.0560 - accuracy: 0.9778 - val_loss: 0.1710 - val_accuracy: 0.9518\n",
      "Epoch 12/700\n",
      "736/736 [==============================] - 7s 9ms/step - loss: 0.0523 - accuracy: 0.9771 - val_loss: 0.1669 - val_accuracy: 0.9505\n",
      "Epoch 13/700\n",
      "736/736 [==============================] - 9s 12ms/step - loss: 0.0538 - accuracy: 0.9785 - val_loss: 0.2637 - val_accuracy: 0.9192\n",
      "Epoch 14/700\n",
      "736/736 [==============================] - 5s 6ms/step - loss: 0.0608 - accuracy: 0.9770 - val_loss: 0.1421 - val_accuracy: 0.9515\n",
      "Epoch 15/700\n",
      "736/736 [==============================] - 5s 6ms/step - loss: 0.0569 - accuracy: 0.9785 - val_loss: 0.1787 - val_accuracy: 0.9437\n",
      "Epoch 16/700\n",
      "736/736 [==============================] - 4s 6ms/step - loss: 0.0656 - accuracy: 0.9755 - val_loss: 0.2060 - val_accuracy: 0.9274\n",
      "Epoch 17/700\n",
      "736/736 [==============================] - 4s 6ms/step - loss: 0.0447 - accuracy: 0.9822 - val_loss: 0.1955 - val_accuracy: 0.9430\n",
      "Epoch 18/700\n",
      "736/736 [==============================] - 4s 6ms/step - loss: 0.0448 - accuracy: 0.9826 - val_loss: 0.1526 - val_accuracy: 0.9508\n",
      "Epoch 19/700\n",
      "736/736 [==============================] - 6s 9ms/step - loss: 0.0615 - accuracy: 0.9781 - val_loss: 0.3556 - val_accuracy: 0.9016\n",
      "Epoch 20/700\n",
      "736/736 [==============================] - 5s 7ms/step - loss: 0.0461 - accuracy: 0.9814 - val_loss: 0.1647 - val_accuracy: 0.9464\n",
      "Epoch 21/700\n",
      "736/736 [==============================] - 5s 6ms/step - loss: 0.0494 - accuracy: 0.9812 - val_loss: 0.3531 - val_accuracy: 0.9145\n",
      "Epoch 22/700\n",
      "736/736 [==============================] - 5s 7ms/step - loss: 0.0498 - accuracy: 0.9829 - val_loss: 0.1964 - val_accuracy: 0.9430\n",
      "Epoch 23/700\n",
      "736/736 [==============================] - 4s 6ms/step - loss: 0.0494 - accuracy: 0.9795 - val_loss: 0.1591 - val_accuracy: 0.9498\n",
      "Epoch 24/700\n",
      "736/736 [==============================] - 5s 7ms/step - loss: 0.0393 - accuracy: 0.9845 - val_loss: 0.2084 - val_accuracy: 0.9471\n",
      "Epoch 25/700\n",
      "736/736 [==============================] - 5s 6ms/step - loss: 0.0425 - accuracy: 0.9820 - val_loss: 0.2097 - val_accuracy: 0.9454\n",
      "Epoch 26/700\n",
      "736/736 [==============================] - 4s 6ms/step - loss: 0.0395 - accuracy: 0.9849 - val_loss: 0.1573 - val_accuracy: 0.9494\n",
      "Epoch 27/700\n",
      "736/736 [==============================] - 5s 7ms/step - loss: 0.0377 - accuracy: 0.9854 - val_loss: 0.2929 - val_accuracy: 0.9345\n",
      "Epoch 28/700\n",
      "736/736 [==============================] - 7s 9ms/step - loss: 0.0611 - accuracy: 0.9780 - val_loss: 0.3201 - val_accuracy: 0.9141\n",
      "Epoch 29/700\n",
      "736/736 [==============================] - 5s 6ms/step - loss: 0.0360 - accuracy: 0.9859 - val_loss: 0.1931 - val_accuracy: 0.9454\n",
      "Epoch 30/700\n",
      "736/736 [==============================] - 6s 8ms/step - loss: 0.0424 - accuracy: 0.9833 - val_loss: 0.2026 - val_accuracy: 0.9420\n",
      "Epoch 31/700\n",
      "736/736 [==============================] - 5s 7ms/step - loss: 0.0362 - accuracy: 0.9861 - val_loss: 0.1990 - val_accuracy: 0.9488\n",
      "Epoch 32/700\n",
      "736/736 [==============================] - 5s 7ms/step - loss: 0.0316 - accuracy: 0.9868 - val_loss: 0.1778 - val_accuracy: 0.9501\n",
      "Epoch 33/700\n",
      "736/736 [==============================] - 6s 8ms/step - loss: 0.0364 - accuracy: 0.9865 - val_loss: 0.2310 - val_accuracy: 0.9444\n",
      "Epoch 34/700\n",
      "736/736 [==============================] - 6s 8ms/step - loss: 0.0331 - accuracy: 0.9865 - val_loss: 0.2701 - val_accuracy: 0.9427\n",
      "Epoch 35/700\n",
      "736/736 [==============================] - 4s 5ms/step - loss: 0.0417 - accuracy: 0.9848 - val_loss: 0.2200 - val_accuracy: 0.9467\n",
      "Epoch 36/700\n",
      "736/736 [==============================] - 7s 10ms/step - loss: 0.0416 - accuracy: 0.9844 - val_loss: 0.2166 - val_accuracy: 0.9403\n",
      "Epoch 37/700\n",
      "736/736 [==============================] - 7s 10ms/step - loss: 0.0340 - accuracy: 0.9878 - val_loss: 0.2461 - val_accuracy: 0.9379\n",
      "Epoch 38/700\n",
      "736/736 [==============================] - 6s 8ms/step - loss: 0.0317 - accuracy: 0.9872 - val_loss: 0.3897 - val_accuracy: 0.9189\n",
      "Epoch 39/700\n",
      "736/736 [==============================] - 5s 7ms/step - loss: 0.0371 - accuracy: 0.9874 - val_loss: 0.2638 - val_accuracy: 0.9379\n",
      "Epoch 40/700\n",
      "736/736 [==============================] - 5s 6ms/step - loss: 0.0293 - accuracy: 0.9882 - val_loss: 0.1770 - val_accuracy: 0.9532\n",
      "Epoch 41/700\n",
      "736/736 [==============================] - 5s 6ms/step - loss: 0.0274 - accuracy: 0.9882 - val_loss: 0.3249 - val_accuracy: 0.9386\n",
      "Epoch 42/700\n",
      "736/736 [==============================] - 8s 11ms/step - loss: 0.0355 - accuracy: 0.9857 - val_loss: 0.3017 - val_accuracy: 0.9406\n",
      "Epoch 43/700\n",
      "736/736 [==============================] - 4s 5ms/step - loss: 0.0284 - accuracy: 0.9863 - val_loss: 0.3514 - val_accuracy: 0.9396\n",
      "Epoch 44/700\n",
      "736/736 [==============================] - 3s 5ms/step - loss: 0.0362 - accuracy: 0.9876 - val_loss: 0.1910 - val_accuracy: 0.9457\n",
      "Epoch 45/700\n",
      "736/736 [==============================] - 4s 5ms/step - loss: 0.0365 - accuracy: 0.9864 - val_loss: 0.2762 - val_accuracy: 0.9420\n",
      "Epoch 46/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0256 - accuracy: 0.9895 - val_loss: 0.1864 - val_accuracy: 0.9515\n",
      "Epoch 47/700\n",
      "736/736 [==============================] - 3s 5ms/step - loss: 0.0219 - accuracy: 0.9925 - val_loss: 0.3427 - val_accuracy: 0.9355\n",
      "Epoch 48/700\n",
      "736/736 [==============================] - 3s 5ms/step - loss: 0.0284 - accuracy: 0.9886 - val_loss: 0.2451 - val_accuracy: 0.9338\n",
      "Epoch 49/700\n",
      "736/736 [==============================] - 3s 5ms/step - loss: 0.0405 - accuracy: 0.9850 - val_loss: 0.2140 - val_accuracy: 0.9494\n",
      "Epoch 50/700\n",
      "736/736 [==============================] - 4s 6ms/step - loss: 0.0238 - accuracy: 0.9901 - val_loss: 0.2199 - val_accuracy: 0.9488\n",
      "Epoch 51/700\n",
      "736/736 [==============================] - 4s 5ms/step - loss: 0.0256 - accuracy: 0.9909 - val_loss: 0.2017 - val_accuracy: 0.9508\n",
      "Epoch 52/700\n",
      "736/736 [==============================] - 4s 5ms/step - loss: 0.0396 - accuracy: 0.9852 - val_loss: 0.1807 - val_accuracy: 0.9545\n",
      "Epoch 53/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0304 - accuracy: 0.9891 - val_loss: 0.2503 - val_accuracy: 0.9430\n",
      "Epoch 54/700\n",
      "736/736 [==============================] - 4s 5ms/step - loss: 0.0265 - accuracy: 0.9894 - val_loss: 0.2911 - val_accuracy: 0.9423\n",
      "Epoch 55/700\n",
      "736/736 [==============================] - 4s 5ms/step - loss: 0.0255 - accuracy: 0.9906 - val_loss: 0.3131 - val_accuracy: 0.9386\n",
      "Epoch 56/700\n",
      "736/736 [==============================] - 4s 5ms/step - loss: 0.0211 - accuracy: 0.9912 - val_loss: 0.2764 - val_accuracy: 0.9460\n",
      "Epoch 57/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0214 - accuracy: 0.9918 - val_loss: 0.2624 - val_accuracy: 0.9430\n",
      "Epoch 58/700\n",
      "736/736 [==============================] - 5s 6ms/step - loss: 0.0320 - accuracy: 0.9895 - val_loss: 0.2493 - val_accuracy: 0.9430\n",
      "Epoch 59/700\n",
      "736/736 [==============================] - 4s 5ms/step - loss: 0.0244 - accuracy: 0.9901 - val_loss: 0.2619 - val_accuracy: 0.9505\n",
      "Epoch 60/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0212 - accuracy: 0.9920 - val_loss: 0.3447 - val_accuracy: 0.9413\n",
      "Epoch 61/700\n",
      "736/736 [==============================] - 4s 5ms/step - loss: 0.0281 - accuracy: 0.9897 - val_loss: 0.2187 - val_accuracy: 0.9501\n",
      "Epoch 62/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0213 - accuracy: 0.9912 - val_loss: 0.2693 - val_accuracy: 0.9488\n",
      "Epoch 63/700\n",
      "736/736 [==============================] - 4s 6ms/step - loss: 0.0335 - accuracy: 0.9897 - val_loss: 0.2514 - val_accuracy: 0.9488\n",
      "Epoch 64/700\n",
      "736/736 [==============================] - 3s 5ms/step - loss: 0.0226 - accuracy: 0.9920 - val_loss: 0.5474 - val_accuracy: 0.9074\n",
      "Epoch 65/700\n",
      "736/736 [==============================] - 4s 5ms/step - loss: 0.0364 - accuracy: 0.9880 - val_loss: 0.2042 - val_accuracy: 0.9528\n",
      "Epoch 66/700\n",
      "736/736 [==============================] - 3s 5ms/step - loss: 0.0200 - accuracy: 0.9914 - val_loss: 0.2657 - val_accuracy: 0.9444\n",
      "Epoch 67/700\n",
      "736/736 [==============================] - 3s 5ms/step - loss: 0.0186 - accuracy: 0.9922 - val_loss: 0.2235 - val_accuracy: 0.9545\n",
      "Epoch 68/700\n",
      "736/736 [==============================] - 4s 5ms/step - loss: 0.0238 - accuracy: 0.9905 - val_loss: 0.2010 - val_accuracy: 0.9586\n",
      "Epoch 69/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0215 - accuracy: 0.9925 - val_loss: 0.3057 - val_accuracy: 0.9460\n",
      "Epoch 70/700\n",
      "736/736 [==============================] - 4s 5ms/step - loss: 0.0201 - accuracy: 0.9936 - val_loss: 0.2803 - val_accuracy: 0.9474\n",
      "Epoch 71/700\n",
      "736/736 [==============================] - 3s 5ms/step - loss: 0.0173 - accuracy: 0.9936 - val_loss: 0.2425 - val_accuracy: 0.9525\n",
      "Epoch 72/700\n",
      "736/736 [==============================] - 3s 5ms/step - loss: 0.0167 - accuracy: 0.9931 - val_loss: 0.2178 - val_accuracy: 0.9518\n",
      "Epoch 73/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0394 - accuracy: 0.9878 - val_loss: 0.1978 - val_accuracy: 0.9539\n",
      "Epoch 74/700\n",
      "736/736 [==============================] - 4s 5ms/step - loss: 0.0164 - accuracy: 0.9944 - val_loss: 0.2422 - val_accuracy: 0.9474\n",
      "Epoch 75/700\n",
      "736/736 [==============================] - 4s 5ms/step - loss: 0.0170 - accuracy: 0.9931 - val_loss: 0.2719 - val_accuracy: 0.9491\n",
      "Epoch 76/700\n",
      "736/736 [==============================] - 5s 6ms/step - loss: 0.0247 - accuracy: 0.9917 - val_loss: 0.3711 - val_accuracy: 0.9399\n",
      "Epoch 77/700\n",
      "736/736 [==============================] - 4s 5ms/step - loss: 0.0157 - accuracy: 0.9947 - val_loss: 0.2000 - val_accuracy: 0.9566\n",
      "Epoch 78/700\n",
      "736/736 [==============================] - 3s 5ms/step - loss: 0.0139 - accuracy: 0.9946 - val_loss: 0.1886 - val_accuracy: 0.9559\n",
      "Epoch 79/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0162 - accuracy: 0.9952 - val_loss: 0.1985 - val_accuracy: 0.9525\n",
      "Epoch 80/700\n",
      "736/736 [==============================] - 4s 5ms/step - loss: 0.0191 - accuracy: 0.9927 - val_loss: 0.2198 - val_accuracy: 0.9528\n",
      "Epoch 81/700\n",
      "736/736 [==============================] - 4s 5ms/step - loss: 0.0174 - accuracy: 0.9924 - val_loss: 0.2423 - val_accuracy: 0.9545\n",
      "Epoch 82/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0217 - accuracy: 0.9914 - val_loss: 0.3023 - val_accuracy: 0.9488\n",
      "Epoch 83/700\n",
      "736/736 [==============================] - 3s 5ms/step - loss: 0.0145 - accuracy: 0.9951 - val_loss: 0.3161 - val_accuracy: 0.9491\n",
      "Epoch 84/700\n",
      "736/736 [==============================] - 2s 2ms/step - loss: 0.0140 - accuracy: 0.9946 - val_loss: 0.3629 - val_accuracy: 0.9420\n",
      "Epoch 85/700\n",
      "736/736 [==============================] - 2s 2ms/step - loss: 0.0255 - accuracy: 0.9922 - val_loss: 0.2682 - val_accuracy: 0.9484\n",
      "Epoch 86/700\n",
      "736/736 [==============================] - 2s 2ms/step - loss: 0.0143 - accuracy: 0.9947 - val_loss: 0.2955 - val_accuracy: 0.9518\n",
      "Epoch 87/700\n",
      "736/736 [==============================] - 2s 2ms/step - loss: 0.0154 - accuracy: 0.9935 - val_loss: 0.3500 - val_accuracy: 0.9444\n",
      "Epoch 88/700\n",
      "736/736 [==============================] - 2s 3ms/step - loss: 0.0131 - accuracy: 0.9942 - val_loss: 0.3260 - val_accuracy: 0.9420\n",
      "Epoch 89/700\n",
      "736/736 [==============================] - 2s 3ms/step - loss: 0.0157 - accuracy: 0.9939 - val_loss: 0.2953 - val_accuracy: 0.9532\n",
      "Epoch 90/700\n",
      "736/736 [==============================] - 2s 2ms/step - loss: 0.0125 - accuracy: 0.9955 - val_loss: 0.2872 - val_accuracy: 0.9535\n",
      "Epoch 91/700\n",
      "736/736 [==============================] - 2s 2ms/step - loss: 0.0179 - accuracy: 0.9931 - val_loss: 0.2964 - val_accuracy: 0.9501\n",
      "Epoch 92/700\n",
      "736/736 [==============================] - 2s 2ms/step - loss: 0.0243 - accuracy: 0.9922 - val_loss: 0.2829 - val_accuracy: 0.9498\n",
      "Epoch 93/700\n",
      "736/736 [==============================] - 2s 2ms/step - loss: 0.0174 - accuracy: 0.9950 - val_loss: 0.2848 - val_accuracy: 0.9505\n",
      "Epoch 94/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0137 - accuracy: 0.9959 - val_loss: 0.2559 - val_accuracy: 0.9532\n",
      "Epoch 95/700\n",
      "736/736 [==============================] - 4s 6ms/step - loss: 0.0114 - accuracy: 0.9965 - val_loss: 0.2933 - val_accuracy: 0.9522\n",
      "Epoch 96/700\n",
      "736/736 [==============================] - 6s 8ms/step - loss: 0.0093 - accuracy: 0.9961 - val_loss: 0.3342 - val_accuracy: 0.9488\n",
      "Epoch 97/700\n",
      "736/736 [==============================] - 5s 7ms/step - loss: 0.0205 - accuracy: 0.9946 - val_loss: 0.2789 - val_accuracy: 0.9484\n",
      "Epoch 98/700\n",
      "736/736 [==============================] - 2s 3ms/step - loss: 0.0130 - accuracy: 0.9956 - val_loss: 0.3629 - val_accuracy: 0.9352\n",
      "Epoch 99/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0311 - accuracy: 0.9910 - val_loss: 0.2157 - val_accuracy: 0.9572\n",
      "Epoch 100/700\n",
      "736/736 [==============================] - 2s 3ms/step - loss: 0.0098 - accuracy: 0.9970 - val_loss: 0.2961 - val_accuracy: 0.9518\n",
      "Epoch 101/700\n",
      "736/736 [==============================] - 3s 3ms/step - loss: 0.0143 - accuracy: 0.9948 - val_loss: 0.2447 - val_accuracy: 0.9528\n",
      "Epoch 102/700\n",
      "736/736 [==============================] - 3s 3ms/step - loss: 0.0138 - accuracy: 0.9950 - val_loss: 0.2568 - val_accuracy: 0.9518\n",
      "Epoch 103/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0092 - accuracy: 0.9967 - val_loss: 0.2744 - val_accuracy: 0.9498\n",
      "Epoch 104/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0158 - accuracy: 0.9942 - val_loss: 0.2523 - val_accuracy: 0.9393\n",
      "Epoch 105/700\n",
      "736/736 [==============================] - 3s 3ms/step - loss: 0.0119 - accuracy: 0.9951 - val_loss: 0.3037 - val_accuracy: 0.9525\n",
      "Epoch 106/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0415 - accuracy: 0.9905 - val_loss: 0.3574 - val_accuracy: 0.9406\n",
      "Epoch 107/700\n",
      "736/736 [==============================] - 3s 3ms/step - loss: 0.0131 - accuracy: 0.9955 - val_loss: 0.3625 - val_accuracy: 0.9460\n",
      "Epoch 108/700\n",
      "736/736 [==============================] - 3s 3ms/step - loss: 0.0099 - accuracy: 0.9956 - val_loss: 0.3485 - val_accuracy: 0.9471\n",
      "Epoch 109/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0126 - accuracy: 0.9954 - val_loss: 0.3774 - val_accuracy: 0.9454\n",
      "Epoch 110/700\n",
      "736/736 [==============================] - 3s 3ms/step - loss: 0.0111 - accuracy: 0.9956 - val_loss: 0.3439 - val_accuracy: 0.9447\n",
      "Epoch 111/700\n",
      "736/736 [==============================] - 3s 3ms/step - loss: 0.0113 - accuracy: 0.9961 - val_loss: 0.3517 - val_accuracy: 0.9484\n",
      "Epoch 112/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0089 - accuracy: 0.9970 - val_loss: 0.4340 - val_accuracy: 0.9335\n",
      "Epoch 113/700\n",
      "736/736 [==============================] - 3s 3ms/step - loss: 0.0308 - accuracy: 0.9924 - val_loss: 0.3776 - val_accuracy: 0.9416\n",
      "Epoch 114/700\n",
      "736/736 [==============================] - 3s 3ms/step - loss: 0.0093 - accuracy: 0.9974 - val_loss: 0.4438 - val_accuracy: 0.9423\n",
      "Epoch 115/700\n",
      "736/736 [==============================] - 2s 3ms/step - loss: 0.0132 - accuracy: 0.9948 - val_loss: 0.4273 - val_accuracy: 0.9389\n",
      "Epoch 116/700\n",
      "736/736 [==============================] - 3s 3ms/step - loss: 0.0120 - accuracy: 0.9956 - val_loss: 0.6858 - val_accuracy: 0.9033\n",
      "Epoch 117/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0071 - accuracy: 0.9974 - val_loss: 0.4620 - val_accuracy: 0.9410\n",
      "Epoch 118/700\n",
      "736/736 [==============================] - 3s 3ms/step - loss: 0.0138 - accuracy: 0.9955 - val_loss: 0.4458 - val_accuracy: 0.9440\n",
      "Epoch 119/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0257 - accuracy: 0.9925 - val_loss: 0.2649 - val_accuracy: 0.9535\n",
      "Epoch 120/700\n",
      "736/736 [==============================] - 3s 3ms/step - loss: 0.0049 - accuracy: 0.9986 - val_loss: 0.2959 - val_accuracy: 0.9542\n",
      "Epoch 121/700\n",
      "736/736 [==============================] - 3s 3ms/step - loss: 0.0116 - accuracy: 0.9959 - val_loss: 0.3153 - val_accuracy: 0.9498\n",
      "Epoch 122/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 0.4594 - val_accuracy: 0.9471\n",
      "Epoch 123/700\n",
      "736/736 [==============================] - 3s 3ms/step - loss: 0.0121 - accuracy: 0.9956 - val_loss: 0.3393 - val_accuracy: 0.9505\n",
      "Epoch 124/700\n",
      "736/736 [==============================] - 3s 3ms/step - loss: 0.0115 - accuracy: 0.9954 - val_loss: 0.3297 - val_accuracy: 0.9505\n",
      "Epoch 125/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0398 - accuracy: 0.9939 - val_loss: 0.2962 - val_accuracy: 0.9450\n",
      "Epoch 126/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0202 - accuracy: 0.9959 - val_loss: 0.3195 - val_accuracy: 0.9447\n",
      "Epoch 127/700\n",
      "736/736 [==============================] - 3s 3ms/step - loss: 0.0052 - accuracy: 0.9982 - val_loss: 0.3353 - val_accuracy: 0.9484\n",
      "Epoch 128/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0205 - accuracy: 0.9939 - val_loss: 0.3270 - val_accuracy: 0.9460\n",
      "Epoch 129/700\n",
      "736/736 [==============================] - 3s 3ms/step - loss: 0.0080 - accuracy: 0.9971 - val_loss: 0.2657 - val_accuracy: 0.9508\n",
      "Epoch 130/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0129 - accuracy: 0.9954 - val_loss: 0.2307 - val_accuracy: 0.9491\n",
      "Epoch 131/700\n",
      "736/736 [==============================] - 3s 3ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.3130 - val_accuracy: 0.9508\n",
      "Epoch 132/700\n",
      "736/736 [==============================] - 3s 3ms/step - loss: 0.0116 - accuracy: 0.9963 - val_loss: 0.2932 - val_accuracy: 0.9511\n",
      "Epoch 133/700\n",
      "736/736 [==============================] - 3s 3ms/step - loss: 0.0064 - accuracy: 0.9981 - val_loss: 0.2643 - val_accuracy: 0.9528\n",
      "Epoch 134/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0259 - accuracy: 0.9921 - val_loss: 0.2487 - val_accuracy: 0.9555\n",
      "Epoch 135/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0163 - accuracy: 0.9951 - val_loss: 0.4089 - val_accuracy: 0.9396\n",
      "Epoch 136/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0070 - accuracy: 0.9976 - val_loss: 0.3207 - val_accuracy: 0.9464\n",
      "Epoch 137/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0079 - accuracy: 0.9976 - val_loss: 0.3780 - val_accuracy: 0.9447\n",
      "Epoch 138/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0143 - accuracy: 0.9954 - val_loss: 0.3683 - val_accuracy: 0.9406\n",
      "Epoch 139/700\n",
      "736/736 [==============================] - 3s 3ms/step - loss: 0.0071 - accuracy: 0.9974 - val_loss: 0.3570 - val_accuracy: 0.9477\n",
      "Epoch 140/700\n",
      "736/736 [==============================] - 3s 3ms/step - loss: 0.0099 - accuracy: 0.9967 - val_loss: 0.3484 - val_accuracy: 0.9471\n",
      "Epoch 141/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0053 - accuracy: 0.9985 - val_loss: 0.3263 - val_accuracy: 0.9518\n",
      "Epoch 142/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0099 - accuracy: 0.9961 - val_loss: 0.3854 - val_accuracy: 0.9471\n",
      "Epoch 143/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0325 - accuracy: 0.9937 - val_loss: 0.3438 - val_accuracy: 0.9427\n",
      "Epoch 144/700\n",
      "736/736 [==============================] - 2s 3ms/step - loss: 0.0117 - accuracy: 0.9963 - val_loss: 0.3218 - val_accuracy: 0.9457\n",
      "Epoch 145/700\n",
      "736/736 [==============================] - 3s 5ms/step - loss: 0.0056 - accuracy: 0.9988 - val_loss: 0.4013 - val_accuracy: 0.9342\n",
      "Epoch 146/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0111 - accuracy: 0.9959 - val_loss: 0.3720 - val_accuracy: 0.9460\n",
      "Epoch 147/700\n",
      "736/736 [==============================] - 3s 3ms/step - loss: 0.0073 - accuracy: 0.9976 - val_loss: 0.3025 - val_accuracy: 0.9508\n",
      "Epoch 148/700\n",
      "736/736 [==============================] - 5s 7ms/step - loss: 0.0058 - accuracy: 0.9980 - val_loss: 0.3641 - val_accuracy: 0.9467\n",
      "Epoch 149/700\n",
      "736/736 [==============================] - 4s 6ms/step - loss: 0.0064 - accuracy: 0.9980 - val_loss: 0.4596 - val_accuracy: 0.9430\n",
      "Epoch 150/700\n",
      "736/736 [==============================] - 4s 5ms/step - loss: 0.0313 - accuracy: 0.9943 - val_loss: 0.3799 - val_accuracy: 0.9464\n",
      "Epoch 151/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0098 - accuracy: 0.9966 - val_loss: 0.3145 - val_accuracy: 0.9528\n",
      "Epoch 152/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0074 - accuracy: 0.9976 - val_loss: 0.3338 - val_accuracy: 0.9532\n",
      "Epoch 153/700\n",
      "736/736 [==============================] - 3s 3ms/step - loss: 0.0039 - accuracy: 0.9990 - val_loss: 0.4193 - val_accuracy: 0.9464\n",
      "Epoch 154/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0229 - accuracy: 0.9946 - val_loss: 0.3356 - val_accuracy: 0.9471\n",
      "Epoch 155/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0100 - accuracy: 0.9967 - val_loss: 0.3529 - val_accuracy: 0.9460\n",
      "Epoch 156/700\n",
      "736/736 [==============================] - 2s 3ms/step - loss: 0.0129 - accuracy: 0.9948 - val_loss: 0.3286 - val_accuracy: 0.9498\n",
      "Epoch 157/700\n",
      "736/736 [==============================] - 2s 3ms/step - loss: 0.0039 - accuracy: 0.9989 - val_loss: 0.3442 - val_accuracy: 0.9491\n",
      "Epoch 158/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0306 - accuracy: 0.9903 - val_loss: 0.3885 - val_accuracy: 0.9396\n",
      "Epoch 159/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0206 - accuracy: 0.9917 - val_loss: 0.3310 - val_accuracy: 0.9460\n",
      "Epoch 160/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0170 - accuracy: 0.9940 - val_loss: 0.3192 - val_accuracy: 0.9484\n",
      "Epoch 161/700\n",
      "736/736 [==============================] - 3s 3ms/step - loss: 0.0205 - accuracy: 0.9925 - val_loss: 0.3076 - val_accuracy: 0.9491\n",
      "Epoch 162/700\n",
      "736/736 [==============================] - 3s 3ms/step - loss: 0.0139 - accuracy: 0.9947 - val_loss: 0.3744 - val_accuracy: 0.9413\n",
      "Epoch 163/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0098 - accuracy: 0.9961 - val_loss: 0.4916 - val_accuracy: 0.9301\n",
      "Epoch 164/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0159 - accuracy: 0.9943 - val_loss: 0.3118 - val_accuracy: 0.9515\n",
      "Epoch 165/700\n",
      "736/736 [==============================] - 3s 3ms/step - loss: 0.0071 - accuracy: 0.9971 - val_loss: 0.3331 - val_accuracy: 0.9518\n",
      "Epoch 166/700\n",
      "736/736 [==============================] - 3s 3ms/step - loss: 0.0049 - accuracy: 0.9985 - val_loss: 0.3954 - val_accuracy: 0.9501\n",
      "Epoch 167/700\n",
      "736/736 [==============================] - 2s 3ms/step - loss: 0.0101 - accuracy: 0.9967 - val_loss: 0.4564 - val_accuracy: 0.9437\n",
      "Epoch 168/700\n",
      "736/736 [==============================] - 2s 3ms/step - loss: 0.0139 - accuracy: 0.9958 - val_loss: 0.3350 - val_accuracy: 0.9494\n",
      "Epoch 169/700\n",
      "736/736 [==============================] - 2s 3ms/step - loss: 0.0091 - accuracy: 0.9971 - val_loss: 0.3490 - val_accuracy: 0.9515\n",
      "Epoch 170/700\n",
      "736/736 [==============================] - 2s 3ms/step - loss: 0.0115 - accuracy: 0.9988 - val_loss: 0.3987 - val_accuracy: 0.9457\n",
      "Epoch 171/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0333 - accuracy: 0.9916 - val_loss: 0.4266 - val_accuracy: 0.9460\n",
      "Epoch 172/700\n",
      "736/736 [==============================] - 4s 5ms/step - loss: 0.0029 - accuracy: 0.9989 - val_loss: 0.4885 - val_accuracy: 0.9362\n",
      "Epoch 173/700\n",
      "736/736 [==============================] - 3s 3ms/step - loss: 0.0129 - accuracy: 0.9956 - val_loss: 0.4088 - val_accuracy: 0.9477\n",
      "Epoch 174/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0072 - accuracy: 0.9976 - val_loss: 0.5191 - val_accuracy: 0.9335\n",
      "Epoch 175/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0059 - accuracy: 0.9978 - val_loss: 0.4365 - val_accuracy: 0.9447\n",
      "Epoch 176/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0072 - accuracy: 0.9978 - val_loss: 0.4488 - val_accuracy: 0.9423\n",
      "Epoch 177/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0077 - accuracy: 0.9977 - val_loss: 0.4623 - val_accuracy: 0.9396\n",
      "Epoch 178/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0032 - accuracy: 0.9993 - val_loss: 0.4348 - val_accuracy: 0.9471\n",
      "Epoch 179/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0176 - accuracy: 0.9940 - val_loss: 0.4458 - val_accuracy: 0.9386\n",
      "Epoch 180/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0126 - accuracy: 0.9976 - val_loss: 0.7296 - val_accuracy: 0.9298\n",
      "Epoch 181/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0074 - accuracy: 0.9974 - val_loss: 0.3538 - val_accuracy: 0.9505\n",
      "Epoch 182/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0089 - accuracy: 0.9971 - val_loss: 0.4160 - val_accuracy: 0.9450\n",
      "Epoch 183/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0179 - accuracy: 0.9942 - val_loss: 0.2961 - val_accuracy: 0.9542\n",
      "Epoch 184/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0016 - accuracy: 0.9999 - val_loss: 0.3338 - val_accuracy: 0.9535\n",
      "Epoch 185/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0093 - accuracy: 0.9969 - val_loss: 0.3049 - val_accuracy: 0.9549\n",
      "Epoch 186/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0090 - accuracy: 0.9973 - val_loss: 0.3414 - val_accuracy: 0.9464\n",
      "Epoch 187/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0130 - accuracy: 0.9973 - val_loss: 0.3897 - val_accuracy: 0.9450\n",
      "Epoch 188/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0034 - accuracy: 0.9993 - val_loss: 0.3689 - val_accuracy: 0.9494\n",
      "Epoch 189/700\n",
      "736/736 [==============================] - 3s 3ms/step - loss: 0.0195 - accuracy: 0.9943 - val_loss: 0.4116 - val_accuracy: 0.9399\n",
      "Epoch 190/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0071 - accuracy: 0.9978 - val_loss: 0.3290 - val_accuracy: 0.9488\n",
      "Epoch 191/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0054 - accuracy: 0.9981 - val_loss: 0.3638 - val_accuracy: 0.9494\n",
      "Epoch 192/700\n",
      "736/736 [==============================] - 2s 3ms/step - loss: 0.0031 - accuracy: 0.9990 - val_loss: 0.3567 - val_accuracy: 0.9511\n",
      "Epoch 193/700\n",
      "736/736 [==============================] - 3s 3ms/step - loss: 6.6131e-04 - accuracy: 1.0000 - val_loss: 0.4096 - val_accuracy: 0.9501\n",
      "Epoch 194/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0108 - accuracy: 0.9969 - val_loss: 0.3273 - val_accuracy: 0.9515\n",
      "Epoch 195/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0110 - accuracy: 0.9963 - val_loss: 0.3037 - val_accuracy: 0.9535\n",
      "Epoch 196/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0022 - accuracy: 0.9997 - val_loss: 0.3641 - val_accuracy: 0.9423\n",
      "Epoch 197/700\n",
      "736/736 [==============================] - 3s 3ms/step - loss: 0.0345 - accuracy: 0.9937 - val_loss: 0.3191 - val_accuracy: 0.9522\n",
      "Epoch 198/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0060 - accuracy: 0.9981 - val_loss: 0.3408 - val_accuracy: 0.9450\n",
      "Epoch 199/700\n",
      "736/736 [==============================] - 3s 3ms/step - loss: 0.0038 - accuracy: 0.9990 - val_loss: 0.3497 - val_accuracy: 0.9515\n",
      "Epoch 200/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 6.9134e-04 - accuracy: 1.0000 - val_loss: 0.3868 - val_accuracy: 0.9505\n",
      "Epoch 201/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0274 - accuracy: 0.9939 - val_loss: 0.4029 - val_accuracy: 0.9437\n",
      "Epoch 202/700\n",
      "736/736 [==============================] - 3s 5ms/step - loss: 0.0074 - accuracy: 0.9974 - val_loss: 0.5499 - val_accuracy: 0.9325\n",
      "Epoch 203/700\n",
      "736/736 [==============================] - 4s 6ms/step - loss: 0.0044 - accuracy: 0.9982 - val_loss: 0.4080 - val_accuracy: 0.9437\n",
      "Epoch 204/700\n",
      "736/736 [==============================] - 5s 7ms/step - loss: 0.0130 - accuracy: 0.9967 - val_loss: 0.3910 - val_accuracy: 0.9450\n",
      "Epoch 205/700\n",
      "736/736 [==============================] - 5s 7ms/step - loss: 0.0034 - accuracy: 0.9989 - val_loss: 0.4400 - val_accuracy: 0.9511\n",
      "Epoch 206/700\n",
      "736/736 [==============================] - 4s 5ms/step - loss: 0.0121 - accuracy: 0.9963 - val_loss: 0.3606 - val_accuracy: 0.9525\n",
      "Epoch 207/700\n",
      "736/736 [==============================] - 2s 3ms/step - loss: 0.0017 - accuracy: 0.9997 - val_loss: 0.5714 - val_accuracy: 0.9325\n",
      "Epoch 208/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0099 - accuracy: 0.9976 - val_loss: 0.4401 - val_accuracy: 0.9471\n",
      "Epoch 209/700\n",
      "736/736 [==============================] - 2s 3ms/step - loss: 0.0012 - accuracy: 0.9999 - val_loss: 0.4444 - val_accuracy: 0.9474\n",
      "Epoch 210/700\n",
      "736/736 [==============================] - 2s 3ms/step - loss: 0.0084 - accuracy: 0.9971 - val_loss: 0.4526 - val_accuracy: 0.9491\n",
      "Epoch 211/700\n",
      "736/736 [==============================] - 2s 3ms/step - loss: 0.0090 - accuracy: 0.9973 - val_loss: 0.4122 - val_accuracy: 0.9477\n",
      "Epoch 212/700\n",
      "736/736 [==============================] - 3s 3ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.4551 - val_accuracy: 0.9501\n",
      "Epoch 213/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 3.6595e-04 - accuracy: 1.0000 - val_loss: 0.4315 - val_accuracy: 0.9525\n",
      "Epoch 214/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0069 - accuracy: 0.9980 - val_loss: 0.4377 - val_accuracy: 0.9477\n",
      "Epoch 215/700\n",
      "736/736 [==============================] - 2s 3ms/step - loss: 0.0112 - accuracy: 0.9981 - val_loss: 0.3644 - val_accuracy: 0.9518\n",
      "Epoch 216/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0146 - accuracy: 0.9973 - val_loss: 0.4666 - val_accuracy: 0.9450\n",
      "Epoch 217/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.4632 - val_accuracy: 0.9440\n",
      "Epoch 218/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 5.2711e-04 - accuracy: 1.0000 - val_loss: 0.4707 - val_accuracy: 0.9471\n",
      "Epoch 219/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0059 - accuracy: 0.9984 - val_loss: 0.4894 - val_accuracy: 0.9416\n",
      "Epoch 220/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0043 - accuracy: 0.9989 - val_loss: 0.4531 - val_accuracy: 0.9467\n",
      "Epoch 221/700\n",
      "736/736 [==============================] - 2s 3ms/step - loss: 0.0112 - accuracy: 0.9958 - val_loss: 0.4638 - val_accuracy: 0.9430\n",
      "Epoch 222/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0011 - accuracy: 0.9999 - val_loss: 0.4947 - val_accuracy: 0.9420\n",
      "Epoch 223/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0116 - accuracy: 0.9967 - val_loss: 0.5126 - val_accuracy: 0.9365\n",
      "Epoch 224/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0061 - accuracy: 0.9984 - val_loss: 0.4083 - val_accuracy: 0.9494\n",
      "Epoch 225/700\n",
      "736/736 [==============================] - 2s 3ms/step - loss: 8.4987e-04 - accuracy: 0.9997 - val_loss: 0.3922 - val_accuracy: 0.9511\n",
      "Epoch 226/700\n",
      "736/736 [==============================] - 2s 3ms/step - loss: 0.0037 - accuracy: 0.9985 - val_loss: 0.4007 - val_accuracy: 0.9501\n",
      "Epoch 227/700\n",
      "736/736 [==============================] - 2s 3ms/step - loss: 0.0274 - accuracy: 0.9951 - val_loss: 0.5055 - val_accuracy: 0.9420\n",
      "Epoch 228/700\n",
      "736/736 [==============================] - 2s 3ms/step - loss: 0.0272 - accuracy: 0.9959 - val_loss: 0.3373 - val_accuracy: 0.9498\n",
      "Epoch 229/700\n",
      "736/736 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9989 - val_loss: 0.3258 - val_accuracy: 0.9498\n",
      "Epoch 230/700\n",
      "736/736 [==============================] - 2s 3ms/step - loss: 3.0888e-04 - accuracy: 1.0000 - val_loss: 0.3464 - val_accuracy: 0.9505\n",
      "Epoch 231/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 2.1251e-04 - accuracy: 1.0000 - val_loss: 0.3732 - val_accuracy: 0.9484\n",
      "Epoch 232/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 2.4148e-04 - accuracy: 1.0000 - val_loss: 0.3791 - val_accuracy: 0.9505\n",
      "Epoch 233/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0199 - accuracy: 0.9928 - val_loss: 0.3575 - val_accuracy: 0.9467\n",
      "Epoch 234/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0154 - accuracy: 0.9966 - val_loss: 0.2568 - val_accuracy: 0.9535\n",
      "Epoch 235/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 6.1437e-04 - accuracy: 1.0000 - val_loss: 0.3036 - val_accuracy: 0.9511\n",
      "Epoch 236/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0037 - accuracy: 0.9989 - val_loss: 0.2793 - val_accuracy: 0.9511\n",
      "Epoch 237/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0121 - accuracy: 0.9954 - val_loss: 0.3858 - val_accuracy: 0.9389\n",
      "Epoch 238/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.3228 - val_accuracy: 0.9511\n",
      "Epoch 239/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 2.9961e-04 - accuracy: 1.0000 - val_loss: 0.3588 - val_accuracy: 0.9505\n",
      "Epoch 240/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0105 - accuracy: 0.9969 - val_loss: 0.4050 - val_accuracy: 0.9416\n",
      "Epoch 241/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0194 - accuracy: 0.9951 - val_loss: 0.3713 - val_accuracy: 0.9494\n",
      "Epoch 242/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0020 - accuracy: 0.9996 - val_loss: 0.3961 - val_accuracy: 0.9467\n",
      "Epoch 243/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0111 - accuracy: 0.9969 - val_loss: 0.3512 - val_accuracy: 0.9505\n",
      "Epoch 244/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 6.2564e-04 - accuracy: 1.0000 - val_loss: 0.4154 - val_accuracy: 0.9457\n",
      "Epoch 245/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 3.4766e-04 - accuracy: 1.0000 - val_loss: 0.4133 - val_accuracy: 0.9484\n",
      "Epoch 246/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 2.0845e-04 - accuracy: 1.0000 - val_loss: 0.4514 - val_accuracy: 0.9464\n",
      "Epoch 247/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.4354 - val_accuracy: 0.9484\n",
      "Epoch 248/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0036 - accuracy: 0.9986 - val_loss: 0.3979 - val_accuracy: 0.9508\n",
      "Epoch 249/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 4.4965e-04 - accuracy: 0.9999 - val_loss: 0.4155 - val_accuracy: 0.9518\n",
      "Epoch 250/700\n",
      "736/736 [==============================] - 4s 6ms/step - loss: 1.1079e-04 - accuracy: 1.0000 - val_loss: 0.4407 - val_accuracy: 0.9505\n",
      "Epoch 251/700\n",
      "736/736 [==============================] - 6s 9ms/step - loss: 7.7717e-05 - accuracy: 1.0000 - val_loss: 0.4603 - val_accuracy: 0.9508\n",
      "Epoch 252/700\n",
      "736/736 [==============================] - 4s 6ms/step - loss: 0.0162 - accuracy: 0.9962 - val_loss: 0.3709 - val_accuracy: 0.9488\n",
      "Epoch 253/700\n",
      "736/736 [==============================] - 4s 5ms/step - loss: 0.0060 - accuracy: 0.9997 - val_loss: 0.3892 - val_accuracy: 0.9494\n",
      "Epoch 254/700\n",
      "736/736 [==============================] - 4s 5ms/step - loss: 0.0333 - accuracy: 0.9956 - val_loss: 0.3995 - val_accuracy: 0.9474\n",
      "Epoch 255/700\n",
      "736/736 [==============================] - 2s 3ms/step - loss: 5.4585e-04 - accuracy: 1.0000 - val_loss: 0.4129 - val_accuracy: 0.9484\n",
      "Epoch 256/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 2.1321e-04 - accuracy: 1.0000 - val_loss: 0.4396 - val_accuracy: 0.9501\n",
      "Epoch 257/700\n",
      "736/736 [==============================] - 2s 3ms/step - loss: 0.0104 - accuracy: 0.9974 - val_loss: 0.3562 - val_accuracy: 0.9467\n",
      "Epoch 258/700\n",
      "736/736 [==============================] - 2s 3ms/step - loss: 0.0028 - accuracy: 0.9989 - val_loss: 0.3575 - val_accuracy: 0.9522\n",
      "Epoch 259/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0082 - accuracy: 0.9985 - val_loss: 0.3283 - val_accuracy: 0.9535\n",
      "Epoch 260/700\n",
      "736/736 [==============================] - 6s 8ms/step - loss: 4.3135e-04 - accuracy: 1.0000 - val_loss: 0.3758 - val_accuracy: 0.9515\n",
      "Epoch 261/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 2.0089e-04 - accuracy: 1.0000 - val_loss: 0.4360 - val_accuracy: 0.9505\n",
      "Epoch 262/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0092 - accuracy: 0.9976 - val_loss: 0.4740 - val_accuracy: 0.9460\n",
      "Epoch 263/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0179 - accuracy: 0.9950 - val_loss: 0.4193 - val_accuracy: 0.9454\n",
      "Epoch 264/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0082 - accuracy: 0.9971 - val_loss: 0.3764 - val_accuracy: 0.9484\n",
      "Epoch 265/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0056 - accuracy: 0.9977 - val_loss: 0.4520 - val_accuracy: 0.9440\n",
      "Epoch 266/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0177 - accuracy: 0.9956 - val_loss: 0.3198 - val_accuracy: 0.9539\n",
      "Epoch 267/700\n",
      "736/736 [==============================] - 2s 3ms/step - loss: 0.0082 - accuracy: 0.9976 - val_loss: 0.4419 - val_accuracy: 0.9328\n",
      "Epoch 268/700\n",
      "736/736 [==============================] - 2s 3ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 0.4420 - val_accuracy: 0.9515\n",
      "Epoch 269/700\n",
      "736/736 [==============================] - 2s 3ms/step - loss: 0.0021 - accuracy: 0.9988 - val_loss: 0.4139 - val_accuracy: 0.9488\n",
      "Epoch 270/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 2.3039e-04 - accuracy: 1.0000 - val_loss: 0.4527 - val_accuracy: 0.9501\n",
      "Epoch 271/700\n",
      "736/736 [==============================] - 3s 3ms/step - loss: 1.7492e-04 - accuracy: 1.0000 - val_loss: 0.4795 - val_accuracy: 0.9488\n",
      "Epoch 272/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0107 - accuracy: 0.9976 - val_loss: 0.4156 - val_accuracy: 0.9491\n",
      "Epoch 273/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 3.0527e-04 - accuracy: 1.0000 - val_loss: 0.4324 - val_accuracy: 0.9511\n",
      "Epoch 274/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0354 - accuracy: 0.9936 - val_loss: 0.4422 - val_accuracy: 0.9498\n",
      "Epoch 275/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4959 - val_accuracy: 0.9481\n",
      "Epoch 276/700\n",
      "736/736 [==============================] - 3s 3ms/step - loss: 3.0056e-04 - accuracy: 1.0000 - val_loss: 0.5171 - val_accuracy: 0.9494\n",
      "Epoch 277/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0106 - accuracy: 0.9971 - val_loss: 0.6215 - val_accuracy: 0.9440\n",
      "Epoch 278/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0097 - accuracy: 0.9971 - val_loss: 0.4062 - val_accuracy: 0.9511\n",
      "Epoch 279/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 5.8859e-04 - accuracy: 1.0000 - val_loss: 0.5031 - val_accuracy: 0.9457\n",
      "Epoch 280/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 2.7000e-04 - accuracy: 1.0000 - val_loss: 0.5327 - val_accuracy: 0.9450\n",
      "Epoch 281/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0098 - accuracy: 0.9973 - val_loss: 0.4955 - val_accuracy: 0.9454\n",
      "Epoch 282/700\n",
      "736/736 [==============================] - 3s 3ms/step - loss: 0.0073 - accuracy: 0.9977 - val_loss: 0.3979 - val_accuracy: 0.9528\n",
      "Epoch 283/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0032 - accuracy: 0.9989 - val_loss: 0.4211 - val_accuracy: 0.9518\n",
      "Epoch 284/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 2.9045e-04 - accuracy: 1.0000 - val_loss: 0.4587 - val_accuracy: 0.9511\n",
      "Epoch 285/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 8.4729e-04 - accuracy: 0.9999 - val_loss: 0.4629 - val_accuracy: 0.9522\n",
      "Epoch 286/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 1.0292e-04 - accuracy: 1.0000 - val_loss: 0.4806 - val_accuracy: 0.9522\n",
      "Epoch 287/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 5.8347e-05 - accuracy: 1.0000 - val_loss: 0.5152 - val_accuracy: 0.9511\n",
      "Epoch 288/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 4.3088e-05 - accuracy: 1.0000 - val_loss: 0.5246 - val_accuracy: 0.9522\n",
      "Epoch 289/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 3.2508e-05 - accuracy: 1.0000 - val_loss: 0.5392 - val_accuracy: 0.9522\n",
      "Epoch 290/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 1.6724e-05 - accuracy: 1.0000 - val_loss: 0.5456 - val_accuracy: 0.9535\n",
      "Epoch 291/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0215 - accuracy: 0.9954 - val_loss: 0.4848 - val_accuracy: 0.9433\n",
      "Epoch 292/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0094 - accuracy: 0.9971 - val_loss: 0.6793 - val_accuracy: 0.9379\n",
      "Epoch 293/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0082 - accuracy: 0.9990 - val_loss: 0.3789 - val_accuracy: 0.9542\n",
      "Epoch 294/700\n",
      "736/736 [==============================] - 3s 3ms/step - loss: 2.7840e-04 - accuracy: 1.0000 - val_loss: 0.4250 - val_accuracy: 0.9539\n",
      "Epoch 295/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0199 - accuracy: 0.9982 - val_loss: 0.3692 - val_accuracy: 0.9535\n",
      "Epoch 296/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 3.5181e-04 - accuracy: 1.0000 - val_loss: 0.4008 - val_accuracy: 0.9539\n",
      "Epoch 297/700\n",
      "736/736 [==============================] - 2s 3ms/step - loss: 1.4271e-04 - accuracy: 1.0000 - val_loss: 0.4093 - val_accuracy: 0.9549\n",
      "Epoch 298/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 1.0112e-04 - accuracy: 1.0000 - val_loss: 0.4383 - val_accuracy: 0.9532\n",
      "Epoch 299/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 5.8803e-05 - accuracy: 1.0000 - val_loss: 0.4376 - val_accuracy: 0.9539\n",
      "Epoch 300/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 5.0048e-05 - accuracy: 1.0000 - val_loss: 0.4751 - val_accuracy: 0.9528\n",
      "Epoch 301/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 3.6450e-05 - accuracy: 1.0000 - val_loss: 0.4744 - val_accuracy: 0.9545\n",
      "Epoch 302/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 2.4187e-05 - accuracy: 1.0000 - val_loss: 0.5382 - val_accuracy: 0.9498\n",
      "Epoch 303/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 2.3205e-05 - accuracy: 1.0000 - val_loss: 0.5086 - val_accuracy: 0.9555\n",
      "Epoch 304/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0639 - accuracy: 0.9859 - val_loss: 0.3421 - val_accuracy: 0.9525\n",
      "Epoch 305/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0295 - accuracy: 0.9950 - val_loss: 0.2808 - val_accuracy: 0.9566\n",
      "Epoch 306/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0074 - accuracy: 0.9988 - val_loss: 0.3549 - val_accuracy: 0.9576\n",
      "Epoch 307/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0010 - accuracy: 0.9999 - val_loss: 0.3474 - val_accuracy: 0.9589\n",
      "Epoch 308/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 5.1888e-04 - accuracy: 1.0000 - val_loss: 0.3620 - val_accuracy: 0.9586\n",
      "Epoch 309/700\n",
      "736/736 [==============================] - 3s 3ms/step - loss: 3.3252e-04 - accuracy: 1.0000 - val_loss: 0.4103 - val_accuracy: 0.9572\n",
      "Epoch 310/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0026 - accuracy: 0.9990 - val_loss: 0.3930 - val_accuracy: 0.9555\n",
      "Epoch 311/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0255 - accuracy: 0.9962 - val_loss: 0.5588 - val_accuracy: 0.9467\n",
      "Epoch 312/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 4.1513e-04 - accuracy: 1.0000 - val_loss: 0.6045 - val_accuracy: 0.9454\n",
      "Epoch 313/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0036 - accuracy: 0.9990 - val_loss: 0.5351 - val_accuracy: 0.9491\n",
      "Epoch 314/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0078 - accuracy: 0.9977 - val_loss: 0.4739 - val_accuracy: 0.9528\n",
      "Epoch 315/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 3.1094e-04 - accuracy: 1.0000 - val_loss: 0.5133 - val_accuracy: 0.9508\n",
      "Epoch 316/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 1.8426e-04 - accuracy: 1.0000 - val_loss: 0.5343 - val_accuracy: 0.9501\n",
      "Epoch 317/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 1.1820e-04 - accuracy: 1.0000 - val_loss: 0.5397 - val_accuracy: 0.9505\n",
      "Epoch 318/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 7.7049e-05 - accuracy: 1.0000 - val_loss: 0.5618 - val_accuracy: 0.9508\n",
      "Epoch 319/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 5.2466e-05 - accuracy: 1.0000 - val_loss: 0.5728 - val_accuracy: 0.9508\n",
      "Epoch 320/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 3.1155e-05 - accuracy: 1.0000 - val_loss: 0.5649 - val_accuracy: 0.9505\n",
      "Epoch 321/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 2.7384e-05 - accuracy: 1.0000 - val_loss: 0.6078 - val_accuracy: 0.9501\n",
      "Epoch 322/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0404 - accuracy: 0.9922 - val_loss: 0.5357 - val_accuracy: 0.9433\n",
      "Epoch 323/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0107 - accuracy: 0.9956 - val_loss: 0.4110 - val_accuracy: 0.9525\n",
      "Epoch 324/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0045 - accuracy: 0.9986 - val_loss: 0.4384 - val_accuracy: 0.9525\n",
      "Epoch 325/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 3.0000e-04 - accuracy: 1.0000 - val_loss: 0.4557 - val_accuracy: 0.9522\n",
      "Epoch 326/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 1.5723e-04 - accuracy: 1.0000 - val_loss: 0.4810 - val_accuracy: 0.9522\n",
      "Epoch 327/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0152 - accuracy: 0.9951 - val_loss: 0.3999 - val_accuracy: 0.9528\n",
      "Epoch 328/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 4.4063e-04 - accuracy: 1.0000 - val_loss: 0.4549 - val_accuracy: 0.9515\n",
      "Epoch 329/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 2.2674e-04 - accuracy: 1.0000 - val_loss: 0.4599 - val_accuracy: 0.9522\n",
      "Epoch 330/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 1.2701e-04 - accuracy: 1.0000 - val_loss: 0.4758 - val_accuracy: 0.9515\n",
      "Epoch 331/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 7.7325e-05 - accuracy: 1.0000 - val_loss: 0.4918 - val_accuracy: 0.9535\n",
      "Epoch 332/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0235 - accuracy: 0.9947 - val_loss: 0.4775 - val_accuracy: 0.9505\n",
      "Epoch 333/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0130 - accuracy: 0.9976 - val_loss: 0.4345 - val_accuracy: 0.9498\n",
      "Epoch 334/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 3.4370e-04 - accuracy: 1.0000 - val_loss: 0.4602 - val_accuracy: 0.9508\n",
      "Epoch 335/700\n",
      "736/736 [==============================] - 2s 3ms/step - loss: 0.0139 - accuracy: 0.9973 - val_loss: 0.4155 - val_accuracy: 0.9471\n",
      "Epoch 336/700\n",
      "736/736 [==============================] - 2s 3ms/step - loss: 0.0137 - accuracy: 0.9948 - val_loss: 0.4064 - val_accuracy: 0.9447\n",
      "Epoch 337/700\n",
      "736/736 [==============================] - 2s 3ms/step - loss: 0.0089 - accuracy: 0.9966 - val_loss: 0.3822 - val_accuracy: 0.9528\n",
      "Epoch 338/700\n",
      "736/736 [==============================] - 3s 3ms/step - loss: 0.0204 - accuracy: 0.9940 - val_loss: 0.3809 - val_accuracy: 0.9488\n",
      "Epoch 339/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0215 - accuracy: 0.9936 - val_loss: 0.4793 - val_accuracy: 0.9474\n",
      "Epoch 340/700\n",
      "736/736 [==============================] - 3s 3ms/step - loss: 0.0062 - accuracy: 0.9978 - val_loss: 0.5081 - val_accuracy: 0.9494\n",
      "Epoch 341/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0026 - accuracy: 0.9993 - val_loss: 0.5033 - val_accuracy: 0.9450\n",
      "Epoch 342/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0034 - accuracy: 0.9989 - val_loss: 0.5106 - val_accuracy: 0.9501\n",
      "Epoch 343/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 3.1996e-04 - accuracy: 1.0000 - val_loss: 0.5392 - val_accuracy: 0.9515\n",
      "Epoch 344/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 1.6856e-04 - accuracy: 1.0000 - val_loss: 0.5456 - val_accuracy: 0.9525\n",
      "Epoch 345/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0292 - accuracy: 0.9946 - val_loss: 0.4221 - val_accuracy: 0.9542\n",
      "Epoch 346/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0298 - accuracy: 0.9959 - val_loss: 0.6361 - val_accuracy: 0.9430\n",
      "Epoch 347/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0067 - accuracy: 0.9977 - val_loss: 0.4652 - val_accuracy: 0.9532\n",
      "Epoch 348/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0067 - accuracy: 0.9969 - val_loss: 0.5024 - val_accuracy: 0.9494\n",
      "Epoch 349/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0048 - accuracy: 0.9977 - val_loss: 0.5926 - val_accuracy: 0.9396\n",
      "Epoch 350/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0057 - accuracy: 0.9982 - val_loss: 0.5256 - val_accuracy: 0.9474\n",
      "Epoch 351/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0091 - accuracy: 0.9976 - val_loss: 0.4578 - val_accuracy: 0.9498\n",
      "Epoch 352/700\n",
      "736/736 [==============================] - 4s 5ms/step - loss: 0.0045 - accuracy: 0.9985 - val_loss: 0.5438 - val_accuracy: 0.9393\n",
      "Epoch 353/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 0.4883 - val_accuracy: 0.9484\n",
      "Epoch 354/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 0.5595 - val_accuracy: 0.9454\n",
      "Epoch 355/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0146 - accuracy: 0.9958 - val_loss: 0.5390 - val_accuracy: 0.9457\n",
      "Epoch 356/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0078 - accuracy: 0.9976 - val_loss: 0.6219 - val_accuracy: 0.9389\n",
      "Epoch 357/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0018 - accuracy: 0.9996 - val_loss: 0.5278 - val_accuracy: 0.9491\n",
      "Epoch 358/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0074 - accuracy: 0.9980 - val_loss: 0.5838 - val_accuracy: 0.9474\n",
      "Epoch 359/700\n",
      "736/736 [==============================] - 2s 3ms/step - loss: 0.0074 - accuracy: 0.9980 - val_loss: 0.5219 - val_accuracy: 0.9505\n",
      "Epoch 360/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5751 - val_accuracy: 0.9488\n",
      "Epoch 361/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0056 - accuracy: 0.9980 - val_loss: 0.6146 - val_accuracy: 0.9440\n",
      "Epoch 362/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0065 - accuracy: 0.9974 - val_loss: 0.6388 - val_accuracy: 0.9460\n",
      "Epoch 363/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0079 - accuracy: 0.9982 - val_loss: 0.5140 - val_accuracy: 0.9525\n",
      "Epoch 364/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 9.5902e-04 - accuracy: 1.0000 - val_loss: 0.5812 - val_accuracy: 0.9467\n",
      "Epoch 365/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 4.9393e-04 - accuracy: 1.0000 - val_loss: 0.6043 - val_accuracy: 0.9477\n",
      "Epoch 366/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 2.8957e-04 - accuracy: 1.0000 - val_loss: 0.6541 - val_accuracy: 0.9423\n",
      "Epoch 367/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0064 - accuracy: 0.9977 - val_loss: 0.5983 - val_accuracy: 0.9494\n",
      "Epoch 368/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 3.0000e-04 - accuracy: 1.0000 - val_loss: 0.6346 - val_accuracy: 0.9501\n",
      "Epoch 369/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.6281 - val_accuracy: 0.9505\n",
      "Epoch 370/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0381 - accuracy: 0.9927 - val_loss: 0.6074 - val_accuracy: 0.9430\n",
      "Epoch 371/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0055 - accuracy: 0.9982 - val_loss: 0.4191 - val_accuracy: 0.9549\n",
      "Epoch 372/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0018 - accuracy: 0.9993 - val_loss: 0.4581 - val_accuracy: 0.9555\n",
      "Epoch 373/700\n",
      "736/736 [==============================] - 3s 5ms/step - loss: 4.5986e-04 - accuracy: 1.0000 - val_loss: 0.4928 - val_accuracy: 0.9562\n",
      "Epoch 374/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 2.2335e-04 - accuracy: 1.0000 - val_loss: 0.5143 - val_accuracy: 0.9545\n",
      "Epoch 375/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0194 - accuracy: 0.9950 - val_loss: 0.4850 - val_accuracy: 0.9488\n",
      "Epoch 376/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0016 - accuracy: 0.9993 - val_loss: 0.4865 - val_accuracy: 0.9481\n",
      "Epoch 377/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0081 - accuracy: 0.9971 - val_loss: 0.6397 - val_accuracy: 0.9348\n",
      "Epoch 378/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0115 - accuracy: 0.9965 - val_loss: 0.4705 - val_accuracy: 0.9511\n",
      "Epoch 379/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 7.9823e-04 - accuracy: 1.0000 - val_loss: 0.5011 - val_accuracy: 0.9522\n",
      "Epoch 380/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0311 - accuracy: 0.9943 - val_loss: 0.5487 - val_accuracy: 0.9471\n",
      "Epoch 381/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0041 - accuracy: 0.9989 - val_loss: 0.5007 - val_accuracy: 0.9477\n",
      "Epoch 382/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0026 - accuracy: 0.9993 - val_loss: 0.5801 - val_accuracy: 0.9365\n",
      "Epoch 383/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0013 - accuracy: 0.9999 - val_loss: 0.5114 - val_accuracy: 0.9515\n",
      "Epoch 384/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0199 - accuracy: 0.9973 - val_loss: 0.5096 - val_accuracy: 0.9494\n",
      "Epoch 385/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0207 - accuracy: 0.9974 - val_loss: 0.6568 - val_accuracy: 0.9416\n",
      "Epoch 386/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.4973 - val_accuracy: 0.9494\n",
      "Epoch 387/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0036 - accuracy: 0.9989 - val_loss: 0.5010 - val_accuracy: 0.9488\n",
      "Epoch 388/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 3.5745e-04 - accuracy: 1.0000 - val_loss: 0.5307 - val_accuracy: 0.9484\n",
      "Epoch 389/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 3.0151e-04 - accuracy: 1.0000 - val_loss: 0.5275 - val_accuracy: 0.9501\n",
      "Epoch 390/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0080 - accuracy: 0.9985 - val_loss: 0.5172 - val_accuracy: 0.9491\n",
      "Epoch 391/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 4.1062e-04 - accuracy: 1.0000 - val_loss: 0.5287 - val_accuracy: 0.9491\n",
      "Epoch 392/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 3.0721e-04 - accuracy: 1.0000 - val_loss: 0.5247 - val_accuracy: 0.9505\n",
      "Epoch 393/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0181 - accuracy: 0.9951 - val_loss: 0.4557 - val_accuracy: 0.9528\n",
      "Epoch 394/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0070 - accuracy: 0.9977 - val_loss: 0.5700 - val_accuracy: 0.9454\n",
      "Epoch 395/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.5515 - val_accuracy: 0.9515\n",
      "Epoch 396/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0033 - accuracy: 0.9986 - val_loss: 0.5503 - val_accuracy: 0.9488\n",
      "Epoch 397/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 3.4246e-04 - accuracy: 1.0000 - val_loss: 0.5606 - val_accuracy: 0.9501\n",
      "Epoch 398/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0075 - accuracy: 0.9980 - val_loss: 0.5091 - val_accuracy: 0.9427\n",
      "Epoch 399/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0152 - accuracy: 0.9969 - val_loss: 0.8024 - val_accuracy: 0.9369\n",
      "Epoch 400/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 9.8278e-04 - accuracy: 0.9997 - val_loss: 0.5889 - val_accuracy: 0.9474\n",
      "Epoch 401/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 3.1624e-04 - accuracy: 1.0000 - val_loss: 0.6034 - val_accuracy: 0.9481\n",
      "Epoch 402/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 1.6274e-04 - accuracy: 1.0000 - val_loss: 0.6178 - val_accuracy: 0.9467\n",
      "Epoch 403/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 9.0105e-05 - accuracy: 1.0000 - val_loss: 0.6390 - val_accuracy: 0.9484\n",
      "Epoch 404/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 4.9490e-05 - accuracy: 1.0000 - val_loss: 0.6781 - val_accuracy: 0.9460\n",
      "Epoch 405/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0110 - accuracy: 0.9974 - val_loss: 0.6050 - val_accuracy: 0.9467\n",
      "Epoch 406/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 1.4066e-04 - accuracy: 1.0000 - val_loss: 0.6195 - val_accuracy: 0.9457\n",
      "Epoch 407/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 8.8590e-05 - accuracy: 1.0000 - val_loss: 0.6419 - val_accuracy: 0.9471\n",
      "Epoch 408/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 7.1599e-05 - accuracy: 1.0000 - val_loss: 0.6459 - val_accuracy: 0.9471\n",
      "Epoch 409/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 5.4945e-05 - accuracy: 1.0000 - val_loss: 0.6503 - val_accuracy: 0.9477\n",
      "Epoch 410/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 4.1533e-05 - accuracy: 1.0000 - val_loss: 0.6488 - val_accuracy: 0.9491\n",
      "Epoch 411/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 2.8259e-05 - accuracy: 1.0000 - val_loss: 0.6855 - val_accuracy: 0.9464\n",
      "Epoch 412/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0085 - accuracy: 0.9981 - val_loss: 0.6480 - val_accuracy: 0.9427\n",
      "Epoch 413/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0192 - accuracy: 0.9955 - val_loss: 0.7259 - val_accuracy: 0.9355\n",
      "Epoch 414/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0047 - accuracy: 0.9989 - val_loss: 0.5483 - val_accuracy: 0.9515\n",
      "Epoch 415/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 4.8306e-04 - accuracy: 0.9999 - val_loss: 0.5601 - val_accuracy: 0.9511\n",
      "Epoch 416/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 1.7990e-04 - accuracy: 1.0000 - val_loss: 0.5820 - val_accuracy: 0.9518\n",
      "Epoch 417/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 8.6082e-04 - accuracy: 0.9997 - val_loss: 0.5474 - val_accuracy: 0.9522\n",
      "Epoch 418/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 1.8936e-04 - accuracy: 1.0000 - val_loss: 0.5750 - val_accuracy: 0.9522\n",
      "Epoch 419/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0356 - accuracy: 0.9929 - val_loss: 0.4260 - val_accuracy: 0.9423\n",
      "Epoch 420/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0260 - accuracy: 0.9965 - val_loss: 0.3665 - val_accuracy: 0.9562\n",
      "Epoch 421/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 9.6508e-04 - accuracy: 1.0000 - val_loss: 0.3938 - val_accuracy: 0.9542\n",
      "Epoch 422/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 5.1615e-04 - accuracy: 1.0000 - val_loss: 0.4064 - val_accuracy: 0.9566\n",
      "Epoch 423/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 2.9544e-04 - accuracy: 1.0000 - val_loss: 0.4369 - val_accuracy: 0.9535\n",
      "Epoch 424/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0027 - accuracy: 0.9992 - val_loss: 0.4474 - val_accuracy: 0.9555\n",
      "Epoch 425/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 1.3443e-04 - accuracy: 1.0000 - val_loss: 0.4649 - val_accuracy: 0.9579\n",
      "Epoch 426/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 1.0906e-04 - accuracy: 1.0000 - val_loss: 0.4575 - val_accuracy: 0.9593\n",
      "Epoch 427/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0066 - accuracy: 0.9985 - val_loss: 0.4865 - val_accuracy: 0.9511\n",
      "Epoch 428/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0226 - accuracy: 0.9966 - val_loss: 0.5074 - val_accuracy: 0.9505\n",
      "Epoch 429/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 6.3573e-04 - accuracy: 1.0000 - val_loss: 0.5576 - val_accuracy: 0.9501\n",
      "Epoch 430/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0051 - accuracy: 0.9986 - val_loss: 0.5951 - val_accuracy: 0.9447\n",
      "Epoch 431/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0010 - accuracy: 0.9997 - val_loss: 0.5640 - val_accuracy: 0.9484\n",
      "Epoch 432/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 1.4006e-04 - accuracy: 1.0000 - val_loss: 0.5830 - val_accuracy: 0.9484\n",
      "Epoch 433/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 9.5461e-05 - accuracy: 1.0000 - val_loss: 0.5989 - val_accuracy: 0.9484\n",
      "Epoch 434/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 7.0017e-05 - accuracy: 1.0000 - val_loss: 0.6171 - val_accuracy: 0.9474\n",
      "Epoch 435/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 4.4071e-05 - accuracy: 1.0000 - val_loss: 0.6363 - val_accuracy: 0.9474\n",
      "Epoch 436/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 2.8718e-05 - accuracy: 1.0000 - val_loss: 0.6556 - val_accuracy: 0.9460\n",
      "Epoch 437/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 3.1870e-05 - accuracy: 1.0000 - val_loss: 0.6669 - val_accuracy: 0.9491\n",
      "Epoch 438/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 1.4335e-05 - accuracy: 1.0000 - val_loss: 0.7127 - val_accuracy: 0.9457\n",
      "Epoch 439/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0423 - accuracy: 0.9959 - val_loss: 1.3860 - val_accuracy: 0.9172\n",
      "Epoch 440/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0133 - accuracy: 0.9982 - val_loss: 0.6092 - val_accuracy: 0.9522\n",
      "Epoch 441/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 7.0559e-05 - accuracy: 1.0000 - val_loss: 0.5986 - val_accuracy: 0.9535\n",
      "Epoch 442/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 4.7516e-05 - accuracy: 1.0000 - val_loss: 0.6119 - val_accuracy: 0.9528\n",
      "Epoch 443/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 3.7412e-05 - accuracy: 1.0000 - val_loss: 0.6109 - val_accuracy: 0.9532\n",
      "Epoch 444/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 3.2450e-05 - accuracy: 1.0000 - val_loss: 0.6312 - val_accuracy: 0.9518\n",
      "Epoch 445/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 2.4727e-05 - accuracy: 1.0000 - val_loss: 0.6357 - val_accuracy: 0.9515\n",
      "Epoch 446/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 1.9361e-05 - accuracy: 1.0000 - val_loss: 0.6398 - val_accuracy: 0.9522\n",
      "Epoch 447/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 1.7105e-05 - accuracy: 1.0000 - val_loss: 0.6604 - val_accuracy: 0.9518\n",
      "Epoch 448/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 1.2606e-05 - accuracy: 1.0000 - val_loss: 0.6545 - val_accuracy: 0.9525\n",
      "Epoch 449/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 9.2785e-06 - accuracy: 1.0000 - val_loss: 0.6690 - val_accuracy: 0.9528\n",
      "Epoch 450/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 7.1980e-06 - accuracy: 1.0000 - val_loss: 0.6970 - val_accuracy: 0.9532\n",
      "Epoch 451/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 4.1366e-06 - accuracy: 1.0000 - val_loss: 0.6893 - val_accuracy: 0.9549\n",
      "Epoch 452/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0198 - accuracy: 0.9969 - val_loss: 0.5413 - val_accuracy: 0.9522\n",
      "Epoch 453/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 2.5389e-04 - accuracy: 1.0000 - val_loss: 0.5759 - val_accuracy: 0.9498\n",
      "Epoch 454/700\n",
      "736/736 [==============================] - 2s 3ms/step - loss: 0.0276 - accuracy: 0.9958 - val_loss: 0.5654 - val_accuracy: 0.9511\n",
      "Epoch 455/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 2.0727e-04 - accuracy: 1.0000 - val_loss: 0.5825 - val_accuracy: 0.9491\n",
      "Epoch 456/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 4.3166e-05 - accuracy: 1.0000 - val_loss: 0.5919 - val_accuracy: 0.9501\n",
      "Epoch 457/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 2.8671e-05 - accuracy: 1.0000 - val_loss: 0.5983 - val_accuracy: 0.9501\n",
      "Epoch 458/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 2.3683e-05 - accuracy: 1.0000 - val_loss: 0.6011 - val_accuracy: 0.9505\n",
      "Epoch 459/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 2.0557e-05 - accuracy: 1.0000 - val_loss: 0.6007 - val_accuracy: 0.9505\n",
      "Epoch 460/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 1.5425e-05 - accuracy: 1.0000 - val_loss: 0.6154 - val_accuracy: 0.9518\n",
      "Epoch 461/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 1.4578e-05 - accuracy: 1.0000 - val_loss: 0.6285 - val_accuracy: 0.9522\n",
      "Epoch 462/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 9.5702e-06 - accuracy: 1.0000 - val_loss: 0.6388 - val_accuracy: 0.9508\n",
      "Epoch 463/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0060 - accuracy: 0.9995 - val_loss: 0.6092 - val_accuracy: 0.9508\n",
      "Epoch 464/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0095 - accuracy: 0.9967 - val_loss: 0.9586 - val_accuracy: 0.9382\n",
      "Epoch 465/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0140 - accuracy: 0.9970 - val_loss: 0.6068 - val_accuracy: 0.9484\n",
      "Epoch 466/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0171 - accuracy: 0.9971 - val_loss: 0.6396 - val_accuracy: 0.9467\n",
      "Epoch 467/700\n",
      "736/736 [==============================] - 4s 5ms/step - loss: 4.2776e-04 - accuracy: 1.0000 - val_loss: 0.5410 - val_accuracy: 0.9515\n",
      "Epoch 468/700\n",
      "736/736 [==============================] - 5s 7ms/step - loss: 4.7794e-04 - accuracy: 1.0000 - val_loss: 0.5672 - val_accuracy: 0.9532\n",
      "Epoch 469/700\n",
      "736/736 [==============================] - 4s 6ms/step - loss: 1.3031e-04 - accuracy: 1.0000 - val_loss: 0.5685 - val_accuracy: 0.9518\n",
      "Epoch 470/700\n",
      "736/736 [==============================] - 4s 6ms/step - loss: 0.0130 - accuracy: 0.9971 - val_loss: 0.7608 - val_accuracy: 0.9315\n",
      "Epoch 471/700\n",
      "736/736 [==============================] - 4s 5ms/step - loss: 0.0060 - accuracy: 0.9993 - val_loss: 0.7178 - val_accuracy: 0.9444\n",
      "Epoch 472/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 2.2960e-04 - accuracy: 1.0000 - val_loss: 0.7198 - val_accuracy: 0.9440\n",
      "Epoch 473/700\n",
      "736/736 [==============================] - 3s 3ms/step - loss: 3.8070e-04 - accuracy: 0.9999 - val_loss: 0.8391 - val_accuracy: 0.9308\n",
      "Epoch 474/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0043 - accuracy: 0.9986 - val_loss: 0.7157 - val_accuracy: 0.9447\n",
      "Epoch 475/700\n",
      "736/736 [==============================] - 3s 5ms/step - loss: 1.1786e-04 - accuracy: 1.0000 - val_loss: 0.7410 - val_accuracy: 0.9444\n",
      "Epoch 476/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 1.1093e-04 - accuracy: 1.0000 - val_loss: 0.7442 - val_accuracy: 0.9450\n",
      "Epoch 477/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 8.1550e-05 - accuracy: 1.0000 - val_loss: 0.7334 - val_accuracy: 0.9447\n",
      "Epoch 478/700\n",
      "736/736 [==============================] - 2s 3ms/step - loss: 0.0263 - accuracy: 0.9969 - val_loss: 0.6579 - val_accuracy: 0.9413\n",
      "Epoch 479/700\n",
      "736/736 [==============================] - 2s 3ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.6053 - val_accuracy: 0.9484\n",
      "Epoch 480/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0075 - accuracy: 0.9982 - val_loss: 0.6041 - val_accuracy: 0.9488\n",
      "Epoch 481/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 2.2469e-04 - accuracy: 1.0000 - val_loss: 0.6051 - val_accuracy: 0.9488\n",
      "Epoch 482/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 1.2903e-04 - accuracy: 1.0000 - val_loss: 0.6342 - val_accuracy: 0.9484\n",
      "Epoch 483/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 9.0025e-05 - accuracy: 1.0000 - val_loss: 0.6435 - val_accuracy: 0.9494\n",
      "Epoch 484/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0146 - accuracy: 0.9963 - val_loss: 0.6474 - val_accuracy: 0.9440\n",
      "Epoch 485/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.5445 - val_accuracy: 0.9501\n",
      "Epoch 486/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 2.6415e-04 - accuracy: 1.0000 - val_loss: 0.5544 - val_accuracy: 0.9501\n",
      "Epoch 487/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 1.7613e-04 - accuracy: 1.0000 - val_loss: 0.5541 - val_accuracy: 0.9518\n",
      "Epoch 488/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 1.2537e-04 - accuracy: 1.0000 - val_loss: 0.5718 - val_accuracy: 0.9515\n",
      "Epoch 489/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 6.5165e-05 - accuracy: 1.0000 - val_loss: 0.6060 - val_accuracy: 0.9491\n",
      "Epoch 490/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 6.8139e-05 - accuracy: 1.0000 - val_loss: 0.5782 - val_accuracy: 0.9532\n",
      "Epoch 491/700\n",
      "736/736 [==============================] - 3s 3ms/step - loss: 0.0156 - accuracy: 0.9962 - val_loss: 0.6421 - val_accuracy: 0.9450\n",
      "Epoch 492/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0028 - accuracy: 0.9993 - val_loss: 0.5746 - val_accuracy: 0.9494\n",
      "Epoch 493/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.5956 - val_accuracy: 0.9515\n",
      "Epoch 494/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 2.0898e-04 - accuracy: 1.0000 - val_loss: 0.6170 - val_accuracy: 0.9505\n",
      "Epoch 495/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 1.3018e-04 - accuracy: 1.0000 - val_loss: 0.6356 - val_accuracy: 0.9494\n",
      "Epoch 496/700\n",
      "736/736 [==============================] - 4s 5ms/step - loss: 8.2705e-05 - accuracy: 1.0000 - val_loss: 0.6591 - val_accuracy: 0.9484\n",
      "Epoch 497/700\n",
      "736/736 [==============================] - 3s 5ms/step - loss: 4.9118e-05 - accuracy: 1.0000 - val_loss: 0.6632 - val_accuracy: 0.9491\n",
      "Epoch 498/700\n",
      "736/736 [==============================] - 3s 5ms/step - loss: 0.0377 - accuracy: 0.9950 - val_loss: 1.3356 - val_accuracy: 0.9175\n",
      "Epoch 499/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0663 - accuracy: 0.9912 - val_loss: 0.7759 - val_accuracy: 0.9433\n",
      "Epoch 500/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.5089 - val_accuracy: 0.9528\n",
      "Epoch 501/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0038 - accuracy: 0.9993 - val_loss: 0.8698 - val_accuracy: 0.9382\n",
      "Epoch 502/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0081 - accuracy: 0.9995 - val_loss: 0.6396 - val_accuracy: 0.9494\n",
      "Epoch 503/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.6645 - val_accuracy: 0.9474\n",
      "Epoch 504/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 2.1176e-04 - accuracy: 1.0000 - val_loss: 0.6932 - val_accuracy: 0.9460\n",
      "Epoch 505/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 1.4228e-04 - accuracy: 1.0000 - val_loss: 0.7503 - val_accuracy: 0.9454\n",
      "Epoch 506/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0091 - accuracy: 0.9981 - val_loss: 0.6428 - val_accuracy: 0.9467\n",
      "Epoch 507/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 3.7061e-04 - accuracy: 1.0000 - val_loss: 0.6649 - val_accuracy: 0.9477\n",
      "Epoch 508/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 1.9017e-04 - accuracy: 1.0000 - val_loss: 0.6788 - val_accuracy: 0.9464\n",
      "Epoch 509/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0118 - accuracy: 0.9977 - val_loss: 0.6063 - val_accuracy: 0.9464\n",
      "Epoch 510/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 7.9955e-04 - accuracy: 0.9997 - val_loss: 0.6016 - val_accuracy: 0.9491\n",
      "Epoch 511/700\n",
      "736/736 [==============================] - 2s 3ms/step - loss: 2.6166e-04 - accuracy: 1.0000 - val_loss: 0.6143 - val_accuracy: 0.9494\n",
      "Epoch 512/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0030 - accuracy: 0.9992 - val_loss: 0.7251 - val_accuracy: 0.9471\n",
      "Epoch 513/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0138 - accuracy: 0.9965 - val_loss: 0.4738 - val_accuracy: 0.9535\n",
      "Epoch 514/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4979 - val_accuracy: 0.9522\n",
      "Epoch 515/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.5169 - val_accuracy: 0.9505\n",
      "Epoch 516/700\n",
      "736/736 [==============================] - 4s 5ms/step - loss: 2.9060e-04 - accuracy: 1.0000 - val_loss: 0.5865 - val_accuracy: 0.9505\n",
      "Epoch 517/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 1.6906e-04 - accuracy: 1.0000 - val_loss: 0.6011 - val_accuracy: 0.9494\n",
      "Epoch 518/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 0.0038 - accuracy: 0.9992 - val_loss: 0.6058 - val_accuracy: 0.9464\n",
      "Epoch 519/700\n",
      "736/736 [==============================] - 5s 7ms/step - loss: 0.0173 - accuracy: 0.9963 - val_loss: 0.6865 - val_accuracy: 0.9444\n",
      "Epoch 520/700\n",
      "736/736 [==============================] - 5s 7ms/step - loss: 9.4792e-04 - accuracy: 0.9997 - val_loss: 0.6873 - val_accuracy: 0.9454\n",
      "Epoch 521/700\n",
      "736/736 [==============================] - 8s 10ms/step - loss: 8.7535e-04 - accuracy: 0.9996 - val_loss: 0.7271 - val_accuracy: 0.9457\n",
      "Epoch 522/700\n",
      "736/736 [==============================] - 9s 12ms/step - loss: 9.3301e-05 - accuracy: 1.0000 - val_loss: 0.7512 - val_accuracy: 0.9450\n",
      "Epoch 523/700\n",
      "736/736 [==============================] - 7s 10ms/step - loss: 6.0657e-05 - accuracy: 1.0000 - val_loss: 0.7904 - val_accuracy: 0.9464\n",
      "Epoch 524/700\n",
      "736/736 [==============================] - 7s 9ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 1.2601 - val_accuracy: 0.9128\n",
      "Epoch 525/700\n",
      "736/736 [==============================] - 7s 9ms/step - loss: 0.0108 - accuracy: 0.9978 - val_loss: 0.8388 - val_accuracy: 0.9352\n",
      "Epoch 526/700\n",
      "736/736 [==============================] - 7s 9ms/step - loss: 0.0215 - accuracy: 0.9978 - val_loss: 0.6238 - val_accuracy: 0.9505\n",
      "Epoch 527/700\n",
      "736/736 [==============================] - 5s 6ms/step - loss: 0.0252 - accuracy: 0.9967 - val_loss: 0.4437 - val_accuracy: 0.9542\n",
      "Epoch 528/700\n",
      "736/736 [==============================] - 6s 8ms/step - loss: 0.0049 - accuracy: 0.9990 - val_loss: 0.4878 - val_accuracy: 0.9549\n",
      "Epoch 529/700\n",
      "736/736 [==============================] - 4s 5ms/step - loss: 4.0665e-04 - accuracy: 1.0000 - val_loss: 0.5230 - val_accuracy: 0.9528\n",
      "Epoch 530/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 1.3073e-04 - accuracy: 1.0000 - val_loss: 0.5296 - val_accuracy: 0.9532\n",
      "Epoch 531/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 6.9524e-05 - accuracy: 1.0000 - val_loss: 0.6044 - val_accuracy: 0.9549\n",
      "Epoch 532/700\n",
      "736/736 [==============================] - 6s 9ms/step - loss: 0.0067 - accuracy: 0.9989 - val_loss: 0.6304 - val_accuracy: 0.9522\n",
      "Epoch 533/700\n",
      "736/736 [==============================] - 7s 10ms/step - loss: 0.0282 - accuracy: 0.9963 - val_loss: 0.6828 - val_accuracy: 0.9406\n",
      "Epoch 534/700\n",
      "736/736 [==============================] - 5s 7ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.5729 - val_accuracy: 0.9484\n",
      "Epoch 535/700\n",
      "736/736 [==============================] - 7s 9ms/step - loss: 3.0576e-04 - accuracy: 1.0000 - val_loss: 0.5922 - val_accuracy: 0.9494\n",
      "Epoch 536/700\n",
      "736/736 [==============================] - 5s 7ms/step - loss: 1.2186e-04 - accuracy: 1.0000 - val_loss: 0.6122 - val_accuracy: 0.9494\n",
      "Epoch 537/700\n",
      "736/736 [==============================] - 8s 10ms/step - loss: 0.0082 - accuracy: 0.9981 - val_loss: 0.5404 - val_accuracy: 0.9518\n",
      "Epoch 538/700\n",
      "736/736 [==============================] - 5s 7ms/step - loss: 3.3913e-04 - accuracy: 1.0000 - val_loss: 0.5823 - val_accuracy: 0.9501\n",
      "Epoch 539/700\n",
      "736/736 [==============================] - 6s 9ms/step - loss: 1.5793e-04 - accuracy: 1.0000 - val_loss: 0.5859 - val_accuracy: 0.9525\n",
      "Epoch 540/700\n",
      "736/736 [==============================] - 6s 8ms/step - loss: 1.3581e-04 - accuracy: 1.0000 - val_loss: 0.6198 - val_accuracy: 0.9518\n",
      "Epoch 541/700\n",
      "736/736 [==============================] - 5s 7ms/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.7172 - val_accuracy: 0.9348\n",
      "Epoch 542/700\n",
      "736/736 [==============================] - 5s 7ms/step - loss: 0.0262 - accuracy: 0.9947 - val_loss: 1.0357 - val_accuracy: 0.9382\n",
      "Epoch 543/700\n",
      "736/736 [==============================] - 5s 6ms/step - loss: 0.0219 - accuracy: 0.9952 - val_loss: 0.8270 - val_accuracy: 0.9393\n",
      "Epoch 544/700\n",
      "736/736 [==============================] - 4s 5ms/step - loss: 7.2701e-04 - accuracy: 1.0000 - val_loss: 0.6870 - val_accuracy: 0.9454\n",
      "Epoch 545/700\n",
      "736/736 [==============================] - 3s 4ms/step - loss: 2.8797e-04 - accuracy: 1.0000 - val_loss: 0.7015 - val_accuracy: 0.9464\n",
      "Epoch 546/700\n",
      "736/736 [==============================] - 12s 16ms/step - loss: 2.0241e-04 - accuracy: 1.0000 - val_loss: 0.7394 - val_accuracy: 0.9437\n",
      "Epoch 547/700\n",
      "736/736 [==============================] - 8s 11ms/step - loss: 1.2365e-04 - accuracy: 1.0000 - val_loss: 0.7359 - val_accuracy: 0.9447\n",
      "Epoch 548/700\n",
      "736/736 [==============================] - 11s 15ms/step - loss: 0.0031 - accuracy: 0.9990 - val_loss: 0.7473 - val_accuracy: 0.9430\n",
      "Epoch 549/700\n",
      "736/736 [==============================] - 5s 7ms/step - loss: 1.1409e-04 - accuracy: 1.0000 - val_loss: 0.7412 - val_accuracy: 0.9450\n",
      "Epoch 550/700\n",
      "736/736 [==============================] - 6s 9ms/step - loss: 0.0124 - accuracy: 0.9971 - val_loss: 0.6959 - val_accuracy: 0.9464\n",
      "Epoch 551/700\n",
      "736/736 [==============================] - 12s 16ms/step - loss: 0.0364 - accuracy: 0.9959 - val_loss: 0.5273 - val_accuracy: 0.9525\n",
      "Epoch 552/700\n",
      "736/736 [==============================] - 8s 10ms/step - loss: 2.2688e-04 - accuracy: 1.0000 - val_loss: 0.5547 - val_accuracy: 0.9528\n",
      "Epoch 553/700\n",
      "736/736 [==============================] - 6s 8ms/step - loss: 1.4164e-04 - accuracy: 1.0000 - val_loss: 0.5536 - val_accuracy: 0.9528\n",
      "Epoch 554/700\n",
      "736/736 [==============================] - 8s 10ms/step - loss: 1.4627e-04 - accuracy: 1.0000 - val_loss: 0.5890 - val_accuracy: 0.9532\n",
      "Epoch 555/700\n",
      "736/736 [==============================] - 9s 12ms/step - loss: 7.8631e-05 - accuracy: 1.0000 - val_loss: 0.5895 - val_accuracy: 0.9522\n",
      "Epoch 556/700\n",
      "736/736 [==============================] - 15s 21ms/step - loss: 5.2033e-05 - accuracy: 1.0000 - val_loss: 0.5925 - val_accuracy: 0.9535\n",
      "Epoch 557/700\n",
      "736/736 [==============================] - 15s 20ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.5540 - val_accuracy: 0.9555\n",
      "Epoch 558/700\n",
      "736/736 [==============================] - 15s 20ms/step - loss: 0.0069 - accuracy: 0.9993 - val_loss: 0.5510 - val_accuracy: 0.9549\n",
      "Epoch 559/700\n",
      "736/736 [==============================] - 9s 13ms/step - loss: 0.0036 - accuracy: 0.9990 - val_loss: 0.5598 - val_accuracy: 0.9535\n",
      "Epoch 560/700\n",
      "736/736 [==============================] - 8s 11ms/step - loss: 1.4522e-04 - accuracy: 1.0000 - val_loss: 0.5728 - val_accuracy: 0.9528\n",
      "Epoch 561/700\n",
      "736/736 [==============================] - 5s 7ms/step - loss: 1.0928e-04 - accuracy: 1.0000 - val_loss: 0.5908 - val_accuracy: 0.9532\n",
      "Epoch 562/700\n",
      "736/736 [==============================] - 6s 8ms/step - loss: 6.6653e-05 - accuracy: 1.0000 - val_loss: 0.5925 - val_accuracy: 0.9549\n",
      "Epoch 563/700\n",
      "736/736 [==============================] - 5s 6ms/step - loss: 0.0019 - accuracy: 0.9996 - val_loss: 0.7123 - val_accuracy: 0.9498\n",
      "Epoch 564/700\n",
      "736/736 [==============================] - 9s 12ms/step - loss: 0.0401 - accuracy: 0.9965 - val_loss: 0.5673 - val_accuracy: 0.9508\n",
      "Epoch 565/700\n",
      "736/736 [==============================] - 8s 11ms/step - loss: 2.1348e-04 - accuracy: 1.0000 - val_loss: 0.5439 - val_accuracy: 0.9511\n",
      "Epoch 566/700\n",
      "736/736 [==============================] - 7s 9ms/step - loss: 1.4321e-04 - accuracy: 1.0000 - val_loss: 0.5511 - val_accuracy: 0.9515\n",
      "Epoch 567/700\n",
      "736/736 [==============================] - 6s 8ms/step - loss: 1.1189e-04 - accuracy: 1.0000 - val_loss: 0.5584 - val_accuracy: 0.9522\n",
      "Epoch 568/700\n",
      "736/736 [==============================] - 6s 9ms/step - loss: 8.5040e-05 - accuracy: 1.0000 - val_loss: 0.5600 - val_accuracy: 0.9528\n",
      "Epoch 569/700\n",
      "736/736 [==============================] - 4s 6ms/step - loss: 6.9182e-05 - accuracy: 1.0000 - val_loss: 0.5897 - val_accuracy: 0.9522\n",
      "Epoch 570/700\n",
      "736/736 [==============================] - 6s 9ms/step - loss: 4.7666e-05 - accuracy: 1.0000 - val_loss: 0.5952 - val_accuracy: 0.9518\n",
      "Epoch 571/700\n",
      "736/736 [==============================] - 7s 9ms/step - loss: 3.1399e-05 - accuracy: 1.0000 - val_loss: 0.5994 - val_accuracy: 0.9532\n",
      "Epoch 572/700\n",
      "736/736 [==============================] - 5s 7ms/step - loss: 0.0169 - accuracy: 0.9962 - val_loss: 1.2823 - val_accuracy: 0.9274\n",
      "Epoch 573/700\n",
      "736/736 [==============================] - 5s 6ms/step - loss: 0.0285 - accuracy: 0.9973 - val_loss: 0.6080 - val_accuracy: 0.9501\n",
      "Epoch 574/700\n",
      "736/736 [==============================] - 4s 6ms/step - loss: 7.4053e-04 - accuracy: 1.0000 - val_loss: 0.6139 - val_accuracy: 0.9481\n",
      "Epoch 575/700\n",
      "736/736 [==============================] - 4s 5ms/step - loss: 0.0028 - accuracy: 0.9990 - val_loss: 0.6544 - val_accuracy: 0.9498\n",
      "Epoch 576/700\n",
      "736/736 [==============================] - 4s 5ms/step - loss: 9.2194e-04 - accuracy: 0.9999 - val_loss: 0.6706 - val_accuracy: 0.9484\n",
      "Epoch 577/700\n",
      "736/736 [==============================] - 6s 8ms/step - loss: 2.0337e-04 - accuracy: 1.0000 - val_loss: 0.6839 - val_accuracy: 0.9484\n",
      "Epoch 578/700\n",
      "736/736 [==============================] - 5s 6ms/step - loss: 1.0312e-04 - accuracy: 1.0000 - val_loss: 0.7234 - val_accuracy: 0.9467\n",
      "Epoch 579/700\n",
      "736/736 [==============================] - 4s 6ms/step - loss: 6.0590e-05 - accuracy: 1.0000 - val_loss: 0.7121 - val_accuracy: 0.9481\n",
      "Epoch 580/700\n",
      "736/736 [==============================] - 4s 6ms/step - loss: 6.2649e-05 - accuracy: 1.0000 - val_loss: 0.7332 - val_accuracy: 0.9501\n",
      "Epoch 581/700\n",
      "736/736 [==============================] - 4s 6ms/step - loss: 2.7290e-05 - accuracy: 1.0000 - val_loss: 0.7530 - val_accuracy: 0.9494\n",
      "Epoch 582/700\n",
      "736/736 [==============================] - 4s 6ms/step - loss: 1.9919e-05 - accuracy: 1.0000 - val_loss: 0.8180 - val_accuracy: 0.9467\n",
      "Epoch 583/700\n",
      "736/736 [==============================] - 6s 8ms/step - loss: 0.0344 - accuracy: 0.9947 - val_loss: 0.3971 - val_accuracy: 0.9525\n",
      "Epoch 584/700\n",
      "736/736 [==============================] - 5s 7ms/step - loss: 0.0039 - accuracy: 0.9990 - val_loss: 0.3868 - val_accuracy: 0.9555\n",
      "Epoch 585/700\n",
      "736/736 [==============================] - 5s 7ms/step - loss: 2.1439e-04 - accuracy: 1.0000 - val_loss: 0.4165 - val_accuracy: 0.9545\n",
      "Epoch 586/700\n",
      "736/736 [==============================] - 5s 6ms/step - loss: 1.0428e-04 - accuracy: 1.0000 - val_loss: 0.4290 - val_accuracy: 0.9545\n",
      "Epoch 587/700\n",
      "736/736 [==============================] - 4s 6ms/step - loss: 7.0765e-05 - accuracy: 1.0000 - val_loss: 0.4450 - val_accuracy: 0.9542\n",
      "Epoch 588/700\n",
      "736/736 [==============================] - 4s 6ms/step - loss: 4.5690e-05 - accuracy: 1.0000 - val_loss: 0.4619 - val_accuracy: 0.9549\n",
      "Epoch 589/700\n",
      "736/736 [==============================] - 5s 7ms/step - loss: 3.2836e-05 - accuracy: 1.0000 - val_loss: 0.4566 - val_accuracy: 0.9545\n",
      "Epoch 590/700\n",
      "736/736 [==============================] - 4s 6ms/step - loss: 2.0367e-05 - accuracy: 1.0000 - val_loss: 0.4712 - val_accuracy: 0.9549\n",
      "Epoch 591/700\n",
      "736/736 [==============================] - 4s 6ms/step - loss: 1.6164e-05 - accuracy: 1.0000 - val_loss: 0.4821 - val_accuracy: 0.9552\n",
      "Epoch 592/700\n",
      "736/736 [==============================] - 4s 6ms/step - loss: 1.2394e-05 - accuracy: 1.0000 - val_loss: 0.5002 - val_accuracy: 0.9545\n",
      "Epoch 593/700\n",
      "736/736 [==============================] - 4s 6ms/step - loss: 8.3670e-06 - accuracy: 1.0000 - val_loss: 0.5267 - val_accuracy: 0.9542\n",
      "Epoch 594/700\n",
      "736/736 [==============================] - 4s 6ms/step - loss: 0.0044 - accuracy: 0.9996 - val_loss: 0.5933 - val_accuracy: 0.9528\n",
      "Epoch 595/700\n",
      "736/736 [==============================] - 4s 6ms/step - loss: 0.0364 - accuracy: 0.9967 - val_loss: 0.4389 - val_accuracy: 0.9559\n",
      "Epoch 596/700\n",
      "736/736 [==============================] - 4s 6ms/step - loss: 0.0304 - accuracy: 0.9965 - val_loss: 0.8935 - val_accuracy: 0.9437\n",
      "Epoch 597/700\n",
      "736/736 [==============================] - 4s 6ms/step - loss: 4.9708e-04 - accuracy: 0.9999 - val_loss: 0.8633 - val_accuracy: 0.9416\n",
      "Epoch 598/700\n",
      "736/736 [==============================] - 4s 6ms/step - loss: 8.8485e-05 - accuracy: 1.0000 - val_loss: 0.8600 - val_accuracy: 0.9420\n",
      "Epoch 599/700\n",
      "736/736 [==============================] - 4s 5ms/step - loss: 6.3144e-05 - accuracy: 1.0000 - val_loss: 0.8650 - val_accuracy: 0.9433\n",
      "Epoch 600/700\n",
      "736/736 [==============================] - 4s 6ms/step - loss: 5.0277e-05 - accuracy: 1.0000 - val_loss: 0.8820 - val_accuracy: 0.9423\n",
      "Epoch 601/700\n",
      "736/736 [==============================] - 4s 6ms/step - loss: 4.4154e-05 - accuracy: 1.0000 - val_loss: 0.8782 - val_accuracy: 0.9440\n",
      "Epoch 602/700\n",
      "736/736 [==============================] - 5s 6ms/step - loss: 3.1740e-05 - accuracy: 1.0000 - val_loss: 0.8917 - val_accuracy: 0.9437\n",
      "Epoch 603/700\n",
      "736/736 [==============================] - 5s 7ms/step - loss: 2.3426e-05 - accuracy: 1.0000 - val_loss: 0.8938 - val_accuracy: 0.9437\n",
      "Epoch 604/700\n",
      "736/736 [==============================] - 5s 7ms/step - loss: 1.5979e-05 - accuracy: 1.0000 - val_loss: 0.8851 - val_accuracy: 0.9450\n",
      "Epoch 605/700\n",
      "736/736 [==============================] - 4s 6ms/step - loss: 0.0025 - accuracy: 0.9996 - val_loss: 0.8309 - val_accuracy: 0.9450\n",
      "Epoch 606/700\n",
      "736/736 [==============================] - 4s 5ms/step - loss: 3.3014e-05 - accuracy: 1.0000 - val_loss: 0.8639 - val_accuracy: 0.9457\n",
      "Epoch 607/700\n",
      "736/736 [==============================] - 5s 7ms/step - loss: 2.1233e-05 - accuracy: 1.0000 - val_loss: 0.8915 - val_accuracy: 0.9457\n",
      "Epoch 608/700\n",
      "736/736 [==============================] - 4s 6ms/step - loss: 1.4008e-05 - accuracy: 1.0000 - val_loss: 0.9108 - val_accuracy: 0.9457\n",
      "Epoch 609/700\n",
      "736/736 [==============================] - 5s 6ms/step - loss: 1.0968e-05 - accuracy: 1.0000 - val_loss: 0.9099 - val_accuracy: 0.9464\n",
      "Epoch 610/700\n",
      "736/736 [==============================] - 5s 6ms/step - loss: 6.7255e-06 - accuracy: 1.0000 - val_loss: 0.9394 - val_accuracy: 0.9447\n",
      "Epoch 611/700\n",
      "736/736 [==============================] - 5s 6ms/step - loss: 4.1023e-06 - accuracy: 1.0000 - val_loss: 0.9462 - val_accuracy: 0.9457\n",
      "Epoch 612/700\n",
      "736/736 [==============================] - 4s 5ms/step - loss: 0.0157 - accuracy: 0.9984 - val_loss: 0.6274 - val_accuracy: 0.9515\n",
      "Epoch 613/700\n",
      "736/736 [==============================] - 4s 6ms/step - loss: 0.0026 - accuracy: 0.9993 - val_loss: 0.5166 - val_accuracy: 0.9552\n",
      "Epoch 614/700\n",
      "736/736 [==============================] - 4s 6ms/step - loss: 0.0069 - accuracy: 0.9985 - val_loss: 0.5906 - val_accuracy: 0.9515\n",
      "Epoch 615/700\n",
      "736/736 [==============================] - 4s 6ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.5447 - val_accuracy: 0.9528\n",
      "Epoch 616/700\n",
      "736/736 [==============================] - 5s 6ms/step - loss: 1.3345e-04 - accuracy: 1.0000 - val_loss: 0.5539 - val_accuracy: 0.9511\n",
      "Epoch 617/700\n",
      "736/736 [==============================] - 4s 6ms/step - loss: 8.0275e-05 - accuracy: 1.0000 - val_loss: 0.5761 - val_accuracy: 0.9525\n",
      "Epoch 618/700\n",
      "736/736 [==============================] - 5s 7ms/step - loss: 5.6240e-05 - accuracy: 1.0000 - val_loss: 0.6096 - val_accuracy: 0.9518\n",
      "Epoch 619/700\n",
      "736/736 [==============================] - 4s 6ms/step - loss: 3.9319e-05 - accuracy: 1.0000 - val_loss: 0.6132 - val_accuracy: 0.9522\n",
      "Epoch 620/700\n",
      "736/736 [==============================] - 4s 6ms/step - loss: 3.3403e-05 - accuracy: 1.0000 - val_loss: 0.6195 - val_accuracy: 0.9518\n",
      "Epoch 621/700\n",
      "736/736 [==============================] - 5s 6ms/step - loss: 1.7886e-05 - accuracy: 1.0000 - val_loss: 0.6463 - val_accuracy: 0.9525\n",
      "Epoch 622/700\n",
      "736/736 [==============================] - 4s 6ms/step - loss: 1.6293e-05 - accuracy: 1.0000 - val_loss: 0.6627 - val_accuracy: 0.9522\n",
      "Epoch 623/700\n",
      "736/736 [==============================] - 4s 6ms/step - loss: 9.7919e-06 - accuracy: 1.0000 - val_loss: 0.6666 - val_accuracy: 0.9525\n",
      "Epoch 624/700\n",
      "736/736 [==============================] - 4s 6ms/step - loss: 5.5134e-06 - accuracy: 1.0000 - val_loss: 0.6826 - val_accuracy: 0.9525\n",
      "Epoch 625/700\n",
      "736/736 [==============================] - 5s 6ms/step - loss: 4.0701e-06 - accuracy: 1.0000 - val_loss: 0.6929 - val_accuracy: 0.9528\n",
      "Epoch 626/700\n",
      "736/736 [==============================] - 4s 6ms/step - loss: 2.6994e-06 - accuracy: 1.0000 - val_loss: 0.7157 - val_accuracy: 0.9525\n",
      "Epoch 627/700\n",
      "736/736 [==============================] - 5s 6ms/step - loss: 2.8401e-06 - accuracy: 1.0000 - val_loss: 0.7196 - val_accuracy: 0.9518\n",
      "Epoch 628/700\n",
      "736/736 [==============================] - 4s 6ms/step - loss: 0.0291 - accuracy: 0.9965 - val_loss: 0.5838 - val_accuracy: 0.9535\n",
      "Epoch 629/700\n",
      "736/736 [==============================] - 4s 6ms/step - loss: 0.0140 - accuracy: 0.9974 - val_loss: 0.6615 - val_accuracy: 0.9522\n",
      "Epoch 630/700\n",
      "736/736 [==============================] - 6s 8ms/step - loss: 0.0027 - accuracy: 0.9989 - val_loss: 0.6878 - val_accuracy: 0.9491\n",
      "Epoch 631/700\n",
      "736/736 [==============================] - 6s 8ms/step - loss: 1.3235e-04 - accuracy: 1.0000 - val_loss: 0.7130 - val_accuracy: 0.9491\n",
      "Epoch 632/700\n",
      "736/736 [==============================] - 7s 9ms/step - loss: 7.1645e-05 - accuracy: 1.0000 - val_loss: 0.7194 - val_accuracy: 0.9491\n",
      "Epoch 633/700\n",
      "736/736 [==============================] - 5s 7ms/step - loss: 5.0445e-05 - accuracy: 1.0000 - val_loss: 0.7452 - val_accuracy: 0.9494\n",
      "Epoch 634/700\n",
      "736/736 [==============================] - 6s 8ms/step - loss: 3.0968e-05 - accuracy: 1.0000 - val_loss: 0.7538 - val_accuracy: 0.9498\n",
      "Epoch 635/700\n",
      "736/736 [==============================] - 6s 8ms/step - loss: 1.7302e-05 - accuracy: 1.0000 - val_loss: 0.7621 - val_accuracy: 0.9494\n",
      "Epoch 636/700\n",
      "736/736 [==============================] - 5s 6ms/step - loss: 1.2571e-05 - accuracy: 1.0000 - val_loss: 0.7776 - val_accuracy: 0.9501\n",
      "Epoch 637/700\n",
      "736/736 [==============================] - 5s 7ms/step - loss: 8.0435e-06 - accuracy: 1.0000 - val_loss: 0.8006 - val_accuracy: 0.9498\n",
      "Epoch 638/700\n",
      "736/736 [==============================] - 6s 8ms/step - loss: 0.0050 - accuracy: 0.9992 - val_loss: 0.7635 - val_accuracy: 0.9477\n",
      "Epoch 639/700\n",
      "736/736 [==============================] - 5s 7ms/step - loss: 0.0014 - accuracy: 0.9993 - val_loss: 0.7310 - val_accuracy: 0.9491\n",
      "Epoch 640/700\n",
      "736/736 [==============================] - 5s 7ms/step - loss: 3.0436e-05 - accuracy: 1.0000 - val_loss: 0.7364 - val_accuracy: 0.9498\n",
      "Epoch 641/700\n",
      "736/736 [==============================] - 4s 6ms/step - loss: 1.9801e-05 - accuracy: 1.0000 - val_loss: 0.7515 - val_accuracy: 0.9501\n",
      "Epoch 642/700\n",
      "736/736 [==============================] - 5s 6ms/step - loss: 1.5468e-05 - accuracy: 1.0000 - val_loss: 0.7614 - val_accuracy: 0.9498\n",
      "Epoch 643/700\n",
      "736/736 [==============================] - 5s 7ms/step - loss: 1.1545e-05 - accuracy: 1.0000 - val_loss: 0.7629 - val_accuracy: 0.9498\n",
      "Epoch 644/700\n",
      "736/736 [==============================] - 5s 7ms/step - loss: 8.7641e-06 - accuracy: 1.0000 - val_loss: 0.7752 - val_accuracy: 0.9501\n",
      "Epoch 645/700\n",
      "736/736 [==============================] - 6s 8ms/step - loss: 5.3361e-06 - accuracy: 1.0000 - val_loss: 0.8072 - val_accuracy: 0.9508\n",
      "Epoch 646/700\n",
      "736/736 [==============================] - 5s 6ms/step - loss: 9.4957e-06 - accuracy: 1.0000 - val_loss: 0.7974 - val_accuracy: 0.9501\n",
      "Epoch 647/700\n",
      "736/736 [==============================] - 5s 7ms/step - loss: 3.9920e-06 - accuracy: 1.0000 - val_loss: 0.7770 - val_accuracy: 0.9505\n",
      "Epoch 648/700\n",
      "736/736 [==============================] - 6s 8ms/step - loss: 4.4199e-06 - accuracy: 1.0000 - val_loss: 0.8212 - val_accuracy: 0.9498\n",
      "Epoch 649/700\n",
      "736/736 [==============================] - 5s 7ms/step - loss: 1.3147e-06 - accuracy: 1.0000 - val_loss: 0.8299 - val_accuracy: 0.9501\n",
      "Epoch 650/700\n",
      "736/736 [==============================] - 5s 7ms/step - loss: 1.3628e-06 - accuracy: 1.0000 - val_loss: 0.8012 - val_accuracy: 0.9501\n",
      "Epoch 651/700\n",
      "736/736 [==============================] - 5s 7ms/step - loss: 0.1041 - accuracy: 0.9901 - val_loss: 0.5759 - val_accuracy: 0.9539\n",
      "Epoch 652/700\n",
      "736/736 [==============================] - 6s 8ms/step - loss: 1.7587e-04 - accuracy: 1.0000 - val_loss: 0.6065 - val_accuracy: 0.9535\n",
      "Epoch 653/700\n",
      "736/736 [==============================] - 6s 8ms/step - loss: 1.2316e-04 - accuracy: 1.0000 - val_loss: 0.6122 - val_accuracy: 0.9532\n",
      "Epoch 654/700\n",
      "736/736 [==============================] - 5s 7ms/step - loss: 9.4834e-05 - accuracy: 1.0000 - val_loss: 0.6136 - val_accuracy: 0.9542\n",
      "Epoch 655/700\n",
      "736/736 [==============================] - 4s 6ms/step - loss: 6.9245e-05 - accuracy: 1.0000 - val_loss: 0.6408 - val_accuracy: 0.9532\n",
      "Epoch 656/700\n",
      "736/736 [==============================] - 5s 7ms/step - loss: 5.0012e-05 - accuracy: 1.0000 - val_loss: 0.6454 - val_accuracy: 0.9542\n",
      "Epoch 657/700\n",
      "736/736 [==============================] - 5s 7ms/step - loss: 3.8016e-05 - accuracy: 1.0000 - val_loss: 0.6420 - val_accuracy: 0.9542\n",
      "Epoch 658/700\n",
      "736/736 [==============================] - 5s 7ms/step - loss: 2.8138e-05 - accuracy: 1.0000 - val_loss: 0.7077 - val_accuracy: 0.9535\n",
      "Epoch 659/700\n",
      "736/736 [==============================] - 6s 8ms/step - loss: 1.8872e-05 - accuracy: 1.0000 - val_loss: 0.7074 - val_accuracy: 0.9545\n",
      "Epoch 660/700\n",
      "736/736 [==============================] - 5s 7ms/step - loss: 0.0292 - accuracy: 0.9962 - val_loss: 0.7893 - val_accuracy: 0.9430\n",
      "Epoch 661/700\n",
      "736/736 [==============================] - 5s 6ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.7551 - val_accuracy: 0.9508\n",
      "Epoch 662/700\n",
      "736/736 [==============================] - 5s 6ms/step - loss: 1.6612e-04 - accuracy: 1.0000 - val_loss: 0.6542 - val_accuracy: 0.9542\n",
      "Epoch 663/700\n",
      "736/736 [==============================] - 5s 7ms/step - loss: 1.4132e-04 - accuracy: 1.0000 - val_loss: 0.6599 - val_accuracy: 0.9532\n",
      "Epoch 664/700\n",
      "736/736 [==============================] - 6s 8ms/step - loss: 8.0923e-05 - accuracy: 1.0000 - val_loss: 0.6729 - val_accuracy: 0.9539\n",
      "Epoch 665/700\n",
      "736/736 [==============================] - 5s 7ms/step - loss: 5.3522e-05 - accuracy: 1.0000 - val_loss: 0.6763 - val_accuracy: 0.9545\n",
      "Epoch 666/700\n",
      "736/736 [==============================] - 5s 6ms/step - loss: 3.3190e-05 - accuracy: 1.0000 - val_loss: 0.6967 - val_accuracy: 0.9549\n",
      "Epoch 667/700\n",
      "736/736 [==============================] - 5s 6ms/step - loss: 2.5470e-05 - accuracy: 1.0000 - val_loss: 0.6960 - val_accuracy: 0.9542\n",
      "Epoch 668/700\n",
      "736/736 [==============================] - 5s 6ms/step - loss: 1.8307e-05 - accuracy: 1.0000 - val_loss: 0.7363 - val_accuracy: 0.9549\n",
      "Epoch 669/700\n",
      "736/736 [==============================] - 5s 7ms/step - loss: 1.1112e-05 - accuracy: 1.0000 - val_loss: 0.7410 - val_accuracy: 0.9545\n",
      "Epoch 670/700\n",
      "736/736 [==============================] - 5s 6ms/step - loss: 0.0369 - accuracy: 0.9943 - val_loss: 0.5146 - val_accuracy: 0.9552\n",
      "Epoch 671/700\n",
      "736/736 [==============================] - 5s 7ms/step - loss: 0.0232 - accuracy: 0.9973 - val_loss: 0.5741 - val_accuracy: 0.9535\n",
      "Epoch 672/700\n",
      "736/736 [==============================] - 5s 7ms/step - loss: 3.0514e-04 - accuracy: 1.0000 - val_loss: 0.5776 - val_accuracy: 0.9549\n",
      "Epoch 673/700\n",
      "736/736 [==============================] - 5s 7ms/step - loss: 5.6428e-04 - accuracy: 0.9996 - val_loss: 0.5544 - val_accuracy: 0.9539\n",
      "Epoch 674/700\n",
      "736/736 [==============================] - 5s 6ms/step - loss: 0.0156 - accuracy: 0.9984 - val_loss: 0.5976 - val_accuracy: 0.9542\n",
      "Epoch 675/700\n",
      "736/736 [==============================] - 5s 6ms/step - loss: 1.5071e-04 - accuracy: 1.0000 - val_loss: 0.6233 - val_accuracy: 0.9549\n",
      "Epoch 676/700\n",
      "736/736 [==============================] - 5s 7ms/step - loss: 9.4562e-05 - accuracy: 1.0000 - val_loss: 0.6203 - val_accuracy: 0.9542\n",
      "Epoch 677/700\n",
      "736/736 [==============================] - 6s 8ms/step - loss: 7.3664e-05 - accuracy: 1.0000 - val_loss: 0.6642 - val_accuracy: 0.9539\n",
      "Epoch 678/700\n",
      "736/736 [==============================] - 6s 8ms/step - loss: 4.3288e-05 - accuracy: 1.0000 - val_loss: 0.6827 - val_accuracy: 0.9528\n",
      "Epoch 679/700\n",
      "736/736 [==============================] - 5s 7ms/step - loss: 5.0812e-05 - accuracy: 1.0000 - val_loss: 0.6868 - val_accuracy: 0.9542\n",
      "Epoch 680/700\n",
      "736/736 [==============================] - 5s 7ms/step - loss: 2.5399e-05 - accuracy: 1.0000 - val_loss: 0.6886 - val_accuracy: 0.9545\n",
      "Epoch 681/700\n",
      "736/736 [==============================] - 5s 6ms/step - loss: 2.3245e-05 - accuracy: 1.0000 - val_loss: 0.6911 - val_accuracy: 0.9545\n",
      "Epoch 682/700\n",
      "736/736 [==============================] - 5s 7ms/step - loss: 1.4283e-05 - accuracy: 1.0000 - val_loss: 0.7047 - val_accuracy: 0.9545\n",
      "Epoch 683/700\n",
      "736/736 [==============================] - 5s 7ms/step - loss: 0.0292 - accuracy: 0.9948 - val_loss: 0.9017 - val_accuracy: 0.9444\n",
      "Epoch 684/700\n",
      "736/736 [==============================] - 5s 6ms/step - loss: 0.0140 - accuracy: 0.9982 - val_loss: 0.8265 - val_accuracy: 0.9450\n",
      "Epoch 685/700\n",
      "736/736 [==============================] - 5s 6ms/step - loss: 2.8981e-04 - accuracy: 1.0000 - val_loss: 0.8321 - val_accuracy: 0.9471\n",
      "Epoch 686/700\n",
      "736/736 [==============================] - 5s 7ms/step - loss: 2.2748e-04 - accuracy: 1.0000 - val_loss: 0.8635 - val_accuracy: 0.9454\n",
      "Epoch 687/700\n",
      "736/736 [==============================] - 5s 7ms/step - loss: 8.9179e-05 - accuracy: 1.0000 - val_loss: 0.8639 - val_accuracy: 0.9467\n",
      "Epoch 688/700\n",
      "736/736 [==============================] - 6s 9ms/step - loss: 6.9766e-05 - accuracy: 1.0000 - val_loss: 0.8715 - val_accuracy: 0.9467\n",
      "Epoch 689/700\n",
      "736/736 [==============================] - 5s 7ms/step - loss: 5.1785e-05 - accuracy: 1.0000 - val_loss: 0.8725 - val_accuracy: 0.9460\n",
      "Epoch 690/700\n",
      "736/736 [==============================] - 5s 6ms/step - loss: 4.1483e-05 - accuracy: 1.0000 - val_loss: 0.8994 - val_accuracy: 0.9464\n",
      "Epoch 691/700\n",
      "736/736 [==============================] - 6s 8ms/step - loss: 3.2711e-05 - accuracy: 1.0000 - val_loss: 0.8939 - val_accuracy: 0.9464\n",
      "Epoch 692/700\n",
      "736/736 [==============================] - 4s 6ms/step - loss: 4.1865e-05 - accuracy: 1.0000 - val_loss: 0.8758 - val_accuracy: 0.9488\n",
      "Epoch 693/700\n",
      "736/736 [==============================] - 5s 6ms/step - loss: 0.0181 - accuracy: 0.9978 - val_loss: 0.8201 - val_accuracy: 0.9410\n",
      "Epoch 694/700\n",
      "736/736 [==============================] - 5s 7ms/step - loss: 0.0299 - accuracy: 0.9961 - val_loss: 1.2020 - val_accuracy: 0.9359\n",
      "Epoch 695/700\n",
      "736/736 [==============================] - 5s 7ms/step - loss: 0.0124 - accuracy: 0.9974 - val_loss: 0.5819 - val_accuracy: 0.9555\n",
      "Epoch 696/700\n",
      "736/736 [==============================] - 5s 7ms/step - loss: 4.7405e-04 - accuracy: 0.9999 - val_loss: 0.5983 - val_accuracy: 0.9569\n",
      "Epoch 697/700\n",
      "736/736 [==============================] - 5s 6ms/step - loss: 1.2247e-04 - accuracy: 1.0000 - val_loss: 0.6156 - val_accuracy: 0.9572\n",
      "Epoch 698/700\n",
      "736/736 [==============================] - 5s 7ms/step - loss: 8.3437e-05 - accuracy: 1.0000 - val_loss: 0.6318 - val_accuracy: 0.9572\n",
      "Epoch 699/700\n",
      "736/736 [==============================] - 5s 7ms/step - loss: 6.1462e-05 - accuracy: 1.0000 - val_loss: 0.6446 - val_accuracy: 0.9569\n",
      "Epoch 700/700\n",
      "736/736 [==============================] - 5s 6ms/step - loss: 4.1008e-05 - accuracy: 1.0000 - val_loss: 0.6542 - val_accuracy: 0.9569\n"
     ]
    }
   ],
   "source": [
    "model3 = build_model()\n",
    "\n",
    "history3 = model3.fit(X_train, dummy_y, validation_data=(X_test, test_y), epochs=700, batch_size=10).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "13a66c3c-f5f2-4d06-9c4d-7abd15a24837",
   "metadata": {
    "id": "XJ0PVBu1xa6k",
    "outputId": "ad447b93-aed4-4740-e0c4-66d2a2c585a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 1s 7ms/step - loss: 0.6542 - accuracy: 0.9569\n",
      "Loss 0.201301, Accuracy 0.952155\n",
      "Loss 0.247177, Accuracy 0.947065\n",
      "Loss 0.654244, Accuracy 0.956905\n"
     ]
    }
   ],
   "source": [
    "test_loss_3, test_acc_3 = model3.evaluate(X_test, test_y)\n",
    "\n",
    "print('Loss %f, Accuracy %f' % (test_loss_1, test_acc_1))\n",
    "print('Loss %f, Accuracy %f' % (test_loss_2, test_acc_2))\n",
    "print('Loss %f, Accuracy %f' % (test_loss_3, test_acc_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "cf70047e-dad2-4224-898c-8ffcb34b2037",
   "metadata": {
    "id": "QQEeztQ4xa6l",
    "outputId": "7ad31aaf-7cf4-4d4a-e647-8aaf01e336f4"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history3['loss'], label='Train')\n",
    "plt.plot(history3['val_loss'], label='Val')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Cross-Entropy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "cdf3801a-5f2a-48c2-9d31-3ed57f0ec93b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.8751272480488632\n",
      "F1-score [0.95824635 0.95074946 0.96695226 0.77267081 0.88548057 1.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.93      0.96       496\n",
      "           1       0.96      0.94      0.95       471\n",
      "           2       0.99      0.94      0.97       420\n",
      "           3       0.99      0.63      0.77       491\n",
      "           4       0.97      0.81      0.89       532\n",
      "           5       1.00      1.00      1.00       537\n",
      "\n",
      "   micro avg       0.98      0.88      0.93      2947\n",
      "   macro avg       0.98      0.88      0.92      2947\n",
      "weighted avg       0.98      0.88      0.92      2947\n",
      " samples avg       0.88      0.88      0.88      2947\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model3.predict(X_test).astype(int)\n",
    "\n",
    "print('Accuracy %s' % accuracy_score(test_y, y_pred))\n",
    "print('F1-score %s' % f1_score(test_y, y_pred, average=None))\n",
    "print(classification_report(test_y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1aa4da3d-1b18-45ce-b415-5187ab30052b",
   "metadata": {
    "id": "FksmmKxZxa6l"
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cd7662-352c-4572-84a2-1222dfe27891",
   "metadata": {
    "id": "gNuEzp7mxa6l"
   },
   "source": [
    "## Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c5d8658-c4e3-4d92-b2a7-69c7a8b55229",
   "metadata": {
    "id": "pLD1rrUyxa6l"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "92a52a3f-dfc2-415e-96e8-74c6599f2521",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_train)\n",
    "encoded_Y = encoder.transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7365cbcf-4dc8-40d2-bb6e-2bcfb2b0ead0",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_val)\n",
    "encoded_val = encoder.transform(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "178d1eb2-61e5-4f20-a28d-65d148c14eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_y = np_utils.to_categorical(encoded_Y)\n",
    "val_y = np_utils.to_categorical(encoded_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b85fb3-6932-41be-a956-94a6de6485f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d6b926c-b221-4bbb-bbd1-fcba5fae29b5",
   "metadata": {
    "collapsed": true,
    "id": "vWGe3oO3xa6m",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "4f96e9bc-47aa-4351-d96e-6da4d969002a",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-20 17:28:52.835233: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "589/589 [==============================] - 3s 5ms/step - loss: 0.3945 - accuracy: 0.8371 - val_loss: 0.3257 - val_accuracy: 0.8613\n",
      "Epoch 2/100\n",
      "589/589 [==============================] - 3s 4ms/step - loss: 0.1566 - accuracy: 0.9412 - val_loss: 0.1446 - val_accuracy: 0.9409\n",
      "Epoch 3/100\n",
      "589/589 [==============================] - 3s 5ms/step - loss: 0.1160 - accuracy: 0.9544 - val_loss: 0.1345 - val_accuracy: 0.9436\n",
      "Epoch 4/100\n",
      "589/589 [==============================] - 3s 6ms/step - loss: 0.0945 - accuracy: 0.9609 - val_loss: 0.0754 - val_accuracy: 0.9680\n",
      "Epoch 5/100\n",
      "589/589 [==============================] - 3s 4ms/step - loss: 0.0988 - accuracy: 0.9614 - val_loss: 0.1066 - val_accuracy: 0.9517\n",
      "Epoch 6/100\n",
      "589/589 [==============================] - 3s 5ms/step - loss: 0.0758 - accuracy: 0.9685 - val_loss: 0.0906 - val_accuracy: 0.9640\n",
      "Epoch 7/100\n",
      "589/589 [==============================] - 3s 5ms/step - loss: 0.0781 - accuracy: 0.9697 - val_loss: 0.0714 - val_accuracy: 0.9721\n",
      "Epoch 8/100\n",
      "589/589 [==============================] - 3s 5ms/step - loss: 0.0637 - accuracy: 0.9748 - val_loss: 0.0629 - val_accuracy: 0.9755\n",
      "Epoch 9/100\n",
      "589/589 [==============================] - 3s 5ms/step - loss: 0.0758 - accuracy: 0.9704 - val_loss: 0.0996 - val_accuracy: 0.9619\n",
      "Epoch 10/100\n",
      "589/589 [==============================] - 3s 5ms/step - loss: 0.0615 - accuracy: 0.9769 - val_loss: 0.0686 - val_accuracy: 0.9728\n",
      "Epoch 11/100\n",
      "589/589 [==============================] - 3s 5ms/step - loss: 0.0791 - accuracy: 0.9718 - val_loss: 0.0742 - val_accuracy: 0.9728\n",
      "Epoch 12/100\n",
      "589/589 [==============================] - 3s 6ms/step - loss: 0.0596 - accuracy: 0.9772 - val_loss: 0.0613 - val_accuracy: 0.9755\n",
      "Epoch 13/100\n",
      "589/589 [==============================] - 3s 4ms/step - loss: 0.0507 - accuracy: 0.9796 - val_loss: 0.1370 - val_accuracy: 0.9490\n",
      "Epoch 14/100\n",
      "589/589 [==============================] - 2s 4ms/step - loss: 0.0559 - accuracy: 0.9781 - val_loss: 0.1881 - val_accuracy: 0.9313\n",
      "Epoch 15/100\n",
      "589/589 [==============================] - 2s 4ms/step - loss: 0.0599 - accuracy: 0.9779 - val_loss: 0.0572 - val_accuracy: 0.9789\n",
      "Epoch 16/100\n",
      "589/589 [==============================] - 3s 4ms/step - loss: 0.0607 - accuracy: 0.9762 - val_loss: 0.0571 - val_accuracy: 0.9810\n",
      "Epoch 17/100\n",
      "589/589 [==============================] - 2s 4ms/step - loss: 0.0462 - accuracy: 0.9833 - val_loss: 0.0699 - val_accuracy: 0.9735\n",
      "Epoch 18/100\n",
      "589/589 [==============================] - 2s 4ms/step - loss: 0.0542 - accuracy: 0.9793 - val_loss: 0.0582 - val_accuracy: 0.9796\n",
      "Epoch 19/100\n",
      "589/589 [==============================] - 3s 5ms/step - loss: 0.0548 - accuracy: 0.9793 - val_loss: 0.0525 - val_accuracy: 0.9823\n",
      "Epoch 20/100\n",
      "589/589 [==============================] - 3s 5ms/step - loss: 0.0484 - accuracy: 0.9801 - val_loss: 0.0659 - val_accuracy: 0.9735\n",
      "Epoch 21/100\n",
      "589/589 [==============================] - 3s 4ms/step - loss: 0.0484 - accuracy: 0.9825 - val_loss: 0.1022 - val_accuracy: 0.9599\n",
      "Epoch 22/100\n",
      "589/589 [==============================] - 2s 3ms/step - loss: 0.0464 - accuracy: 0.9825 - val_loss: 0.0745 - val_accuracy: 0.9674\n",
      "Epoch 23/100\n",
      "589/589 [==============================] - 2s 4ms/step - loss: 0.0619 - accuracy: 0.9767 - val_loss: 0.0956 - val_accuracy: 0.9626\n",
      "Epoch 24/100\n",
      "589/589 [==============================] - 3s 5ms/step - loss: 0.0396 - accuracy: 0.9837 - val_loss: 0.0457 - val_accuracy: 0.9830\n",
      "Epoch 25/100\n",
      "589/589 [==============================] - 4s 6ms/step - loss: 0.0594 - accuracy: 0.9772 - val_loss: 0.0602 - val_accuracy: 0.9803\n",
      "Epoch 26/100\n",
      "589/589 [==============================] - 3s 5ms/step - loss: 0.0414 - accuracy: 0.9837 - val_loss: 0.0557 - val_accuracy: 0.9789\n",
      "Epoch 27/100\n",
      "589/589 [==============================] - 3s 4ms/step - loss: 0.0410 - accuracy: 0.9845 - val_loss: 0.0782 - val_accuracy: 0.9687\n",
      "Epoch 28/100\n",
      "589/589 [==============================] - 3s 5ms/step - loss: 0.0363 - accuracy: 0.9845 - val_loss: 0.0465 - val_accuracy: 0.9823\n",
      "Epoch 29/100\n",
      "589/589 [==============================] - 2s 4ms/step - loss: 0.0471 - accuracy: 0.9815 - val_loss: 0.0612 - val_accuracy: 0.9782\n",
      "Epoch 30/100\n",
      "589/589 [==============================] - 2s 4ms/step - loss: 0.0460 - accuracy: 0.9828 - val_loss: 0.0614 - val_accuracy: 0.9789\n",
      "Epoch 31/100\n",
      "589/589 [==============================] - 3s 5ms/step - loss: 0.0438 - accuracy: 0.9828 - val_loss: 0.0684 - val_accuracy: 0.9728\n",
      "Epoch 32/100\n",
      "589/589 [==============================] - 2s 3ms/step - loss: 0.0346 - accuracy: 0.9871 - val_loss: 0.0630 - val_accuracy: 0.9755\n",
      "Epoch 33/100\n",
      "589/589 [==============================] - 2s 4ms/step - loss: 0.0350 - accuracy: 0.9861 - val_loss: 0.0461 - val_accuracy: 0.9830\n",
      "Epoch 34/100\n",
      "589/589 [==============================] - 2s 3ms/step - loss: 0.0525 - accuracy: 0.9828 - val_loss: 0.0625 - val_accuracy: 0.9742\n"
     ]
    }
   ],
   "source": [
    "es = EarlyStopping(monitor='val_loss', patience=10)\n",
    "mc = ModelCheckpoint('best_model_NOREG.h5', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "model4 = build_model()\n",
    "history4 = model4.fit(X_train, dummy_y, validation_data=(X_val, val_y), epochs=100, \n",
    "                      batch_size=10, callbacks=[es,mc]).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf62108-6db9-4f5c-bf33-904846cc2b39",
   "metadata": {
    "id": "ZTebFhQpxa6m",
    "outputId": "dcb50dd1-3924-425e-81c7-6de1a61be7d3"
   },
   "outputs": [],
   "source": [
    "test_loss_4, test_acc_4 = model4.evaluate(X_val, val_y)\n",
    "\n",
    "print('Loss %f, Accuracy %f' % (test_loss_1, test_acc_1))\n",
    "print('Loss %f, Accuracy %f' % (test_loss_2, test_acc_2))\n",
    "print('Loss %f, Accuracy %f' % (test_loss_3, test_acc_3))\n",
    "print('Loss %f, Accuracy %f' % (test_loss_4, test_acc_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b9395e8d-cf25-470a-98e8-f538aef21bce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history4['loss'], label='Train')\n",
    "plt.plot(history4['val_loss'], label='Val')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Cross-Entropy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1955bd2f-c6b7-485f-9a9f-e7af6e39b5c8",
   "metadata": {
    "id": "B_d1jVy4xa6m"
   },
   "source": [
    "## L2 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3da78c5f-9571-44fa-8f3b-4d17aeeccd4c",
   "metadata": {
    "id": "Xqzuwshlxa6n"
   },
   "outputs": [],
   "source": [
    "from keras.regularizers import l2\n",
    "\n",
    "def build_L2_model():\n",
    "    # define the model\n",
    "    model = Sequential()\n",
    "\n",
    "    n_feature = X_train.shape[1]\n",
    "    h_dim=100\n",
    "    model.add(Dense(h_dim, activation='relu', input_shape=(n_feature,), kernel_regularizer=l2(0.01)))\n",
    "    model.add(Dense(h_dim, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "    model.add(Dense(h_dim, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "    model.add(Dense(h_dim, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "    #linear activation\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    #compile the model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "872d8fb5-68bb-4ecd-850b-75dabaa2bbd5",
   "metadata": {
    "collapsed": true,
    "id": "UpUhCig-xa6n",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "1a4626b4-06cf-4e0f-ac28-e34fc3497ec5",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "589/589 [==============================] - 4s 5ms/step - loss: 2.0992 - accuracy: 0.8235 - val_loss: 1.2868 - val_accuracy: 0.8333\n",
      "Epoch 2/100\n",
      "589/589 [==============================] - 3s 5ms/step - loss: 1.0366 - accuracy: 0.8333 - val_loss: 0.8481 - val_accuracy: 0.8333\n",
      "Epoch 3/100\n",
      "589/589 [==============================] - 3s 5ms/step - loss: 0.7362 - accuracy: 0.8333 - val_loss: 0.6473 - val_accuracy: 0.8333\n",
      "Epoch 4/100\n",
      "589/589 [==============================] - 3s 5ms/step - loss: 0.5915 - accuracy: 0.8333 - val_loss: 0.5467 - val_accuracy: 0.8333\n",
      "Epoch 5/100\n",
      "589/589 [==============================] - 3s 6ms/step - loss: 0.5184 - accuracy: 0.8333 - val_loss: 0.4958 - val_accuracy: 0.8333\n",
      "Epoch 6/100\n",
      "589/589 [==============================] - 3s 6ms/step - loss: 0.4817 - accuracy: 0.8333 - val_loss: 0.4707 - val_accuracy: 0.8333\n",
      "Epoch 7/100\n",
      "589/589 [==============================] - 3s 5ms/step - loss: 0.4640 - accuracy: 0.8333 - val_loss: 0.4589 - val_accuracy: 0.8333\n",
      "Epoch 8/100\n",
      "589/589 [==============================] - 3s 5ms/step - loss: 0.4559 - accuracy: 0.8333 - val_loss: 0.4537 - val_accuracy: 0.8333\n",
      "Epoch 9/100\n",
      "589/589 [==============================] - 3s 5ms/step - loss: 0.4525 - accuracy: 0.8333 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
      "Epoch 10/100\n",
      "589/589 [==============================] - 3s 5ms/step - loss: 0.4512 - accuracy: 0.8333 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
      "Epoch 11/100\n",
      "589/589 [==============================] - 3s 5ms/step - loss: 0.4507 - accuracy: 0.8333 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
      "Epoch 12/100\n",
      "589/589 [==============================] - 3s 6ms/step - loss: 0.4506 - accuracy: 0.8333 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
      "Epoch 13/100\n",
      "589/589 [==============================] - 3s 5ms/step - loss: 0.4506 - accuracy: 0.8333 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
      "Epoch 14/100\n",
      "589/589 [==============================] - 3s 6ms/step - loss: 0.4506 - accuracy: 0.8333 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
      "Epoch 15/100\n",
      "589/589 [==============================] - 3s 5ms/step - loss: 0.4506 - accuracy: 0.8333 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
      "Epoch 16/100\n",
      "589/589 [==============================] - 3s 6ms/step - loss: 0.4506 - accuracy: 0.8333 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
      "Epoch 17/100\n",
      "589/589 [==============================] - 3s 5ms/step - loss: 0.4506 - accuracy: 0.8333 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
      "Epoch 18/100\n",
      "589/589 [==============================] - 3s 5ms/step - loss: 0.4506 - accuracy: 0.8333 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
      "Epoch 19/100\n",
      "589/589 [==============================] - 3s 5ms/step - loss: 0.4506 - accuracy: 0.8333 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
      "Epoch 20/100\n",
      "589/589 [==============================] - 3s 5ms/step - loss: 0.4506 - accuracy: 0.8333 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
      "Epoch 21/100\n",
      "589/589 [==============================] - 2s 4ms/step - loss: 0.4506 - accuracy: 0.8333 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
      "Epoch 22/100\n",
      "589/589 [==============================] - 2s 3ms/step - loss: 0.4506 - accuracy: 0.8333 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
      "Epoch 23/100\n",
      "589/589 [==============================] - 2s 3ms/step - loss: 0.4506 - accuracy: 0.8333 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
      "Epoch 24/100\n",
      "589/589 [==============================] - 2s 3ms/step - loss: 0.4506 - accuracy: 0.8333 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
      "Epoch 25/100\n",
      "589/589 [==============================] - 3s 5ms/step - loss: 0.4506 - accuracy: 0.8333 - val_loss: 0.4506 - val_accuracy: 0.8333\n"
     ]
    }
   ],
   "source": [
    "mc = ModelCheckpoint('best_model_L2.h5', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "L2_model = build_L2_model()\n",
    "h_L2 = L2_model.fit(X_train, dummy_y, validation_data=(X_val, val_y), epochs=100, \n",
    "                    batch_size=10, callbacks=[es,mc]).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3113213b-25ab-43ed-8102-df68cc3e24c9",
   "metadata": {
    "id": "_pXYeQ63xa6p"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dropout\n",
    "\n",
    "def build_DROPOUT_model():\n",
    "    # define the model\n",
    "    model = Sequential()\n",
    "\n",
    "    n_feature = X_train.shape[1]\n",
    "    h_dim=100\n",
    "    model.add(Dense(h_dim, activation='relu', input_shape=(n_feature,)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(h_dim, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(h_dim, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(h_dim, activation='relu'))\n",
    "    #linear activation\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    #compile the model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ec7c1eb5-8e86-4c8c-b25b-e065cbdba7e2",
   "metadata": {
    "collapsed": true,
    "id": "1396b1Gexa6p",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "6e16dc17-2eed-454b-9b4c-31b7568587cc",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "589/589 [==============================] - 4s 5ms/step - loss: 0.4833 - accuracy: 0.8304 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
      "Epoch 2/100\n",
      "589/589 [==============================] - 3s 6ms/step - loss: 0.4516 - accuracy: 0.8333 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 3/100\n",
      "589/589 [==============================] - 3s 5ms/step - loss: 0.4586 - accuracy: 0.8324 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
      "Epoch 4/100\n",
      "589/589 [==============================] - 4s 6ms/step - loss: 0.4539 - accuracy: 0.8330 - val_loss: 0.4512 - val_accuracy: 0.8329\n",
      "Epoch 5/100\n",
      "589/589 [==============================] - 4s 6ms/step - loss: 0.4537 - accuracy: 0.8332 - val_loss: 0.4520 - val_accuracy: 0.8333\n",
      "Epoch 6/100\n",
      "589/589 [==============================] - 3s 5ms/step - loss: 0.4524 - accuracy: 0.8332 - val_loss: 0.4520 - val_accuracy: 0.8333\n",
      "Epoch 7/100\n",
      "589/589 [==============================] - 3s 5ms/step - loss: 0.4514 - accuracy: 0.8332 - val_loss: 0.4521 - val_accuracy: 0.8333\n",
      "Epoch 8/100\n",
      "589/589 [==============================] - 2s 4ms/step - loss: 0.4514 - accuracy: 0.8333 - val_loss: 0.4520 - val_accuracy: 0.8333\n",
      "Epoch 9/100\n",
      "589/589 [==============================] - 2s 4ms/step - loss: 0.4522 - accuracy: 0.8333 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
      "Epoch 10/100\n",
      "589/589 [==============================] - 3s 4ms/step - loss: 0.4507 - accuracy: 0.8333 - val_loss: 0.4513 - val_accuracy: 0.8329\n",
      "Epoch 11/100\n",
      "589/589 [==============================] - 3s 5ms/step - loss: 0.4521 - accuracy: 0.8330 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 12/100\n",
      "589/589 [==============================] - 3s 5ms/step - loss: 0.4507 - accuracy: 0.8333 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
      "Epoch 13/100\n",
      "589/589 [==============================] - 3s 5ms/step - loss: 0.4507 - accuracy: 0.8332 - val_loss: 0.4520 - val_accuracy: 0.8333\n",
      "Epoch 14/100\n",
      "589/589 [==============================] - 3s 5ms/step - loss: 0.4506 - accuracy: 0.8333 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
      "Epoch 15/100\n",
      "589/589 [==============================] - 3s 5ms/step - loss: 0.4506 - accuracy: 0.8333 - val_loss: 0.4520 - val_accuracy: 0.8333\n",
      "Epoch 16/100\n",
      "589/589 [==============================] - 3s 5ms/step - loss: 0.4506 - accuracy: 0.8333 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
      "Epoch 17/100\n",
      "589/589 [==============================] - 3s 5ms/step - loss: 0.4506 - accuracy: 0.8333 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
      "Epoch 18/100\n",
      "589/589 [==============================] - 3s 5ms/step - loss: 0.4506 - accuracy: 0.8333 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
      "Epoch 19/100\n",
      "589/589 [==============================] - 3s 5ms/step - loss: 0.4506 - accuracy: 0.8332 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
      "Epoch 20/100\n",
      "589/589 [==============================] - 3s 5ms/step - loss: 0.4506 - accuracy: 0.8333 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
      "Epoch 21/100\n",
      "589/589 [==============================] - 3s 5ms/step - loss: 0.4506 - accuracy: 0.8333 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
      "Epoch 22/100\n",
      "589/589 [==============================] - 3s 5ms/step - loss: 0.4506 - accuracy: 0.8333 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
      "Epoch 23/100\n",
      "589/589 [==============================] - 3s 5ms/step - loss: 0.4506 - accuracy: 0.8333 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
      "Epoch 24/100\n",
      "589/589 [==============================] - 3s 4ms/step - loss: 0.4506 - accuracy: 0.8333 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
      "Epoch 25/100\n",
      "589/589 [==============================] - 3s 5ms/step - loss: 0.4506 - accuracy: 0.8333 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
      "Epoch 26/100\n",
      "589/589 [==============================] - 3s 6ms/step - loss: 0.4506 - accuracy: 0.8333 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
      "Epoch 27/100\n",
      "589/589 [==============================] - 3s 5ms/step - loss: 0.4506 - accuracy: 0.8333 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
      "Epoch 28/100\n",
      "589/589 [==============================] - 3s 5ms/step - loss: 0.4506 - accuracy: 0.8333 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
      "Epoch 29/100\n",
      "589/589 [==============================] - 3s 5ms/step - loss: 0.4506 - accuracy: 0.8333 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
      "Epoch 30/100\n",
      "589/589 [==============================] - 3s 4ms/step - loss: 0.4506 - accuracy: 0.8333 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
      "Epoch 31/100\n",
      "589/589 [==============================] - 3s 5ms/step - loss: 0.4506 - accuracy: 0.8333 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
      "Epoch 32/100\n",
      "589/589 [==============================] - 2s 4ms/step - loss: 0.4506 - accuracy: 0.8333 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
      "Epoch 33/100\n",
      "589/589 [==============================] - 3s 4ms/step - loss: 0.4506 - accuracy: 0.8333 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
      "Epoch 34/100\n",
      "589/589 [==============================] - 3s 5ms/step - loss: 0.4506 - accuracy: 0.8333 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
      "Epoch 35/100\n",
      "589/589 [==============================] - 3s 5ms/step - loss: 0.4506 - accuracy: 0.8333 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
      "Epoch 36/100\n",
      "589/589 [==============================] - 3s 5ms/step - loss: 0.4506 - accuracy: 0.8333 - val_loss: 0.4506 - val_accuracy: 0.8333\n"
     ]
    }
   ],
   "source": [
    "mc = ModelCheckpoint('best_model_DROPOUT.h5', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "DROPOUT_model = build_DROPOUT_model()\n",
    "h_DROPOUT = DROPOUT_model.fit(X_train, dummy_y, validation_data=(X_val, val_y), \n",
    "                              epochs=100, batch_size=10, callbacks=[es,mc]).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "755b9225-91fe-460c-bd4b-ee8e6aabceb7",
   "metadata": {
    "id": "IUP-OdFhxa6q",
    "outputId": "ff20e657-a4a2-4aee-8270-76ba7a275ef0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 3ms/step - loss: 0.0457 - accuracy: 0.9830\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4506 - accuracy: 0.8333\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4506 - accuracy: 0.8333\n"
     ]
    }
   ],
   "source": [
    "# laod best models and test them\n",
    "from keras.models import load_model\n",
    "\n",
    "best_NOREG_model = load_model('best_model_NOREG.h5')\n",
    "best_L2_model = load_model('best_model_L2.h5')\n",
    "best_DROPOUT_model = load_model('best_model_DROPOUT.h5')\n",
    "\n",
    "loss_NOREG, acc_NOREG = best_NOREG_model.evaluate(X_val, val_y)\n",
    "loss_L2, acc_L2 = best_L2_model.evaluate(X_val, val_y)\n",
    "loss_DROPOUT, acc_DROPOUT = best_DROPOUT_model.evaluate(X_val, val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c52fa2fa-82de-4a6e-9ef6-bfce19f4b2a9",
   "metadata": {
    "id": "g3DIAjnJxa6q",
    "outputId": "dace7b8a-8dea-4679-a21f-ff7ad115e50a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 0.045745, Accuracy 0.983005\n",
      "Loss 0.450561, Accuracy 0.833333\n",
      "Loss 0.450561, Accuracy 0.833333\n"
     ]
    }
   ],
   "source": [
    "print('Loss %f, Accuracy %f' % (loss_NOREG, acc_NOREG))\n",
    "print('Loss %f, Accuracy %f' % (loss_L2, acc_L2))\n",
    "print('Loss %f, Accuracy %f' % (loss_DROPOUT, acc_DROPOUT))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
